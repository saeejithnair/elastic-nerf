{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import torch\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "import wandb\n",
    "from elastic_nerf.nerfacc.radiance_fields.ngp import (\n",
    "    NGPRadianceField,\n",
    "    NGPRadianceFieldConfig,\n",
    ")\n",
    "from elastic_nerf.utils import dataset_utils as du\n",
    "from elastic_nerf.utils import notebook_utils as nu\n",
    "from elastic_nerf.utils import plotting_utils as pu\n",
    "from elastic_nerf.utils import results_utils as ru\n",
    "from elastic_nerf.utils import wandb_utils as wu\n",
    "from elastic_nerf.utils.experiments.sweeps import SWEEPS\n",
    "\n",
    "pio.renderers.default = \"plotly_mimetype+notebook_connected\"\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run dl2jtisb from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run e3pz30qh from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run m9xhztrp from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run mnsir9w4 from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run szt53wvx from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run yxgs90fl from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run aq3euasd from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run 3uxsoxyl from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run 1tr8v17t from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run ccfxl8j8 from 39 files.\n",
      "Downloading weights and gradients for run 99poosnb from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run caklteez from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run xhz9x6q4 from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run egir8lsk from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 1/39 [00:12<08:07, 12.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run m2jpab2y from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run 3j51c6rp from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run 9bnx2h2c from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run i50o37p5 from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run ztq19iqr from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run 7pqmuw7e from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run caezqxkl from 39 files.\n",
      "Downloading weights and gradients for run p7afcuvc from 39 files.\n",
      "Downloading weights and gradients for run s7vvmvdo from 39 files.\n",
      "Downloading weights and gradients for run cauvbtcy from 39 files.\n",
      "Downloading weights and gradients for run ibcx1yni from 39 files.\n",
      "Downloading weights and gradients for run e1u3kcjo from 39 files.\n",
      "Downloading weights and gradients for run lb7ss2j6 from 39 files.\n",
      "Downloading weights and gradients for run 7gnc9mnn from 39 files.\n",
      "Downloading weights and gradients for run uw1pa86q from 39 files.\n",
      "Downloading weights and gradients for run s0y1ioia from 39 files.\n",
      "Downloading weights and gradients for run be9r0zps from 39 files.\n",
      "Downloading weights and gradients for run ux43iyvw from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  5%|▌         | 2/39 [01:16<26:31, 43.01s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  8%|▊         | 3/39 [02:15<30:08, 50.22s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|█         | 4/39 [03:14<31:22, 53.77s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|█▎        | 5/39 [04:19<32:39, 57.63s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|█▌        | 6/39 [05:23<32:51, 59.75s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 18%|█▊        | 7/39 [06:24<32:09, 60.31s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|██        | 8/39 [07:29<31:53, 61.74s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|██▎       | 9/39 [08:35<31:32, 63.09s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|██▌       | 10/39 [09:39<30:35, 63.30s/it]A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██▊       | 11/39 [10:39<29:02, 62.22s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|███       | 12/39 [11:42<28:08, 62.55s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 13/39 [12:45<27:06, 62.54s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|███▌      | 14/39 [13:45<25:49, 61.96s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 15/39 [14:47<24:49, 62.06s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|████      | 16/39 [15:53<24:08, 62.99s/it]A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|███▌      | 14/39 [16:05<28:44, 68.98s/it]A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run ccfxl8j8: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run jwps1v5t from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|███▌      | 14/39 [16:12<28:56, 69.45s/it]A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run aq3euasd: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run 87l0osdc from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 13/39 [16:05<32:10, 74.25s/it]A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run lb7ss2j6: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      " 38%|███▊      | 15/39 [16:22<26:11, 65.47s/it]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run e3pz30qh: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run jj2hfnp5 from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run rea2ecop from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 13/39 [16:29<32:58, 76.11s/it]A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run yxgs90fl: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run nj65mr75 from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 15/39 [16:39<26:38, 66.62s/it]A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run szt53wvx: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      " 36%|███▌      | 14/39 [16:38<29:43, 71.35s/it]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run 99poosnb: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      " 38%|███▊      | 15/39 [16:40<26:40, 66.68s/it]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run xhz9x6q4: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run jdk298zm from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run 25gx1w3a from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 15/39 [16:42<26:43, 66.81s/it]A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run 3uxsoxyl: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      " 36%|███▌      | 14/39 [16:43<29:51, 71.65s/it]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run caklteez: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run za3l4ndu from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 15/39 [16:44<26:46, 66.96s/it]A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run 1tr8v17t: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run j128w9iq from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 15/39 [16:44<26:47, 66.99s/it]A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run egir8lsk: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run 8zhv3qw1 from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 15/39 [16:39<26:39, 66.64s/it]A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run 7pqmuw7e: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run 2wy2ia3n from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run wo169kgy from 39 files.\n",
      "Downloading weights and gradients for run jmurb5ym from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|████      | 16/39 [16:58<24:24, 63.66s/it]A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run dl2jtisb: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      " 38%|███▊      | 15/39 [16:45<26:49, 67.04s/it]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run p7afcuvc: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      " 38%|███▊      | 15/39 [16:42<26:43, 66.81s/it]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run uw1pa86q: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      " 38%|███▊      | 15/39 [16:42<26:44, 66.85s/it]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run be9r0zps: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run qlrb1zsf from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run b21vbwpp from 39 files.\n",
      "Downloading weights and gradients for run a9f92tnu from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 15/39 [16:49<26:54, 67.28s/it]A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run ztq19iqr: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run qbk2hhse from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 15/39 [16:45<26:48, 67.03s/it]A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run ux43iyvw: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      " 38%|███▊      | 15/39 [16:51<26:58, 67.44s/it]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run 3j51c6rp: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run nzy5e6xy from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run c9q3pzhb from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 15/39 [16:53<27:01, 67.56s/it]A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run m2jpab2y: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run 4nod4jbc from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 15/39 [16:49<26:55, 67.31s/it]A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run 7gnc9mnn: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      " 38%|███▊      | 15/39 [16:54<27:03, 67.65s/it]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run s7vvmvdo: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run y757jtj4 from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run wuscm9fh from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 15/39 [16:56<27:06, 67.75s/it]A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run i50o37p5: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run n0vtz8bj from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|████      | 16/39 [17:07<24:37, 64.23s/it]A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run m9xhztrp: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      " 38%|███▊      | 15/39 [16:58<27:09, 67.88s/it]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run cauvbtcy: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      " 38%|███▊      | 15/39 [16:53<27:02, 67.59s/it]\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run s0y1ioia: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      " 38%|███▊      | 15/39 [16:58<27:09, 67.88s/it]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run ibcx1yni: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run vd2erlx8 from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run mrhp72xv from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 15/39 [16:59<27:10, 67.95s/it]A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run e1u3kcjo: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      " 41%|████      | 16/39 [17:07<24:37, 64.23s/it]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run mnsir9w4: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      " 38%|███▊      | 15/39 [16:59<27:11, 67.99s/it]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run caezqxkl: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      " 38%|███▊      | 15/39 [17:00<27:12, 68.01s/it]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run 9bnx2h2c: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run b3yudjvu from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run 212b4gek from 39 files.\n",
      "Downloading weights and gradients for run x6z4lrli from 39 files.\n",
      "Downloading weights and gradients for run sadqrmla from 39 files.\n",
      "Downloading weights and gradients for run ax404vzx from 39 files.\n",
      "Downloading weights and gradients for run sd9wjww5 from 39 files.\n",
      "Downloading weights and gradients for run g27q2tss from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/39 [01:01<?, ?it/s]A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run jwps1v5t: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run m422z3vf from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/39 [00:59<?, ?it/s]A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run 87l0osdc: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run 9l9le1kt from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/39 [01:00<?, ?it/s]A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run jj2hfnp5: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run b6d0la66 from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/39 [01:01<?, ?it/s]A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run rea2ecop: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run iuplie3o from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/39 [01:01<?, ?it/s]A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run nj65mr75: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run 2b42uurs from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/39 [01:03<?, ?it/s]A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run 25gx1w3a: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [01:01<?, ?it/s]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run za3l4ndu: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [01:04<?, ?it/s]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run jdk298zm: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run 9md45ih8 from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/39 [01:02<?, ?it/s]A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run j128w9iq: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run aq4f5ufl from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run k6vtbh3u from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/39 [01:02<?, ?it/s]A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run 8zhv3qw1: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [01:02<?, ?it/s]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run 2wy2ia3n: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run sreoadrb from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/39 [01:02<?, ?it/s]A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run wo169kgy: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run mr6dg0ea from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run oxiz8p6d from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/39 [01:03<?, ?it/s]A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run jmurb5ym: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run yb4bdgfa from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run 9b902mgv from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/39 [01:01<?, ?it/s]A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run qlrb1zsf: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [00:59<?, ?it/s]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run a9f92tnu: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run 1et8s67o from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/39 [01:01<?, ?it/s]A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run qbk2hhse: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run 6cs1i42o from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/39 [01:01<?, ?it/s]A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run c9q3pzhb: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run 00iof26x from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/39 [01:03<?, ?it/s]A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run nzy5e6xy: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [01:01<?, ?it/s]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run 4nod4jbc: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [00:59<?, ?it/s]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run y757jtj4: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights and gradients for run wvn16b5w from 39 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/39 [01:00<?, ?it/s]A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run n0vtz8bj: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [00:59<?, ?it/s]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run vd2erlx8: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [01:03<?, ?it/s]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run wuscm9fh: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [01:00<?, ?it/s]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run mrhp72xv: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [01:00<?, ?it/s]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run b3yudjvu: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [01:02<?, ?it/s]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run 212b4gek: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [01:02<?, ?it/s]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run x6z4lrli: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [01:03<?, ?it/s]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run sd9wjww5: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [01:04<?, ?it/s]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run ax404vzx: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [01:02<?, ?it/s]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run m422z3vf: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [01:05<?, ?it/s]\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run sadqrmla: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [01:05<?, ?it/s]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run g27q2tss: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [00:58<?, ?it/s]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run 9l9le1kt: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [00:55<?, ?it/s]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run b6d0la66: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [00:54<?, ?it/s]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run iuplie3o: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [00:48<?, ?it/s]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run 2b42uurs: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [01:35<?, ?it/s]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run b21vbwpp: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [00:44<?, ?it/s]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run aq4f5ufl: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [00:45<?, ?it/s]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run 9md45ih8: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [00:44<?, ?it/s]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run k6vtbh3u: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [00:48<?, ?it/s]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run sreoadrb: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [00:48<?, ?it/s]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run mr6dg0ea: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [00:49<?, ?it/s]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run oxiz8p6d: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [00:48<?, ?it/s]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run yb4bdgfa: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [00:48<?, ?it/s]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run 9b902mgv: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [00:43<?, ?it/s]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run 00iof26x: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [00:46<?, ?it/s]\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run 1et8s67o: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "  0%|          | 0/39 [00:41<?, ?it/s]\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\n",
      "  0%|          | 0/39 [00:45<?, ?it/s]\u001b[91m(gonas) [ERROR] An error occurred while fetching run wvn16b5w: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\n",
      "\u001b[91m(gonas) [ERROR] An error occurred while fetching run 6cs1i42o: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[91m(gonas) [ERROR] Failed to fetch a run due to: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 47.54 GiB total capacity; 44.63 GiB already allocated; 269.75 MiB free; 46.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
      "\u001b[92m(gonas) [INFO] Fetched 0 finished runs out of 81 total runs.\u001b[0m\n",
      "\u001b[92m(gonas) [INFO] Cached results for sweep w488d29q.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sweep_id = \"w488d29q\"\n",
    "\n",
    "# Get the runs from sweep.\n",
    "tables = [\"EvalResultsSummarytable\", \"EvalResultstable\"]\n",
    "wu.remove_sweep_results_cache(sweep_id)\n",
    "ngp_occ_blender_results = wu.fetch_sweep_results(\n",
    "    sweep_id, refresh_cache=True, download_weights_grads=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore spectral norm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [01:38,  2.54s/it]\n"
     ]
    }
   ],
   "source": [
    "run = wu.fetch_run(\"aq4f5ufl\")\n",
    "filter_fn = lambda x: x.name.endswith(\".pt\") and \"weights_grads\" in x.name\n",
    "run_weights_grads = wu.RunResult.download_weights_grads(run, filter_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000, 6500, 7000, 7500, 8000, 8500, 9000, 9500, 10000, 10500, 11000, 11500, 12000, 12500, 13000, 13500, 14000, 14500, 15000, 15500, 16000, 16500, 17000, 17500, 18000, 18500, 19000, 19500]\n",
      "defaultdict(<class 'dict'>, {'radiance_field': {1000: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([-3.9030e-02,  2.5807e-02, -1.2177e-07,  ...,  4.6400e-03,\n",
      "         2.3618e-02, -3.4991e-03], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-0.4147,  0.4121, -0.3420,  ..., -0.3262,  0.2138,  0.0370],\n",
      "        [ 0.6530, -0.3418,  0.4532,  ..., -0.0690,  0.2276,  0.2381],\n",
      "        [ 0.1035,  0.1366,  0.1412,  ...,  0.2177, -0.2514, -0.0034],\n",
      "        ...,\n",
      "        [ 0.0673,  0.2280, -0.0741,  ..., -0.2435,  0.2053,  0.1632],\n",
      "        [-0.0501,  0.3059,  0.0031,  ...,  0.1531, -0.1801, -0.0733],\n",
      "        [ 0.1162, -0.0365,  0.3182,  ...,  0.0754, -0.0662,  0.2582]],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 0.1189,  0.0094,  0.0922, -0.0412,  0.0747,  0.1042,  0.1229,  0.1410,\n",
      "         0.0983,  0.2325, -0.0034,  0.0160, -0.0543,  0.1246, -0.0495, -0.0293,\n",
      "        -0.0756,  0.1122,  0.0645,  0.1035, -0.0342,  0.4145, -0.0339,  0.1396,\n",
      "         0.1322, -0.0433, -0.0271,  0.0962, -0.0330,  0.1175,  0.1210, -0.0897,\n",
      "         0.0915,  0.0755,  0.0692, -0.0522, -0.0790, -0.0261,  0.0478,  0.0541,\n",
      "        -0.0922,  0.0903,  0.0572,  0.0648,  0.0721,  0.0808, -0.0467, -0.0361,\n",
      "         0.1205, -0.0692, -0.0272, -0.1010, -0.0414, -0.0279, -0.0453, -0.0518,\n",
      "        -0.0422, -0.0267, -0.0205,  0.0848, -0.1527,  0.0494,  0.0710,  0.0701],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-0.4997,  0.6072,  0.8343,  ..., -0.3447, -0.3471, -0.2857],\n",
      "        [-0.0520, -0.1139,  0.0377,  ...,  0.2169,  0.0831, -0.3425],\n",
      "        [ 0.2056, -0.3147,  0.0550,  ...,  0.1451,  0.2709, -0.0451],\n",
      "        ...,\n",
      "        [ 0.1570, -0.0600, -0.0538,  ..., -0.0307,  0.1848, -0.3445],\n",
      "        [ 0.2167,  0.1830,  0.0624,  ...,  0.1398,  0.2366,  0.1106],\n",
      "        [ 0.1132, -0.1867, -0.1014,  ...,  0.1407,  0.2824, -0.2039]],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([-0.0357,  0.1247,  0.1629, -0.0075, -0.0814,  0.2563,  0.0254,  0.0488,\n",
      "        -0.0454, -0.0068,  0.1656,  0.1723,  0.0668,  0.1447, -0.0126,  0.0822],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-1.4097e-01,  1.1793e-01, -3.9217e-01,  ...,  9.7817e-24,\n",
      "         7.6744e-24,  7.9908e-25], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[ 1.1981e-05, -1.0967e-05,  4.7684e-07,  ..., -4.1723e-07,\n",
      "         -1.1921e-07,  1.3113e-06],\n",
      "        [ 4.5662e-03, -4.1008e-03,  5.1003e-03,  ..., -2.9802e-06,\n",
      "         -6.3062e-05,  5.3763e-05],\n",
      "        [ 5.6076e-04, -2.3890e-04, -5.2261e-03,  ..., -1.7035e-04,\n",
      "         -6.7174e-05,  1.4830e-04],\n",
      "        ...,\n",
      "        [-1.3113e-06,  2.3246e-06,  5.9605e-07,  ..., -1.1921e-07,\n",
      "          5.9605e-08, -4.1723e-07],\n",
      "        [-3.6955e-06,  3.3379e-06,  5.9605e-08,  ..., -1.1921e-07,\n",
      "         -5.9605e-08,  5.9605e-07],\n",
      "        [ 3.0193e-03, -1.9007e-03,  2.7122e-03,  ...,  1.5080e-05,\n",
      "         -9.0599e-06,  1.9670e-06]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([-2.5332e-05,  2.8368e-02, -3.2986e-02,  8.5775e-02, -2.8481e-02,\n",
      "         2.1672e-03,  4.3279e-04,  1.2531e-01,  4.9591e-05, -3.7979e-03,\n",
      "        -7.6334e-02,  8.0585e-05,  2.2805e-03,  1.5223e-04,  7.2976e-02,\n",
      "        -2.2388e-02, -2.9087e-05,  8.3029e-05,  1.1528e-04,  2.8241e-04,\n",
      "        -1.1438e-02, -3.8257e-03, -7.7941e-03, -3.8251e-03, -6.3476e-03,\n",
      "        -5.4456e-03, -3.3267e-02,  4.4158e-03, -1.2134e-02,  5.0915e-02,\n",
      "         1.0657e-04,  3.1946e-02, -1.2687e-03,  7.5519e-05, -2.3842e-06,\n",
      "         3.2279e-03,  3.8499e-04, -2.7066e-04,  9.9480e-05,  3.6716e-05,\n",
      "         1.7065e-04,  5.5200e-04,  2.2411e-05, -3.6706e-03,  6.9499e-05,\n",
      "         1.3542e-04, -9.2459e-04, -5.4562e-04, -4.4584e-05,  1.2155e-03,\n",
      "        -7.1542e-03,  1.3113e-06, -3.3853e-03, -8.8638e-04, -2.3227e-03,\n",
      "         1.2008e-03, -7.8847e-03, -4.2603e-03, -6.2572e-03,  1.1255e-03,\n",
      "         1.0624e-02,  2.6405e-05,  1.2636e-05,  1.2465e-02], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[-3.3736e-05, -2.1973e-02, -1.9318e-02,  ..., -1.1921e-06,\n",
      "          3.9339e-06, -4.9973e-04],\n",
      "        [ 1.1921e-06, -3.6713e-02, -3.2715e-02,  ...,  1.7881e-07,\n",
      "         -7.1526e-07, -7.6199e-04],\n",
      "        [-4.7684e-06, -9.4360e-02, -9.6802e-02,  ...,  3.5763e-07,\n",
      "          1.4305e-06, -1.4763e-03],\n",
      "        ...,\n",
      "        [-5.9605e-06, -9.9304e-02, -1.0309e-01,  ...,  4.7684e-07,\n",
      "          1.3113e-06, -1.3428e-03],\n",
      "        [ 1.6689e-06,  1.0719e-02,  1.4282e-02,  ...,  2.3842e-07,\n",
      "          4.7684e-07, -6.5684e-05],\n",
      "        [-5.9605e-07,  3.1235e-02,  4.3732e-02,  ...,  2.3842e-07,\n",
      "         -1.1325e-06, -1.6451e-04]], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([-0.0198, -0.0171, -0.0446, -0.0233, -0.0172, -0.0381,  0.0063,  0.0138,\n",
      "         0.0027, -0.0433, -0.0365,  0.0033, -0.0257, -0.0479,  0.0050,  0.0152],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([-0.0045,  0.0019, -0.0011,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0')}}, 10000: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([ 5.4857e-41, -9.5524e-40, -2.0400e-04,  ...,  4.1046e-03,\n",
      "        -1.0953e-02,  3.6952e-03], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-0.5099, -0.1312, -0.2143,  ...,  0.1725,  0.1023, -0.0342],\n",
      "        [ 0.2701, -0.5719,  0.7371,  ...,  0.0366,  0.0324,  0.0260],\n",
      "        [ 0.4453,  0.3153, -0.2457,  ..., -0.1273,  0.0301, -0.0513],\n",
      "        ...,\n",
      "        [-0.0550,  0.0286, -0.0274,  ..., -0.0013,  0.0018, -0.0008],\n",
      "        [-0.1550,  0.0998, -0.1934,  ...,  0.0287,  0.0032, -0.0145],\n",
      "        [-0.2973, -0.0835, -0.2430,  ..., -0.1127,  0.2271,  0.0315]],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 8.8106e-01,  9.7334e-02,  3.5977e-01, -3.9883e-02,  4.7022e-01,\n",
      "         1.9953e-01,  5.2302e-01,  1.3326e-01,  5.3378e-01,  6.7733e-01,\n",
      "        -1.0595e-01,  3.8031e-01,  3.1923e-01, -7.3450e-03,  7.5428e-02,\n",
      "        -1.6081e-02,  1.8269e-01,  2.2016e-01,  7.4211e-02,  9.2515e-02,\n",
      "         3.4314e-01,  2.4665e-01,  1.0789e-01,  3.3275e-01, -7.8911e-01,\n",
      "         1.2811e-01,  4.0311e-01, -5.3466e-02,  2.1484e-01,  2.1527e-01,\n",
      "         1.6244e-01, -2.6053e-02, -8.2231e-02,  8.0448e-03,  3.4165e-02,\n",
      "        -6.5015e-02, -5.8421e-02, -1.0527e-01, -5.8577e-03, -7.4594e-02,\n",
      "        -1.1100e-01,  1.8212e-02, -1.2136e-01, -1.1577e-01,  3.6601e-02,\n",
      "        -2.3837e-02, -2.0736e-02,  3.5907e-02, -7.6684e-04, -2.1674e-01,\n",
      "         3.2937e-02, -7.2021e-02, -4.5079e-02,  9.0791e-02, -6.1092e-02,\n",
      "        -2.4908e-02, -1.4363e-01,  1.1880e-01, -3.6854e-01,  2.6173e-02,\n",
      "        -4.3471e-01,  1.8774e-02,  1.4312e-02, -1.1206e-01], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-2.7627e+00,  7.6238e-01,  1.1316e+00,  ..., -3.3680e-02,\n",
      "         -1.8083e-01, -4.4682e-01],\n",
      "        [ 5.4866e-01,  4.2675e-02, -3.9964e-02,  ..., -2.8539e-03,\n",
      "          1.9276e-03, -1.2993e-01],\n",
      "        [-2.5398e-01, -3.6375e-01,  2.0888e-01,  ..., -2.2938e-03,\n",
      "         -6.9458e-02, -1.4616e-01],\n",
      "        ...,\n",
      "        [ 6.5942e-01,  3.5890e-01,  3.4972e-02,  ..., -2.0038e-03,\n",
      "          1.9284e-02, -3.0958e-01],\n",
      "        [-5.4940e-01,  3.4000e-01, -6.1812e-02,  ...,  9.1952e-05,\n",
      "          5.9132e-02,  2.6434e-02],\n",
      "        [ 2.9566e-01, -3.6800e-01, -2.4994e-01,  ...,  4.9593e-05,\n",
      "          1.0140e-01,  5.0843e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([ 0.1896,  0.2082,  0.1037,  0.2424, -0.3709,  0.8180, -0.1748,  0.2827,\n",
      "        -0.0386,  0.1890,  0.2660,  0.4389,  0.2062,  0.5644, -0.2497,  0.2180],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-3.6986e-01,  4.2453e-01,  2.0903e-01,  ..., -1.4632e-39,\n",
      "         7.5838e-24, -9.5240e-11], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -4.1723e-07,\n",
      "        -0.0000e+00,  0.0000e+00], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[-3.2063e-03,  1.8272e-03, -1.5650e-03,  ...,  1.0884e-04,\n",
      "         -1.1754e-04, -3.1948e-05],\n",
      "        [ 9.8343e-03,  7.8354e-03,  7.4692e-03,  ...,  2.4939e-04,\n",
      "          1.1814e-04,  6.8247e-05],\n",
      "        [-4.4179e-04,  1.0118e-03,  3.4027e-03,  ..., -2.6131e-04,\n",
      "         -8.0645e-05, -2.7966e-04],\n",
      "        ...,\n",
      "        [ 2.7418e-06,  3.2783e-06,  2.0266e-06,  ...,  2.3842e-07,\n",
      "          0.0000e+00, -2.3842e-07],\n",
      "        [-1.1921e-07,  0.0000e+00, -1.7881e-07,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 5.0735e-04, -4.0412e-05, -3.0661e-04,  ...,  1.6928e-05,\n",
      "          2.5392e-05, -8.1658e-06]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([ 1.6499e-03,  3.2106e-02, -3.6097e-02,  3.3172e-02, -4.7418e-02,\n",
      "         4.6858e-02, -7.6268e-03,  3.1785e-02, -4.8530e-04, -4.5943e-04,\n",
      "        -3.5256e-03, -4.4330e-03,  4.2036e-02,  5.5082e-03,  2.4646e-03,\n",
      "        -4.3784e-02, -3.9374e-03, -1.1885e-03,  2.6865e-03,  1.9968e-05,\n",
      "         1.6122e-03, -6.0784e-03, -1.0568e-04, -1.6037e-03, -7.3889e-03,\n",
      "        -1.2512e-03, -1.1326e-02, -2.6953e-03,  3.8154e-03,  5.5653e-03,\n",
      "         8.2457e-04, -4.4262e-03,  3.7289e-04,  3.7432e-05, -2.2054e-06,\n",
      "         1.5742e-03, -1.5500e-03,  3.0220e-05,  2.3842e-07,  0.0000e+00,\n",
      "         0.0000e+00,  2.7418e-06,  1.9935e-03,  8.5109e-04, -4.7803e-05,\n",
      "        -6.6197e-04, -5.4044e-04, -1.0633e-03, -5.9605e-08, -7.8976e-05,\n",
      "         3.5107e-04,  0.0000e+00,  2.3782e-04, -1.3199e-03, -1.6046e-04,\n",
      "        -3.3021e-05, -4.0072e-04, -8.9711e-04, -1.9878e-04,  8.3447e-07,\n",
      "         3.6726e-03,  6.4373e-06,  1.3113e-06,  1.1724e-03], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[-9.9778e-05, -2.0659e-04, -2.5902e-03,  ..., -1.1921e-06,\n",
      "          0.0000e+00,  2.9981e-05],\n",
      "        [-2.1327e-04,  7.2861e-04,  1.2848e-02,  ...,  2.9802e-07,\n",
      "          0.0000e+00,  8.9645e-05],\n",
      "        [-9.2268e-05, -3.9001e-02, -5.5695e-02,  ...,  4.1723e-07,\n",
      "          0.0000e+00,  6.4373e-06],\n",
      "        ...,\n",
      "        [-1.3375e-04,  1.0719e-02,  2.9907e-02,  ..., -4.1723e-07,\n",
      "          0.0000e+00, -5.6982e-05],\n",
      "        [-3.3593e-04, -4.2755e-02, -5.2612e-02,  ..., -1.7881e-07,\n",
      "          0.0000e+00, -1.1146e-05],\n",
      "        [-1.2994e-04, -5.2948e-02, -6.7261e-02,  ..., -1.0729e-06,\n",
      "         -5.9605e-08, -1.2994e-05]], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([-0.0089,  0.0034, -0.0272, -0.0180, -0.0207, -0.0127, -0.0045,  0.0183,\n",
      "         0.0128, -0.0233, -0.0097,  0.0005, -0.0272,  0.0128, -0.0335, -0.0391],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([ 0.0019, -0.0002,  0.0012,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0')}}, 10500: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([ 3.3844e-10,  2.8725e-10,  2.0644e-03,  ..., -5.8674e-03,\n",
      "        -2.0746e-02,  5.3410e-02], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-5.0683e-01, -1.1000e-01, -2.0021e-01,  ...,  4.3443e-02,\n",
      "          4.1541e-02, -2.1251e-02],\n",
      "        [ 2.7327e-01, -5.8461e-01,  7.2026e-01,  ..., -5.1827e-02,\n",
      "          1.3408e-02,  5.6827e-02],\n",
      "        [ 4.4556e-01,  2.8989e-01, -2.4769e-01,  ..., -1.0085e-01,\n",
      "          8.5482e-02, -1.3662e-01],\n",
      "        ...,\n",
      "        [-4.1526e-02,  1.9183e-02, -2.2205e-02,  ...,  9.9119e-05,\n",
      "          2.4083e-04, -9.7542e-05],\n",
      "        [-1.3493e-01,  8.0659e-02, -1.5558e-01,  ...,  8.0376e-03,\n",
      "          4.0953e-04, -7.1719e-03],\n",
      "        [-2.9672e-01, -8.5788e-02, -2.0808e-01,  ..., -2.5739e-02,\n",
      "          5.8304e-02,  2.1500e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 9.3811e-01,  9.3805e-02,  3.5707e-01, -4.1158e-02,  4.6097e-01,\n",
      "         1.9834e-01,  5.4852e-01,  1.3488e-01,  5.5526e-01,  6.9980e-01,\n",
      "        -9.2502e-02,  3.9060e-01,  3.1110e-01,  2.8259e-02,  7.9369e-02,\n",
      "        -1.3029e-02,  2.1078e-01,  2.1695e-01,  8.7707e-02,  9.3376e-02,\n",
      "         3.5711e-01,  2.8653e-01,  1.1572e-01,  3.4970e-01, -7.6779e-01,\n",
      "         1.2704e-01,  4.3179e-01, -3.1903e-02,  2.4135e-01,  2.0969e-01,\n",
      "         1.8864e-01, -4.5166e-03, -1.0094e-01,  9.8039e-03,  3.5910e-02,\n",
      "        -5.6489e-02, -3.5240e-02, -9.8836e-02, -5.7767e-03, -7.2910e-02,\n",
      "        -1.0907e-01,  1.7848e-02, -9.7153e-02, -8.2995e-02,  3.5038e-02,\n",
      "        -1.6191e-02,  4.5581e-03,  5.2616e-02, -7.1502e-04, -1.8712e-01,\n",
      "         3.2407e-02, -6.9867e-02, -2.5006e-02,  1.2381e-01, -3.5505e-02,\n",
      "        -2.7694e-02, -1.1353e-01,  1.8316e-01, -3.4623e-01,  2.5548e-02,\n",
      "        -4.4639e-01,  1.7728e-02,  1.4187e-02, -1.0168e-01], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-2.8943e+00,  7.9457e-01,  1.1615e+00,  ..., -2.6863e-02,\n",
      "         -1.5866e-01, -4.7302e-01],\n",
      "        [ 5.2293e-01,  4.3005e-02, -4.3566e-02,  ..., -1.9473e-03,\n",
      "          8.2140e-04, -4.0818e-02],\n",
      "        [-2.8375e-01, -3.6834e-01,  2.1175e-01,  ..., -1.7273e-03,\n",
      "         -2.5452e-02, -1.6387e-01],\n",
      "        ...,\n",
      "        [ 6.7563e-01,  3.5673e-01,  3.0486e-02,  ..., -2.4828e-03,\n",
      "          7.5002e-03, -1.7075e-01],\n",
      "        [-5.2056e-01,  3.4556e-01, -6.2307e-02,  ..., -3.0188e-03,\n",
      "          2.3287e-02,  1.2098e-01],\n",
      "        [ 2.6714e-01, -3.7269e-01, -2.5397e-01,  ..., -5.5804e-04,\n",
      "          3.6655e-02,  5.6938e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([ 0.1768,  0.2097,  0.1053,  0.2459, -0.3657,  0.8139, -0.1766,  0.2688,\n",
      "        -0.0495,  0.1922,  0.2677,  0.4419,  0.2080,  0.5626, -0.2452,  0.2266],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-3.6601e-01,  4.2528e-01,  2.1454e-01,  ..., -4.2048e-39,\n",
      "         6.1716e-35, -3.7539e-22], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[ 2.8343e-03,  1.9197e-03,  1.2856e-03,  ...,  1.2636e-05,\n",
      "         -8.9407e-06,  9.8944e-05],\n",
      "        [ 1.0155e-02, -3.6278e-03,  4.3831e-03,  ...,  4.7922e-05,\n",
      "         -3.8981e-05,  3.4034e-05],\n",
      "        [ 7.1335e-03, -5.5199e-03,  1.1292e-02,  ..., -8.3447e-06,\n",
      "          2.4772e-04,  1.8144e-04],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([ 6.3221e-03,  2.0159e-02,  2.4265e-02, -4.9470e-02,  1.4551e-03,\n",
      "        -1.7884e-02,  5.5977e-03,  9.6202e-03, -7.7301e-04,  2.0856e-04,\n",
      "         4.4165e-03,  2.6459e-03, -8.1428e-03, -2.5516e-03, -3.4985e-03,\n",
      "         8.4985e-03, -1.0584e-03, -4.1127e-06,  3.5632e-04, -5.3644e-06,\n",
      "         8.5235e-04, -2.5079e-03,  6.0552e-04, -6.4415e-04,  2.3311e-03,\n",
      "        -2.7636e-03, -4.3284e-03, -4.0054e-04,  2.8299e-03,  8.1551e-04,\n",
      "        -7.1675e-04,  2.7568e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[ 1.2243e-04, -5.6915e-03, -1.6617e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 2.9469e-04,  2.1652e-02,  2.6566e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 7.7128e-05,  1.4328e-02,  1.2489e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 1.9729e-04,  1.3451e-02,  2.7802e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 2.0742e-05,  2.4048e-02,  2.2354e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-2.9063e-04, -3.9520e-03, -9.5596e-03,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([-0.0053,  0.0172,  0.0075, -0.0056,  0.0164, -0.0156, -0.0044, -0.0234,\n",
      "         0.0020,  0.0204, -0.0011, -0.0090, -0.0009,  0.0152,  0.0168, -0.0060],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([6.4135e-04, 2.5034e-06, 1.2627e-03,  ..., 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00], device='cuda:0')}}, 11000: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([-4.2375e-22,  4.4390e-22,  2.2796e-11,  ...,  1.0866e-02,\n",
      "        -2.0609e-02,  2.8568e-02], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-5.1482e-01, -1.1390e-01, -2.2172e-01,  ...,  4.3954e-02,\n",
      "          4.7861e-02, -1.1052e-02],\n",
      "        [ 2.7032e-01, -5.8036e-01,  7.0867e-01,  ..., -6.7123e-02,\n",
      "         -2.9285e-02,  4.3729e-03],\n",
      "        [ 4.3138e-01,  2.7624e-01, -2.5780e-01,  ..., -1.1212e-01,\n",
      "          1.7036e-01, -1.6132e-01],\n",
      "        ...,\n",
      "        [-3.0089e-02,  1.3052e-02, -1.9938e-02,  ..., -1.7348e-04,\n",
      "         -1.7526e-04,  2.2351e-04],\n",
      "        [-1.1274e-01,  6.1721e-02, -1.1767e-01,  ...,  1.5283e-03,\n",
      "          4.9897e-05, -2.8894e-03],\n",
      "        [-2.7602e-01, -7.5987e-02, -1.4941e-01,  ..., -7.5555e-03,\n",
      "         -6.0832e-03,  3.8989e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 9.4256e-01,  7.8999e-02,  3.3545e-01, -4.9243e-02,  4.3300e-01,\n",
      "         2.0128e-01,  5.4281e-01,  1.3553e-01,  5.5240e-01,  6.9405e-01,\n",
      "        -8.5988e-02,  3.9266e-01,  3.0538e-01,  3.6962e-02,  7.8937e-02,\n",
      "        -1.2403e-02,  2.1055e-01,  2.0704e-01,  7.4118e-02,  9.3994e-02,\n",
      "         3.4918e-01,  2.8455e-01,  1.1963e-01,  3.5262e-01, -7.2798e-01,\n",
      "         1.1309e-01,  4.1431e-01, -1.7792e-02,  2.4588e-01,  2.1931e-01,\n",
      "         1.7694e-01,  4.8377e-03, -9.4697e-02, -8.1280e-04,  4.0285e-02,\n",
      "        -3.6131e-02, -4.3624e-02, -8.4591e-02, -5.6917e-03, -7.0789e-02,\n",
      "        -1.0665e-01,  1.7353e-02, -9.1301e-02, -8.7639e-02,  3.4102e-02,\n",
      "        -2.1295e-02, -7.9248e-04,  4.0652e-02, -6.5445e-04, -1.6063e-01,\n",
      "         3.7329e-02, -6.7195e-02, -3.2279e-02,  1.6294e-01, -3.2477e-02,\n",
      "        -2.0597e-02, -9.4035e-02,  2.0348e-01, -3.1815e-01,  2.3830e-02,\n",
      "        -4.3593e-01,  1.6275e-02,  1.4132e-02, -9.2703e-02], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-3.0097e+00,  8.3685e-01,  1.2060e+00,  ..., -1.7924e-02,\n",
      "         -1.3416e-01, -5.3342e-01],\n",
      "        [ 5.6698e-01,  4.6451e-02, -4.4620e-02,  ..., -4.2652e-03,\n",
      "          2.8785e-04, -1.6003e-02],\n",
      "        [-3.1735e-01, -3.6856e-01,  2.1487e-01,  ..., -4.2262e-03,\n",
      "         -7.0166e-03, -1.3580e-01],\n",
      "        ...,\n",
      "        [ 6.9047e-01,  3.5732e-01,  2.4207e-02,  ..., -1.1817e-03,\n",
      "          2.2578e-03, -1.4838e-01],\n",
      "        [-4.9295e-01,  3.4816e-01, -6.3811e-02,  ..., -5.5269e-04,\n",
      "          6.9755e-03,  9.8463e-02],\n",
      "        [ 2.9950e-01, -3.8452e-01, -2.6047e-01,  ..., -5.8995e-04,\n",
      "          9.8758e-03,  8.4603e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([ 0.1431,  0.2152,  0.1098,  0.2446, -0.3705,  0.8166, -0.1691,  0.2538,\n",
      "        -0.0495,  0.1973,  0.2643,  0.4440,  0.2084,  0.5647, -0.2456,  0.2362],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-3.5709e-01,  4.2375e-01,  2.1853e-01,  ...,  6.5195e-39,\n",
      "         3.5645e-39, -5.1744e-34], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.9605e-08, 1.0133e-06,\n",
      "        4.7684e-07], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[-4.9553e-03, -3.8338e-04, -2.6588e-03,  ...,  5.2750e-05,\n",
      "          5.3167e-05,  4.2379e-05],\n",
      "        [ 3.7556e-03,  2.8496e-03, -6.1874e-03,  ...,  6.0141e-05,\n",
      "         -2.5392e-05, -4.1783e-05],\n",
      "        [-4.2152e-03,  3.7708e-03, -3.6278e-03,  ...,  5.9366e-05,\n",
      "          1.4305e-06,  1.3304e-04],\n",
      "        ...,\n",
      "        [ 1.4305e-06,  2.5630e-06, -1.9670e-06,  ...,  0.0000e+00,\n",
      "          0.0000e+00, -5.9605e-08],\n",
      "        [ 0.0000e+00, -5.9605e-08,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-4.1485e-05, -1.3375e-04,  7.8249e-04,  ..., -5.3644e-06,\n",
      "         -8.3447e-06, -1.1146e-05]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([-2.1175e-03, -8.8058e-03, -1.1380e-02,  1.9548e-02, -2.7610e-02,\n",
      "         2.5246e-02, -3.6149e-03,  1.6464e-02, -8.5950e-05,  2.5824e-03,\n",
      "        -8.0483e-03,  7.9203e-04, -9.6941e-03,  4.1054e-03,  1.4075e-02,\n",
      "         3.8400e-03,  1.5771e-03, -2.8521e-04,  1.7324e-03, -4.8876e-06,\n",
      "        -3.4114e-03, -4.9245e-04,  1.2335e-03, -3.9958e-03, -1.1379e-03,\n",
      "        -1.7078e-03,  2.6909e-03, -1.1091e-03, -3.1031e-03, -4.8867e-03,\n",
      "        -1.0952e-03, -8.1211e-04,  1.1758e-03,  2.2646e-03,  5.2541e-04,\n",
      "        -1.1176e-03, -4.9782e-04, -2.4056e-04,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -3.1590e-06,  1.2527e-03,  1.2567e-03, -8.9407e-06,\n",
      "        -4.1896e-04,  1.1730e-03, -1.6725e-04,  0.0000e+00,  2.7621e-04,\n",
      "         8.0919e-04,  0.0000e+00,  7.1490e-04, -4.2838e-04,  8.2493e-05,\n",
      "         1.4396e-03,  2.3805e-03, -2.3779e-03,  7.1186e-04,  2.2054e-06,\n",
      "        -6.3747e-04, -1.7524e-05,  1.7881e-07,  2.1699e-03], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[ 1.7703e-04, -6.8550e-03, -1.9035e-03,  ...,  2.3842e-07,\n",
      "         -1.1921e-07, -2.0182e-04],\n",
      "        [-1.6820e-04, -1.5602e-02, -1.5396e-02,  ...,  3.5763e-07,\n",
      "          0.0000e+00,  2.6405e-05],\n",
      "        [-1.0478e-04, -1.0704e-02, -1.6495e-02,  ...,  2.3842e-07,\n",
      "          0.0000e+00,  7.3791e-05],\n",
      "        ...,\n",
      "        [-3.7789e-05, -1.8188e-02, -2.1805e-02,  ...,  3.5763e-07,\n",
      "          0.0000e+00, -8.7023e-06],\n",
      "        [-2.8419e-04, -4.0932e-03,  5.1842e-03,  ...,  5.3644e-07,\n",
      "          0.0000e+00,  4.9889e-05],\n",
      "        [-1.1474e-04, -1.7212e-02, -2.2995e-02,  ..., -5.9605e-08,\n",
      "          0.0000e+00,  1.6034e-04]], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([-0.0055, -0.0126, -0.0089,  0.0063, -0.0063, -0.0043, -0.0012,  0.0153,\n",
      "         0.0011, -0.0030,  0.0012,  0.0095,  0.0025, -0.0138,  0.0002, -0.0140],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([-0.0012, -0.0003, -0.0012,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0')}}, 11500: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([-1.0899e-33, -5.1927e-33, -5.1163e-08,  ..., -4.2901e-03,\n",
      "         8.1653e-03, -1.7150e-03], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-5.3112e-01, -9.6942e-02, -2.2411e-01,  ...,  4.5578e-02,\n",
      "          1.3080e-01, -6.1313e-02],\n",
      "        [ 2.6148e-01, -5.8432e-01,  7.0682e-01,  ..., -2.9143e-02,\n",
      "         -4.6906e-02, -9.2900e-02],\n",
      "        [ 4.2046e-01,  2.7343e-01, -2.6277e-01,  ...,  2.4501e-03,\n",
      "          1.2876e-01, -1.5583e-01],\n",
      "        ...,\n",
      "        [-3.0632e-02,  9.4519e-03, -1.0120e-02,  ..., -3.0879e-04,\n",
      "          1.9661e-04,  4.4280e-04],\n",
      "        [-8.9268e-02,  4.3977e-02, -8.2202e-02,  ...,  1.3132e-04,\n",
      "          6.7210e-05, -9.3866e-04],\n",
      "        [-2.1433e-01, -5.7704e-02, -1.3308e-01,  ..., -8.0629e-02,\n",
      "          6.1869e-04,  2.7907e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 9.4386e-01,  6.6348e-02,  3.1444e-01, -5.6942e-02,  4.0420e-01,\n",
      "         2.0552e-01,  5.5533e-01,  1.3825e-01,  5.4944e-01,  6.5588e-01,\n",
      "        -8.2359e-02,  3.9419e-01,  3.0341e-01,  2.2796e-02,  8.7340e-02,\n",
      "        -1.8404e-02,  2.1372e-01,  2.0324e-01,  6.9586e-02,  9.2303e-02,\n",
      "         3.4294e-01,  2.7369e-01,  1.3845e-01,  3.4506e-01, -6.8424e-01,\n",
      "         1.0042e-01,  4.1523e-01, -1.1522e-02,  2.4145e-01,  2.1660e-01,\n",
      "         1.7276e-01,  1.5938e-02, -9.2026e-02, -2.4157e-02,  4.0956e-02,\n",
      "        -3.1929e-02, -4.6971e-02, -7.3744e-02, -5.5918e-03, -6.8156e-02,\n",
      "        -1.0362e-01,  1.6336e-02, -7.5111e-02, -6.8048e-02,  3.3356e-02,\n",
      "        -7.7212e-03,  3.6175e-02,  2.8316e-02, -5.8410e-04, -1.6702e-01,\n",
      "         3.7237e-02, -6.3911e-02, -3.3065e-02,  2.0489e-01, -2.1536e-02,\n",
      "        -3.0022e-02, -9.8597e-02,  2.2553e-01, -2.9984e-01,  1.8215e-02,\n",
      "        -4.1386e-01,  1.3585e-02,  1.4230e-02, -9.4357e-02], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-3.1293e+00,  8.7240e-01,  1.2432e+00,  ..., -6.1707e-03,\n",
      "         -1.0827e-01, -5.5570e-01],\n",
      "        [ 6.3348e-01,  4.9285e-02, -4.6425e-02,  ..., -5.2335e-03,\n",
      "          6.0650e-05, -1.1413e-02],\n",
      "        [-3.3203e-01, -3.7425e-01,  2.1624e-01,  ..., -2.9052e-03,\n",
      "         -1.3687e-03, -8.0888e-02],\n",
      "        ...,\n",
      "        [ 7.0802e-01,  3.6088e-01,  2.3694e-02,  ...,  1.2997e-03,\n",
      "          5.2001e-04, -1.6672e-01],\n",
      "        [-4.5661e-01,  3.4500e-01, -6.5765e-02,  ...,  1.7872e-03,\n",
      "          1.4928e-03,  7.7434e-02],\n",
      "        [ 2.7737e-01, -3.9070e-01, -2.6427e-01,  ...,  8.6087e-03,\n",
      "          1.8575e-03,  3.1006e-03]], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([ 0.1114,  0.2150,  0.1091,  0.2445, -0.3715,  0.8178, -0.1663,  0.2389,\n",
      "        -0.0501,  0.1987,  0.2615,  0.4458,  0.2086,  0.5672, -0.2449,  0.2428],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-3.5470e-01,  4.2598e-01,  2.0674e-01,  ..., -3.1546e-39,\n",
      "        -5.8779e-39,  7.7111e-39], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -8.9407e-07,\n",
      "        -2.3842e-07, -2.3842e-07], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[-2.7256e-03,  2.9106e-03, -2.6455e-03,  ..., -4.9472e-05,\n",
      "         -5.7280e-05, -1.7881e-07],\n",
      "        [ 1.7059e-02, -8.4229e-03, -2.4948e-03,  ..., -1.9252e-05,\n",
      "          1.1927e-04,  1.9073e-05],\n",
      "        [-8.5754e-03,  2.7351e-03,  1.8716e-04,  ..., -6.4254e-05,\n",
      "          5.3048e-06,  1.1027e-04],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  5.9605e-08,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 8.3447e-07, -1.1921e-07,  1.1921e-07,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 1.3268e-04, -9.8991e-04,  6.0463e-04,  ..., -4.8280e-06,\n",
      "          7.8678e-06, -8.8215e-06]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([-7.8043e-03,  2.6595e-02, -1.2271e-02,  7.4933e-02, -4.8166e-02,\n",
      "         2.8860e-02,  1.3804e-03,  3.1565e-03,  1.1808e-03, -3.2629e-03,\n",
      "         1.4263e-02,  2.4937e-03,  5.4191e-03, -7.3946e-04,  5.8035e-03,\n",
      "        -1.4452e-02, -4.5387e-03, -6.2120e-04, -2.0462e-03,  2.5034e-05,\n",
      "        -3.9924e-03, -1.3966e-02,  1.2138e-03,  9.5968e-03,  2.4587e-03,\n",
      "        -1.3057e-03,  3.2060e-03,  2.5754e-03, -2.7134e-03, -6.5686e-03,\n",
      "         1.6889e-03, -1.9516e-03,  3.0977e-03,  4.8959e-04, -2.8729e-04,\n",
      "         5.1248e-04, -1.6879e-03, -9.4426e-04,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -5.0068e-06, -7.7033e-04,  1.5488e-03, -4.3511e-06,\n",
      "         4.2301e-04, -4.8153e-03, -1.6989e-03,  0.0000e+00,  3.2157e-04,\n",
      "        -1.5893e-03,  0.0000e+00,  7.4804e-04,  1.2381e-03,  3.3331e-03,\n",
      "        -8.3208e-05, -1.3678e-03, -1.9246e-04, -1.6087e-04, -1.1921e-06,\n",
      "         1.5060e-03, -7.7486e-07, -1.8477e-06,  7.1555e-04], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[-2.5558e-04, -2.3346e-03,  9.6207e-03,  ..., -1.7881e-07,\n",
      "          5.9605e-08,  2.7418e-04],\n",
      "        [ 5.8413e-06, -2.9190e-02, -4.2633e-02,  ...,  5.9605e-08,\n",
      "          0.0000e+00, -1.4508e-04],\n",
      "        [-2.4557e-04, -3.2867e-02, -4.4586e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00, -1.6212e-04],\n",
      "        ...,\n",
      "        [-2.3854e-04, -6.0883e-03, -6.7139e-03,  ...,  5.9605e-08,\n",
      "          0.0000e+00, -1.0014e-04],\n",
      "        [ 2.1768e-04, -4.0070e-02, -4.3579e-02,  ...,  0.0000e+00,\n",
      "          5.9605e-08, -1.3304e-04],\n",
      "        [-6.2418e-04, -4.3793e-02, -4.8492e-02,  ...,  0.0000e+00,\n",
      "         -5.9605e-08,  8.5235e-06]], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([ 0.0030, -0.0260, -0.0289, -0.0016, -0.0307, -0.0182, -0.0063,  0.0110,\n",
      "        -0.0052, -0.0136, -0.0043,  0.0139, -0.0151, -0.0065, -0.0271, -0.0343],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([-1.6904e-04, -7.9489e-04,  9.1493e-05,  ...,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0')}}, 12000: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([ 5.2229e-40, -1.0373e-39,  3.1874e-18,  ..., -2.5066e-03,\n",
      "         9.7600e-03, -4.0950e-03], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-5.4905e-01, -1.0138e-01, -2.3946e-01,  ...,  2.2064e-03,\n",
      "          8.3227e-02, -1.9010e-02],\n",
      "        [ 2.6460e-01, -5.8696e-01,  7.0805e-01,  ...,  1.5595e-02,\n",
      "         -1.1157e-01, -1.2106e-01],\n",
      "        [ 4.0800e-01,  2.6921e-01, -2.6470e-01,  ..., -2.3654e-02,\n",
      "          1.9528e-01, -1.6920e-01],\n",
      "        ...,\n",
      "        [-5.8266e-02,  7.7619e-02, -5.1807e-02,  ...,  5.4923e-03,\n",
      "         -1.1135e-03,  4.8156e-05],\n",
      "        [-6.4893e-02,  2.7109e-02, -5.1316e-02,  ...,  4.8345e-05,\n",
      "          1.2035e-04, -1.7509e-04],\n",
      "        [-1.9373e-01, -5.5811e-02, -1.3516e-01,  ..., -1.4929e-02,\n",
      "         -2.3262e-02,  8.0176e-03]], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 9.3547e-01,  5.8715e-02,  3.0012e-01, -6.4001e-02,  3.8645e-01,\n",
      "         2.1087e-01,  5.5497e-01,  1.3986e-01,  5.4147e-01,  6.2855e-01,\n",
      "        -7.1260e-02,  3.9317e-01,  3.0003e-01,  2.2240e-02,  8.7410e-02,\n",
      "        -1.4596e-02,  2.1747e-01,  1.8722e-01,  6.8569e-02,  8.0659e-02,\n",
      "         3.3617e-01,  2.7065e-01,  1.5368e-01,  3.3149e-01, -6.5450e-01,\n",
      "         9.0897e-02,  4.0686e-01, -9.2413e-04,  2.5605e-01,  2.2165e-01,\n",
      "         1.5376e-01,  2.1348e-02, -9.9366e-02, -5.7960e-02,  3.8344e-02,\n",
      "        -1.1137e-02, -4.1297e-02, -6.5395e-02, -5.4601e-03, -6.4918e-02,\n",
      "        -9.9845e-02,  1.2540e-02, -7.9083e-02, -7.6217e-02,  2.9038e-02,\n",
      "        -7.4967e-03,  3.9063e-02,  4.2382e-02, -5.0468e-04, -1.6357e-01,\n",
      "         5.5455e-02, -5.9928e-02, -4.2709e-02,  2.1618e-01, -4.1517e-02,\n",
      "        -1.3886e-02, -8.4295e-02,  2.3697e-01, -2.9350e-01,  1.6445e-02,\n",
      "        -4.0245e-01, -5.1116e-05,  1.4187e-02, -1.0536e-01], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-3.2124e+00,  9.0521e-01,  1.2760e+00,  ..., -4.9348e-02,\n",
      "         -8.2316e-02, -5.4383e-01],\n",
      "        [ 6.4610e-01,  4.8786e-02, -4.7859e-02,  ..., -6.3875e-02,\n",
      "         -3.9666e-04, -5.3718e-03],\n",
      "        [-3.5015e-01, -3.7643e-01,  2.2137e-01,  ..., -4.1138e-02,\n",
      "         -1.9858e-03, -1.5414e-01],\n",
      "        ...,\n",
      "        [ 7.3644e-01,  3.6167e-01,  2.3436e-02,  ...,  7.3057e-02,\n",
      "          1.1946e-03, -1.4189e-01],\n",
      "        [-4.5246e-01,  3.4629e-01, -6.4439e-02,  ..., -9.2983e-02,\n",
      "         -1.4732e-04,  1.0005e-01],\n",
      "        [ 3.0160e-01, -3.9616e-01, -2.6637e-01,  ...,  9.0063e-02,\n",
      "          9.1358e-05,  7.5947e-03]], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([ 0.0866,  0.2194,  0.1113,  0.2453, -0.3718,  0.8204, -0.1639,  0.2262,\n",
      "        -0.0508,  0.2028,  0.2579,  0.4478,  0.2097,  0.5708, -0.2451,  0.2478],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-3.5489e-01,  4.5579e-01,  1.9446e-01,  ...,  9.1827e-40,\n",
      "        -3.0635e-39,  9.8643e-39], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -7.1526e-07,\n",
      "        -5.9605e-08, -1.7881e-07], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[ 1.8251e-04,  5.3406e-03, -5.7507e-04,  ...,  1.1921e-07,\n",
      "          3.4392e-05, -1.5497e-05],\n",
      "        [ 6.4964e-03, -2.8496e-03,  6.3667e-03,  ..., -2.7966e-04,\n",
      "         -1.1158e-04,  1.7285e-06],\n",
      "        [-6.9761e-04, -2.5196e-03, -3.4409e-03,  ...,  1.8954e-04,\n",
      "         -1.7619e-04,  2.8551e-05],\n",
      "        ...,\n",
      "        [-1.4305e-06, -5.9605e-08,  4.7088e-06,  ...,  0.0000e+00,\n",
      "          2.3842e-07, -5.9605e-08],\n",
      "        [ 5.9605e-08, -1.7881e-07,  1.1921e-07,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-6.6376e-04,  4.7159e-04,  2.7370e-04,  ...,  1.5914e-05,\n",
      "         -1.0014e-05, -1.6749e-05]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([-5.7729e-03,  1.5956e-02, -1.2886e-02, -4.4333e-02,  1.5753e-02,\n",
      "        -1.3875e-02, -3.9560e-04,  1.4702e-02, -1.8536e-03, -8.1617e-04,\n",
      "         2.9787e-03,  2.2429e-03, -1.8243e-02,  9.7489e-04,  2.0773e-03,\n",
      "         8.0109e-03, -4.5352e-03, -2.9278e-04,  2.6236e-03, -3.0935e-05,\n",
      "        -3.0516e-03, -6.2205e-03,  2.6660e-03, -3.1529e-03,  4.4405e-03,\n",
      "        -2.8170e-03, -7.9036e-05, -1.6159e-03,  1.1268e-03,  1.9687e-04,\n",
      "        -1.3046e-03,  5.2643e-03, -3.3975e-04, -1.3828e-04,  2.7740e-04,\n",
      "        -1.6417e-03, -2.5644e-03, -2.7245e-04,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -1.1027e-05, -2.5370e-03, -3.9172e-04, -1.4186e-05,\n",
      "         1.4607e-03, -1.7121e-03, -1.2641e-03,  0.0000e+00, -1.1581e-04,\n",
      "        -8.6653e-04,  0.0000e+00, -1.6019e-03,  8.2541e-04, -2.6469e-03,\n",
      "         4.4155e-04,  6.1989e-06,  2.8265e-03, -7.8142e-04, -4.5300e-06,\n",
      "         7.2104e-04, -2.1458e-06, -2.2054e-06, -1.1244e-03], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[ 2.2602e-04, -1.1078e-02, -1.5480e-02,  ...,  0.0000e+00,\n",
      "          1.1921e-07, -2.0766e-04],\n",
      "        [ 2.6524e-05,  1.1032e-02,  2.2873e-02,  ..., -3.5763e-07,\n",
      "          0.0000e+00,  1.3041e-04],\n",
      "        [-1.2136e-04,  6.1455e-03,  1.5915e-02,  ..., -2.3842e-07,\n",
      "          0.0000e+00,  1.1718e-04],\n",
      "        ...,\n",
      "        [ 2.0742e-04,  9.8724e-03,  8.6594e-03,  ..., -2.3842e-07,\n",
      "         -5.9605e-08,  1.0240e-04],\n",
      "        [ 2.5582e-04,  3.2196e-02,  4.6539e-02,  ...,  7.7486e-07,\n",
      "          0.0000e+00,  3.0816e-05],\n",
      "        [ 1.3316e-04,  5.9853e-03,  2.0187e-02,  ..., -5.3644e-07,\n",
      "         -5.9605e-08, -2.9802e-07]], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([-0.0036,  0.0131,  0.0051, -0.0100,  0.0022,  0.0003, -0.0028, -0.0006,\n",
      "        -0.0041,  0.0005, -0.0057, -0.0107,  0.0091,  0.0081,  0.0309,  0.0088],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([-4.0650e-05,  3.0613e-04,  6.9380e-04,  ...,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0')}}, 12500: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([-4.0667e-40, -5.5716e-40, -5.3806e-31,  ..., -3.8382e-03,\n",
      "        -5.2784e-02, -3.2841e-02], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-5.4839e-01, -1.0001e-01, -2.4672e-01,  ..., -2.8326e-02,\n",
      "          1.6474e-02, -1.0488e-01],\n",
      "        [ 2.5793e-01, -5.8763e-01,  7.0032e-01,  ...,  4.6224e-02,\n",
      "         -1.0766e-01, -1.0947e-01],\n",
      "        [ 3.9975e-01,  2.6858e-01, -2.6095e-01,  ..., -1.0226e-01,\n",
      "          1.6200e-01, -2.0742e-01],\n",
      "        ...,\n",
      "        [-3.8942e-02,  4.3277e-02, -3.3609e-02,  ...,  2.5170e-05,\n",
      "          6.5681e-06, -2.9570e-05],\n",
      "        [-3.9686e-02,  1.6596e-02, -2.6244e-02,  ...,  3.9657e-04,\n",
      "          4.0179e-04, -3.3347e-04],\n",
      "        [-2.1427e-01, -4.8397e-02, -1.0724e-01,  ..., -1.9827e-02,\n",
      "          5.9727e-02,  2.9958e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 9.2552e-01,  5.1546e-02,  2.8920e-01, -7.0828e-02,  3.7017e-01,\n",
      "         2.1805e-01,  5.5193e-01,  1.3936e-01,  5.3196e-01,  6.0349e-01,\n",
      "        -6.3985e-02,  3.8873e-01,  3.0386e-01,  4.7157e-04,  8.7249e-02,\n",
      "        -1.6447e-02,  2.1943e-01,  1.8022e-01,  7.0578e-02,  6.7645e-02,\n",
      "         3.2458e-01,  2.5932e-01,  1.6334e-01,  3.1950e-01, -6.2789e-01,\n",
      "         8.5705e-02,  4.1107e-01,  1.1620e-02,  2.5609e-01,  2.1516e-01,\n",
      "         1.3974e-01,  1.6032e-02, -1.0863e-01, -5.5785e-02,  2.6747e-02,\n",
      "         1.9353e-05, -6.4003e-02, -6.3359e-02, -5.2984e-03, -6.0982e-02,\n",
      "        -9.5204e-02,  9.3453e-03, -8.0572e-02, -6.5007e-02,  2.5000e-02,\n",
      "        -9.5478e-03,  4.7876e-02,  4.8094e-02, -4.1826e-04, -1.6266e-01,\n",
      "         5.8774e-02, -5.5173e-02, -2.7057e-02,  2.1397e-01, -2.3293e-02,\n",
      "         8.6003e-03, -5.1696e-02,  2.4329e-01, -2.7402e-01,  1.2893e-02,\n",
      "        -3.8982e-01, -3.6894e-04,  1.2218e-02, -1.1262e-01], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-3.3163e+00,  9.3295e-01,  1.3084e+00,  ..., -3.1527e-02,\n",
      "         -5.7718e-02, -5.8366e-01],\n",
      "        [ 6.8667e-01,  4.9227e-02, -5.0643e-02,  ..., -1.5935e-02,\n",
      "          2.5047e-04,  5.9260e-02],\n",
      "        [-3.8596e-01, -3.7750e-01,  2.2153e-01,  ..., -8.1437e-03,\n",
      "         -5.4740e-04, -1.5016e-01],\n",
      "        ...,\n",
      "        [ 7.5193e-01,  3.6683e-01,  2.3219e-02,  ...,  3.7987e-02,\n",
      "          1.8010e-04, -1.0610e-01],\n",
      "        [-4.4557e-01,  3.4239e-01, -6.7704e-02,  ..., -4.0963e-02,\n",
      "         -7.3763e-04,  1.0578e-01],\n",
      "        [ 3.0581e-01, -3.9832e-01, -2.6826e-01,  ...,  2.8753e-02,\n",
      "          2.8310e-04, -7.4768e-03]], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([ 0.0627,  0.2219,  0.1128,  0.2456, -0.3692,  0.8226, -0.1640,  0.2146,\n",
      "        -0.0426,  0.2080,  0.2590,  0.4453,  0.2078,  0.5787, -0.2475,  0.2530],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-3.4780e-01,  4.8056e-01,  1.7382e-01,  ...,  1.1176e-06,\n",
      "        -1.5230e-17,  4.4718e-17], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  5.9605e-08,\n",
      "         4.8280e-06, -9.0599e-06], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[-2.2068e-03, -6.6566e-04,  4.2381e-03,  ...,  4.2856e-05,\n",
      "          4.4405e-05, -1.1444e-05],\n",
      "        [-8.6136e-03, -3.4924e-03, -1.4664e-02,  ...,  1.1325e-06,\n",
      "         -9.1195e-06,  2.7418e-05],\n",
      "        [ 1.2970e-02, -2.9716e-03,  6.3934e-03,  ..., -4.5121e-05,\n",
      "          8.4877e-05, -1.9372e-05],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-7.7486e-07,  5.9605e-08, -2.3842e-07,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-7.3576e-04,  9.5320e-04,  3.6526e-04,  ..., -1.5199e-05,\n",
      "          2.3842e-06,  1.9670e-06]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([-2.6950e-03, -3.2996e-02,  2.3591e-02, -7.8469e-02,  2.6411e-02,\n",
      "        -5.4468e-02,  8.9645e-05, -9.6836e-02,  1.6749e-03,  4.9796e-03,\n",
      "         2.5167e-02, -3.3498e-03,  3.8039e-02, -4.8888e-03, -1.7102e-02,\n",
      "        -2.6007e-02,  2.9802e-04,  1.7029e-04, -1.5783e-04, -6.8367e-05,\n",
      "        -2.3981e-03,  9.2232e-04,  2.8461e-03, -5.1428e-03, -8.5803e-03,\n",
      "        -5.3249e-03,  1.8450e-02,  3.5553e-03,  5.7876e-05, -3.4806e-03,\n",
      "        -1.7709e-03, -5.3434e-03,  1.5923e-03,  1.5318e-04, -1.3894e-04,\n",
      "        -2.4626e-03,  2.3152e-03,  1.1308e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -6.5565e-07,  6.5827e-04,  1.3913e-03,  1.7762e-05,\n",
      "         9.2351e-04,  6.9612e-04,  1.6392e-03,  0.0000e+00, -1.5396e-04,\n",
      "         2.3657e-04,  0.0000e+00,  6.7514e-04, -6.0436e-03, -2.5886e-03,\n",
      "        -9.3842e-04,  1.1992e-02, -3.1163e-03,  1.2833e-03,  9.5367e-07,\n",
      "        -3.6236e-03,  0.0000e+00,  1.7285e-06, -1.1027e-03], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[ 1.9777e-04,  9.4528e-03,  9.6054e-03,  ...,  0.0000e+00,\n",
      "         -1.7881e-07, -4.9770e-05],\n",
      "        [-3.2759e-04,  1.2611e-02,  2.0233e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  2.7919e-04],\n",
      "        [ 8.3387e-05,  3.9825e-02,  5.0049e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  3.3855e-04],\n",
      "        ...,\n",
      "        [ 3.3092e-04,  5.1117e-02,  5.1025e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  1.9407e-04],\n",
      "        [-3.9673e-04, -1.4694e-02, -9.8419e-03,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  1.8203e-04],\n",
      "        [ 2.0969e-04,  3.4454e-02,  4.9805e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  2.1625e-04]], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([ 0.0083,  0.0123,  0.0304,  0.0184, -0.0100,  0.0621, -0.0092,  0.0036,\n",
      "        -0.0025,  0.0310,  0.0121, -0.0177,  0.0649,  0.0402, -0.0103,  0.0289],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([-1.3485e-03,  3.1233e-05, -1.0643e-03,  ...,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0')}}, 13000: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([-1.4631e-09,  1.6896e-39,  1.3916e-08,  ..., -1.4447e-03,\n",
      "         6.7929e-03, -6.7938e-02], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-5.5069e-01, -1.1402e-01, -2.5791e-01,  ..., -8.9391e-02,\n",
      "         -4.3924e-03, -9.0962e-02],\n",
      "        [ 2.5571e-01, -5.8991e-01,  7.0380e-01,  ...,  2.5851e-02,\n",
      "         -8.9576e-02, -8.8514e-02],\n",
      "        [ 3.9075e-01,  2.6868e-01, -2.6326e-01,  ..., -3.6589e-02,\n",
      "          1.7232e-01, -1.0973e-01],\n",
      "        ...,\n",
      "        [-2.2931e-02,  1.9939e-02, -1.9059e-02,  ...,  1.8925e-08,\n",
      "          3.7903e-10, -3.2874e-07],\n",
      "        [-2.6983e-02,  8.0027e-03, -2.2120e-02,  ...,  2.8266e-04,\n",
      "          3.7011e-05, -6.0153e-04],\n",
      "        [-1.8527e-01, -5.8488e-02, -1.1073e-01,  ...,  6.6079e-02,\n",
      "          1.8670e-02,  3.4986e-03]], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 9.1469e-01,  5.1052e-02,  2.8212e-01, -7.7198e-02,  3.6481e-01,\n",
      "         2.1937e-01,  5.4930e-01,  1.4107e-01,  5.4316e-01,  5.8389e-01,\n",
      "        -5.3786e-02,  3.8686e-01,  3.0407e-01, -1.1103e-03,  9.2848e-02,\n",
      "        -1.3494e-02,  2.2455e-01,  1.5806e-01,  6.4883e-02,  2.4063e-02,\n",
      "         3.1625e-01,  2.4864e-01,  1.6690e-01,  3.1061e-01, -6.0584e-01,\n",
      "         8.4559e-02,  3.9171e-01, -2.9387e-03,  2.4894e-01,  2.1428e-01,\n",
      "         1.3061e-01,  2.0292e-02, -1.0755e-01, -7.5964e-02,  1.9474e-02,\n",
      "         7.2376e-03, -6.7911e-02, -7.8331e-02, -5.0977e-03, -5.6275e-02,\n",
      "        -8.9557e-02,  5.6557e-04, -7.0945e-02, -6.9067e-02,  1.6559e-02,\n",
      "        -2.0933e-02,  5.3057e-02,  4.4647e-02, -3.2854e-04, -1.6901e-01,\n",
      "         5.3471e-02, -4.9614e-02, -3.1224e-02,  2.1215e-01, -2.5523e-02,\n",
      "        -1.2569e-04, -6.8957e-02,  2.3097e-01, -2.5865e-01,  9.4900e-03,\n",
      "        -3.6271e-01, -3.6754e-04,  9.5942e-03, -1.0697e-01], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-3.3739e+00,  9.5300e-01,  1.3299e+00,  ..., -1.7932e-02,\n",
      "         -3.6278e-02, -6.0949e-01],\n",
      "        [ 7.0924e-01,  4.9660e-02, -4.7378e-02,  ..., -2.6298e-03,\n",
      "         -2.9364e-04,  8.6973e-02],\n",
      "        [-3.7377e-01, -3.7886e-01,  2.2477e-01,  ..., -1.0006e-03,\n",
      "         -4.2959e-03, -1.9085e-01],\n",
      "        ...,\n",
      "        [ 7.5811e-01,  3.6663e-01,  2.1609e-02,  ...,  1.6348e-02,\n",
      "          1.4966e-03, -5.4690e-02],\n",
      "        [-4.7781e-01,  3.4497e-01, -6.6449e-02,  ..., -1.4129e-02,\n",
      "          1.9085e-03,  1.7803e-01],\n",
      "        [ 3.0370e-01, -4.0464e-01, -2.7347e-01,  ...,  6.6097e-03,\n",
      "          5.0342e-03,  2.7287e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([ 0.0503,  0.2257,  0.1156,  0.2404, -0.3660,  0.8211, -0.1611,  0.2048,\n",
      "        -0.0471,  0.2065,  0.2593,  0.4451,  0.2086,  0.5816, -0.2446,  0.2559],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-3.4552e-01,  4.8077e-01,  1.7377e-01,  ..., -3.4082e-18,\n",
      "        -9.3042e-14,  2.8265e-14], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[-6.0806e-03,  4.3068e-03, -3.4676e-03,  ..., -1.3518e-04,\n",
      "          1.7047e-05, -5.4002e-05],\n",
      "        [-2.3407e-02,  6.7940e-03, -1.0658e-02,  ..., -6.4969e-05,\n",
      "          1.4639e-04, -2.5415e-04],\n",
      "        [-5.6534e-03,  4.4479e-03, -1.6937e-02,  ..., -2.0742e-04,\n",
      "          4.1723e-07, -6.2585e-05],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([-4.7980e-03, -8.7230e-02, -4.2161e-02, -1.1510e-01, -3.9257e-02,\n",
      "         4.8616e-02,  5.1737e-03, -7.4824e-02,  1.9349e-03,  6.2258e-03,\n",
      "         3.9201e-03, -2.4272e-02,  2.6868e-02,  1.4168e-02, -1.8857e-02,\n",
      "        -2.2448e-02, -2.4545e-03, -1.8674e-04,  5.2965e-03, -5.9605e-08,\n",
      "        -3.2620e-03,  2.0555e-02, -2.4334e-03, -1.4975e-02,  2.5307e-02,\n",
      "        -3.9613e-03, -1.4293e-02,  7.9088e-03, -8.8644e-04,  6.2031e-03,\n",
      "        -3.5257e-03, -2.4455e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[ 0.0009, -0.0460, -0.0573,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0004,  0.0236,  0.0335,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0004,  0.0471,  0.0692,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0005,  0.0269,  0.0211,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0004, -0.0167, -0.0172,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0001, -0.0062, -0.0080,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([-0.0389,  0.0249,  0.0458,  0.0091,  0.0184,  0.0374,  0.0087,  0.0056,\n",
      "         0.0097,  0.0045,  0.0351,  0.0092,  0.0669,  0.0245, -0.0138, -0.0076],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([ 0.0001, -0.0003,  0.0006,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0')}}, 13500: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([-1.0576e-20,  1.9473e-40,  9.7409e-20,  ..., -1.6808e-02,\n",
      "         2.3697e-03, -1.6171e-02], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-5.5545e-01, -1.0937e-01, -2.6399e-01,  ..., -4.0845e-02,\n",
      "         -2.7187e-02,  4.7570e-03],\n",
      "        [ 2.5900e-01, -5.9254e-01,  7.0426e-01,  ..., -1.1128e-02,\n",
      "         -2.2006e-02, -9.6493e-02],\n",
      "        [ 3.8534e-01,  2.6948e-01, -2.6389e-01,  ..., -8.9538e-03,\n",
      "          1.9515e-01, -1.2009e-01],\n",
      "        ...,\n",
      "        [-1.1584e-02,  7.3554e-03, -9.1863e-03,  ...,  1.0492e-12,\n",
      "          3.5921e-16, -8.4928e-10],\n",
      "        [-1.8776e-02,  7.1926e-03, -1.8741e-02,  ...,  6.0519e-05,\n",
      "         -1.7466e-04,  2.4207e-04],\n",
      "        [-1.9524e-01, -7.0448e-02, -9.1823e-02,  ..., -5.4222e-02,\n",
      "         -3.8769e-02,  2.7350e-03]], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 9.0214e-01,  4.9486e-02,  2.7799e-01, -8.0362e-02,  3.6285e-01,\n",
      "         2.1793e-01,  5.3412e-01,  1.3984e-01,  5.4673e-01,  5.6076e-01,\n",
      "        -4.8914e-02,  3.7980e-01,  3.1046e-01, -1.0020e-02,  9.5921e-02,\n",
      "        -1.4895e-02,  2.2597e-01,  1.4810e-01,  5.6386e-02,  2.3603e-02,\n",
      "         3.1721e-01,  2.5205e-01,  1.7183e-01,  3.0452e-01, -5.9247e-01,\n",
      "         8.8754e-02,  3.9730e-01, -5.3642e-03,  2.4485e-01,  2.1427e-01,\n",
      "         1.2065e-01,  1.4303e-02, -1.1158e-01, -8.4804e-02,  1.9276e-03,\n",
      "         2.1191e-02, -5.7659e-02, -5.8158e-02, -4.8511e-03, -5.0756e-02,\n",
      "        -8.2791e-02,  2.1743e-04, -6.4207e-02, -7.4690e-02,  1.3951e-02,\n",
      "        -1.0901e-02,  6.1780e-02,  6.6285e-02, -2.4085e-04, -1.7209e-01,\n",
      "         5.9663e-02, -4.3285e-02, -3.9413e-02,  2.2068e-01, -2.6691e-02,\n",
      "         8.1239e-03, -6.4410e-02,  2.3010e-01, -2.2921e-01, -3.9325e-02,\n",
      "        -3.5450e-01, -3.5102e-04,  6.9151e-03, -1.1502e-01], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-3.4208e+00,  9.7185e-01,  1.3472e+00,  ..., -8.6687e-03,\n",
      "         -1.7842e-02, -6.3289e-01],\n",
      "        [ 7.1690e-01,  5.0594e-02, -5.3490e-02,  ..., -2.5375e-04,\n",
      "         -4.1736e-05,  2.3668e-02],\n",
      "        [-3.9871e-01, -3.8359e-01,  2.2298e-01,  ..., -6.5493e-05,\n",
      "          8.6885e-05, -2.4158e-01],\n",
      "        ...,\n",
      "        [ 7.7922e-01,  3.6400e-01,  1.9188e-02,  ...,  5.5081e-03,\n",
      "         -1.0880e-03, -1.1631e-01],\n",
      "        [-4.5246e-01,  3.4500e-01, -6.5085e-02,  ..., -3.5719e-03,\n",
      "         -1.2470e-03,  9.5189e-02],\n",
      "        [ 3.0076e-01, -4.0754e-01, -2.7325e-01,  ...,  9.8452e-04,\n",
      "         -3.0928e-03, -2.3143e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([ 0.0415,  0.2267,  0.1142,  0.2404, -0.3686,  0.8240, -0.1602,  0.2010,\n",
      "        -0.0475,  0.2095,  0.2556,  0.4414,  0.2114,  0.5841, -0.2413,  0.2642],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-3.3957e-01,  4.8598e-01,  1.5248e-01,  ..., -8.0738e-07,\n",
      "        -4.8754e-25,  7.1467e-25], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([0., 0., 0.,  ..., 0., -0., 0.], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[-6.8140e-04,  2.6836e-03,  3.6120e-05,  ...,  1.4842e-05,\n",
      "         -9.5963e-06,  5.1141e-05],\n",
      "        [-3.0193e-03, -2.4624e-03, -7.0648e-03,  ..., -2.1338e-04,\n",
      "          1.9670e-05, -3.0398e-06],\n",
      "        [-1.3018e-03, -4.3259e-03, -8.4457e-03,  ..., -3.3736e-05,\n",
      "          1.4007e-05, -1.2231e-04],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 1.5497e-06,  6.5565e-07,  5.9605e-07,  ..., -5.9605e-08,\n",
      "          5.9605e-08,  0.0000e+00],\n",
      "        [ 4.8828e-04, -3.7694e-04, -1.3292e-05,  ..., -3.6955e-06,\n",
      "          1.8597e-05,  1.7107e-05]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([-1.8083e-03, -2.6065e-02, -1.7322e-02,  3.9556e-02,  1.5968e-02,\n",
      "        -1.0066e-02, -5.3933e-03, -3.6197e-02, -2.3481e-03, -4.9551e-03,\n",
      "         1.3906e-02, -2.9697e-03,  1.1058e-02,  7.3624e-03,  5.3693e-03,\n",
      "        -1.5001e-02,  3.2532e-04, -2.4742e-04,  1.1446e-03, -9.3579e-06,\n",
      "        -1.3362e-03,  1.4113e-03,  2.1607e-03, -2.3428e-03, -5.6809e-03,\n",
      "        -1.8785e-03,  6.6901e-03,  1.6990e-03, -6.4626e-03, -3.9298e-03,\n",
      "        -4.1717e-04, -7.3668e-03, -1.1384e-05, -6.2785e-03, -9.8944e-06,\n",
      "        -1.3167e-04,  8.4370e-04,  9.9140e-04,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  5.9605e-07, -9.1517e-04,  2.4129e-03, -8.1062e-06,\n",
      "         6.8307e-05, -1.7398e-03,  3.3693e-03,  0.0000e+00,  3.2449e-04,\n",
      "        -2.4574e-03,  0.0000e+00,  3.5650e-04, -3.7271e-04,  9.5427e-05,\n",
      "         4.4900e-04, -2.6345e-04,  1.2583e-03,  2.7604e-03,  0.0000e+00,\n",
      "        -2.8789e-05,  0.0000e+00, -4.3511e-06, -4.0412e-04], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[ 3.2949e-04,  4.1428e-03,  1.2695e-02,  ...,  0.0000e+00,\n",
      "          5.3644e-07,  3.0577e-05],\n",
      "        [ 4.2415e-04, -7.1220e-03, -9.3842e-03,  ...,  0.0000e+00,\n",
      "          0.0000e+00, -6.2168e-05],\n",
      "        [ 2.7561e-04, -9.6741e-03, -1.8936e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00, -3.4928e-05],\n",
      "        ...,\n",
      "        [ 1.8525e-04, -7.5455e-03, -1.3351e-02,  ...,  0.0000e+00,\n",
      "          1.1921e-07, -4.3273e-05],\n",
      "        [-2.0289e-04, -2.1439e-02, -2.9602e-02,  ...,  0.0000e+00,\n",
      "          1.1921e-07, -2.6631e-04],\n",
      "        [ 2.4581e-04,  1.5747e-02,  2.6459e-02,  ...,  0.0000e+00,\n",
      "         -5.9605e-08, -8.2850e-06]], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([ 0.0116, -0.0018, -0.0075,  0.0132, -0.0262,  0.0250,  0.0048,  0.0222,\n",
      "        -0.0119, -0.0083,  0.0035,  0.0151,  0.0175, -0.0058, -0.0204,  0.0214],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([ 2.2924e-04,  8.3542e-04, -1.4305e-06,  ...,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0')}}, 14000: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([-2.5862e-32,  1.5285e-39,  7.5104e-08,  ..., -5.0150e-02,\n",
      "         4.6458e-03,  4.7323e-03], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-5.6915e-01, -1.1075e-01, -2.5994e-01,  ...,  3.1439e-02,\n",
      "          6.8924e-02, -9.3698e-03],\n",
      "        [ 2.5688e-01, -5.9040e-01,  7.0088e-01,  ...,  2.6742e-02,\n",
      "         -1.3546e-01, -6.6826e-02],\n",
      "        [ 3.8271e-01,  2.6767e-01, -2.5481e-01,  ...,  4.3960e-02,\n",
      "          1.2856e-01, -1.4508e-01],\n",
      "        ...,\n",
      "        [-4.8035e-03,  2.0291e-03, -3.5847e-03,  ...,  9.2797e-19,\n",
      "         -4.1955e-26, -2.8409e-13],\n",
      "        [-7.3560e-03,  2.5168e-03, -6.9924e-03,  ..., -6.0435e-05,\n",
      "          1.5310e-05,  2.3357e-05],\n",
      "        [-1.5123e-01, -4.1490e-02, -1.0245e-01,  ..., -2.9313e-02,\n",
      "          9.8780e-03, -1.0524e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 8.9634e-01,  4.7815e-02,  2.7799e-01, -8.3552e-02,  3.6240e-01,\n",
      "         2.1934e-01,  5.2938e-01,  1.3837e-01,  5.3873e-01,  5.3192e-01,\n",
      "        -4.0192e-02,  3.7424e-01,  3.1044e-01, -2.0223e-02,  1.0089e-01,\n",
      "        -1.4553e-02,  2.3238e-01,  1.2949e-01,  4.7661e-02,  2.2837e-02,\n",
      "         3.2104e-01,  2.3408e-01,  1.7879e-01,  3.0033e-01, -5.7502e-01,\n",
      "         7.8027e-02,  3.9076e-01,  1.1045e-02,  2.4636e-01,  2.1471e-01,\n",
      "         1.1721e-01,  3.2482e-02, -1.0163e-01, -9.2059e-02,  3.1953e-03,\n",
      "         2.3817e-02, -8.0572e-02, -7.5784e-02, -4.5518e-03, -4.4452e-02,\n",
      "        -7.4844e-02,  2.7329e-05, -6.9271e-02, -5.3106e-02,  1.0282e-02,\n",
      "        -2.0987e-02,  6.7924e-02,  4.8848e-02, -1.6155e-04, -1.5958e-01,\n",
      "         4.8257e-02, -3.6322e-02, -4.0075e-02,  2.1265e-01, -3.7098e-02,\n",
      "         9.0383e-04, -6.8926e-02,  2.3815e-01, -2.3641e-01, -3.7435e-02,\n",
      "        -3.5314e-01, -3.3194e-04,  4.7441e-03, -1.2875e-01], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-3.4851e+00,  9.8862e-01,  1.3671e+00,  ..., -3.3956e-03,\n",
      "         -7.9295e-03, -6.3714e-01],\n",
      "        [ 7.5765e-01,  5.2220e-02, -5.3128e-02,  ..., -1.2069e-05,\n",
      "         -6.1607e-04,  8.5924e-02],\n",
      "        [-3.9973e-01, -3.8414e-01,  2.2462e-01,  ..., -1.8610e-06,\n",
      "         -8.3576e-04, -2.7324e-01],\n",
      "        ...,\n",
      "        [ 7.7744e-01,  3.6807e-01,  1.9934e-02,  ...,  1.3506e-03,\n",
      "          2.8341e-04,  1.4408e-04],\n",
      "        [-4.6641e-01,  3.4376e-01, -6.6405e-02,  ..., -6.0235e-04,\n",
      "          5.5399e-05,  1.6951e-01],\n",
      "        [ 2.9039e-01, -4.1023e-01, -2.7612e-01,  ...,  8.3026e-05,\n",
      "          3.5999e-04, -5.9845e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([ 0.0339,  0.2311,  0.1163,  0.2415, -0.3645,  0.8252, -0.1581,  0.1952,\n",
      "        -0.0430,  0.2128,  0.2564,  0.4420,  0.2122,  0.5871, -0.2407,  0.2677],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-3.4344e-01,  4.8312e-01,  1.5455e-01,  ...,  8.3185e-15,\n",
      "        -2.3214e-11,  2.5038e-11], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -5.9605e-08,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[-3.6697e-03, -2.9736e-03,  4.9067e-04,  ..., -1.1623e-05,\n",
      "          4.1068e-05,  2.6822e-05],\n",
      "        [ 1.1574e-02,  3.5172e-03,  5.5084e-03,  ..., -5.0604e-05,\n",
      "          2.1839e-04, -6.0081e-05],\n",
      "        [ 1.4931e-02, -9.0408e-03,  2.0416e-02,  ..., -1.0878e-04,\n",
      "         -1.3590e-04, -2.1958e-04],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([-6.1479e-03,  3.7307e-02,  7.0659e-02,  5.2759e-02, -1.3254e-02,\n",
      "         1.6753e-02,  1.8951e-03,  1.2931e-01, -3.8975e-03, -3.4242e-03,\n",
      "        -8.5523e-03,  1.1793e-02,  1.1858e-02, -2.5325e-02,  9.1160e-03,\n",
      "        -9.6621e-03,  6.7899e-03, -5.8532e-05, -6.6769e-04,  1.9073e-06,\n",
      "         4.1513e-03, -7.0089e-03, -9.6499e-03,  1.0629e-02, -1.1596e-02,\n",
      "         5.1309e-03, -4.0178e-03, -5.7786e-03,  1.0097e-02,  2.9677e-04,\n",
      "         6.5938e-03,  3.2021e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[-0.0003,  0.0125,  0.0249,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0002,  0.0020,  0.0134,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0001, -0.0185, -0.0160,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.0006, -0.0407, -0.0261,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0004,  0.0004,  0.0012,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0004, -0.0414, -0.0395,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([ 0.0169,  0.0039, -0.0145,  0.0176,  0.0132, -0.0517, -0.0158,  0.0039,\n",
      "         0.0131, -0.0007, -0.0195, -0.0277, -0.0717, -0.0300,  0.0009, -0.0334],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([-0.0009,  0.0001, -0.0006,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0')}}, 14500: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([-3.1282e-40, -2.4429e-39,  5.7732e-19,  ...,  4.6755e-04,\n",
      "         1.4555e-02, -8.0180e-03], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-5.7131e-01, -1.0344e-01, -2.7036e-01,  ..., -1.2028e-01,\n",
      "          4.6424e-02, -1.2066e-02],\n",
      "        [ 2.5558e-01, -5.9327e-01,  7.1224e-01,  ...,  2.2684e-03,\n",
      "         -1.1046e-01, -3.3946e-02],\n",
      "        [ 3.8149e-01,  2.6991e-01, -2.5414e-01,  ...,  7.3836e-02,\n",
      "          1.4476e-01, -8.8901e-02],\n",
      "        ...,\n",
      "        [-1.5424e-03,  3.8345e-04, -1.0637e-03,  ..., -1.0507e-28,\n",
      "         -1.2904e-37, -4.6251e-18],\n",
      "        [-3.8087e-03,  1.0886e-03, -3.8920e-03,  ...,  7.5291e-05,\n",
      "          2.6606e-07, -1.5222e-05],\n",
      "        [-1.3391e-01, -5.9428e-02, -1.1362e-01,  ..., -5.1975e-02,\n",
      "         -5.5125e-02, -8.1768e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 8.9734e-01,  4.8855e-02,  2.7611e-01, -8.5198e-02,  3.5742e-01,\n",
      "         2.2446e-01,  5.2536e-01,  1.3777e-01,  5.2642e-01,  5.1226e-01,\n",
      "        -3.9020e-02,  3.7537e-01,  3.1611e-01, -3.3465e-02,  1.0319e-01,\n",
      "        -1.3882e-02,  2.3364e-01,  1.2753e-01,  5.8714e-02, -1.5516e-02,\n",
      "         3.1145e-01,  2.3460e-01,  1.9921e-01,  2.8915e-01, -5.6976e-01,\n",
      "         7.6093e-02,  3.8774e-01,  1.3675e-02,  2.3553e-01,  2.1650e-01,\n",
      "         1.0833e-01,  3.1384e-02, -1.1006e-01, -7.7907e-02,  4.4208e-03,\n",
      "         3.1888e-02, -7.9207e-02, -3.5828e-02, -4.1941e-03, -3.7487e-02,\n",
      "        -6.5742e-02, -9.3001e-02, -6.8604e-02, -6.3707e-02, -1.0631e-02,\n",
      "        -2.5398e-02,  7.5846e-02,  4.4496e-02, -9.6621e-05, -1.4775e-01,\n",
      "         3.5053e-02, -2.8991e-02, -4.6708e-02,  2.1813e-01, -3.6646e-02,\n",
      "         2.5855e-03, -5.9453e-02,  2.3253e-01, -1.9876e-01, -3.5140e-02,\n",
      "        -3.3770e-01, -3.0972e-04,  2.8367e-03, -1.2823e-01], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-3.5576e+00,  1.0020e+00,  1.3809e+00,  ..., -1.0126e-03,\n",
      "         -2.9093e-03, -6.1858e-01],\n",
      "        [ 7.6807e-01,  5.3402e-02, -5.7181e-02,  ..., -2.2397e-07,\n",
      "         -1.0378e-04,  6.0991e-02],\n",
      "        [-4.0893e-01, -3.8442e-01,  2.2798e-01,  ..., -1.7278e-08,\n",
      "         -2.2126e-04, -2.7950e-01],\n",
      "        ...,\n",
      "        [ 7.9527e-01,  3.7272e-01,  2.2794e-02,  ...,  2.1885e-04,\n",
      "          8.7031e-05, -3.5046e-02],\n",
      "        [-4.6493e-01,  3.4262e-01, -6.7912e-02,  ..., -5.9793e-05,\n",
      "         -1.1260e-04,  1.3132e-01],\n",
      "        [ 3.1495e-01, -4.1154e-01, -2.7836e-01,  ...,  3.3038e-06,\n",
      "         -5.9007e-05, -6.3251e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([ 0.0243,  0.2294,  0.1153,  0.2398, -0.3660,  0.8262, -0.1600,  0.1854,\n",
      "        -0.0372,  0.2135,  0.2547,  0.4395,  0.2121,  0.5932, -0.2459,  0.2721],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-3.3470e-01,  4.5103e-01,  1.2127e-01,  ..., -4.2836e-07,\n",
      "        -1.3630e-08, -9.5329e-09], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[-4.6539e-03,  6.5918e-03, -7.4234e-03,  ...,  6.6280e-05,\n",
      "          6.5386e-05, -5.3644e-07],\n",
      "        [ 5.6793e-02, -3.4729e-02,  2.2858e-02,  ..., -1.5259e-05,\n",
      "         -1.3638e-04, -3.5584e-05],\n",
      "        [ 2.5253e-03, -8.1863e-03,  1.3550e-02,  ..., -1.7524e-04,\n",
      "          1.2034e-04,  2.0194e-04],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 2.9802e-07,  0.0000e+00, -1.1921e-07,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 1.4949e-04, -6.2704e-04,  5.4789e-04,  ..., -6.7949e-06,\n",
      "         -6.4373e-06,  6.6161e-06]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([-2.4107e-02,  1.3950e-01,  4.0943e-02,  8.8147e-02,  2.1226e-02,\n",
      "         1.1992e-04, -1.1256e-02,  1.0113e-01, -7.7426e-04, -4.6921e-03,\n",
      "         1.8197e-04,  3.3405e-02, -1.4587e-02, -3.3640e-02,  2.0354e-02,\n",
      "        -8.4949e-03, -3.8109e-03, -1.8859e-03, -4.6166e-03,  0.0000e+00,\n",
      "         6.7055e-03, -7.9535e-03,  1.2197e-02,  1.5021e-02, -3.0309e-02,\n",
      "         4.3362e-03,  7.4998e-03, -7.6112e-03,  6.4932e-03,  2.6180e-03,\n",
      "        -4.1702e-03,  7.6038e-04,  1.7894e-03,  4.4498e-03, -3.7551e-06,\n",
      "         2.6351e-03, -8.2701e-04,  5.6171e-04,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -5.8286e-03, -1.5921e-03,  0.0000e+00,\n",
      "         8.3923e-05, -1.5058e-03,  1.8460e-04,  0.0000e+00,  3.3522e-04,\n",
      "        -1.8102e-04,  0.0000e+00,  9.0170e-04,  4.6422e-03, -6.4683e-04,\n",
      "         6.0123e-04, -7.4410e-03,  2.0860e-03, -2.1742e-03,  0.0000e+00,\n",
      "         4.4245e-03,  0.0000e+00, -1.9670e-06,  9.9885e-04], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[ 4.0293e-04,  4.2969e-02,  3.9978e-02,  ...,  0.0000e+00,\n",
      "         -1.7881e-07,  4.6790e-05],\n",
      "        [-1.7595e-04, -1.2383e-02, -2.5375e-02,  ...,  0.0000e+00,\n",
      "         -1.7881e-07,  1.2171e-04],\n",
      "        [-2.3663e-04, -2.8946e-02, -3.8635e-02,  ...,  0.0000e+00,\n",
      "          3.5763e-07,  4.0710e-05],\n",
      "        ...,\n",
      "        [-1.2851e-04, -1.7502e-02, -1.7899e-02,  ...,  0.0000e+00,\n",
      "         -5.9605e-08,  5.7757e-05],\n",
      "        [ 6.2847e-04,  2.1606e-02,  1.4107e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00, -3.4451e-05],\n",
      "        [-5.1689e-04, -4.2816e-02, -4.5135e-02,  ...,  0.0000e+00,\n",
      "          5.9605e-08,  3.8445e-05]], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([ 0.0358, -0.0131, -0.0271, -0.0343, -0.0162, -0.0674, -0.0086, -0.0059,\n",
      "         0.0008, -0.0158, -0.0483, -0.0278, -0.0624, -0.0181,  0.0169, -0.0378],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([ 0.0005, -0.0001,  0.0006,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0')}}, 1500: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([-0.0397,  0.0275, -0.0046,  ...,  0.0116,  0.0042,  0.0049],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-0.3683,  0.3569, -0.3399,  ..., -0.3176,  0.2059,  0.0360],\n",
      "        [ 0.6534, -0.3470,  0.4982,  ..., -0.0675,  0.2322,  0.2308],\n",
      "        [ 0.0996,  0.1955,  0.1454,  ...,  0.2121, -0.0857, -0.0328],\n",
      "        ...,\n",
      "        [ 0.0732,  0.2165, -0.0712,  ..., -0.2314,  0.1921,  0.1578],\n",
      "        [-0.0273,  0.2750, -0.0098,  ...,  0.1477, -0.1692, -0.0717],\n",
      "        [ 0.0586, -0.0126,  0.2603,  ...,  0.0697, -0.0672,  0.2540]],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 0.1202,  0.0024,  0.0998, -0.0469,  0.1054,  0.1018,  0.1254,  0.1569,\n",
      "         0.1004,  0.2742, -0.0063,  0.0091, -0.0507,  0.1281, -0.0457, -0.0451,\n",
      "        -0.0758,  0.1128,  0.0634,  0.1050, -0.0176,  0.3367, -0.0296,  0.1542,\n",
      "         0.1063, -0.0386, -0.0150,  0.0796, -0.0368,  0.1123,  0.1203, -0.0616,\n",
      "         0.0875,  0.0752,  0.0699, -0.0623, -0.0841, -0.0233,  0.0466,  0.0530,\n",
      "        -0.0924,  0.0892,  0.0574,  0.0551,  0.0714,  0.0804, -0.0514, -0.0263,\n",
      "         0.1156, -0.0773, -0.0291, -0.1004, -0.0373, -0.0187, -0.0461, -0.0556,\n",
      "        -0.0691, -0.0232, -0.0216,  0.0820, -0.1570,  0.0495,  0.0702,  0.0668],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-0.5051,  0.6540,  0.9265,  ..., -0.3437, -0.3470, -0.2813],\n",
      "        [-0.0545, -0.1008,  0.0655,  ...,  0.2040,  0.0783, -0.3489],\n",
      "        [ 0.2052, -0.3030,  0.0967,  ...,  0.1341,  0.2565, -0.0359],\n",
      "        ...,\n",
      "        [ 0.1593, -0.0239, -0.0281,  ..., -0.0301,  0.1743, -0.3601],\n",
      "        [ 0.2083,  0.2038,  0.1229,  ...,  0.1278,  0.2163,  0.1159],\n",
      "        [ 0.1277, -0.1660, -0.0716,  ...,  0.1247,  0.2560, -0.2250]],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([-0.0290,  0.1128,  0.1727, -0.0057, -0.1196,  0.3212,  0.0186,  0.0926,\n",
      "        -0.0596, -0.0186,  0.2194,  0.1978,  0.0858,  0.1770, -0.0513,  0.0723],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-1.4302e-01,  7.4961e-02, -1.9163e-01,  ...,  9.6481e-35,\n",
      "        -4.3147e-35, -3.0954e-36], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -5.9605e-08,\n",
      "        -1.1921e-07, -1.1921e-07], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[-8.9347e-05,  1.6546e-04, -7.0214e-05,  ..., -1.0967e-05,\n",
      "          1.1683e-05,  5.5432e-06],\n",
      "        [ 5.7526e-03, -3.7098e-03,  5.9128e-03,  ...,  1.0431e-05,\n",
      "          9.9957e-05,  2.3425e-05],\n",
      "        [-6.2790e-03,  3.3875e-03, -2.5158e-03,  ...,  5.0008e-05,\n",
      "         -2.1815e-05,  7.9393e-05],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([ 3.8803e-04,  2.9950e-02, -1.4769e-02,  2.8328e-02, -1.1571e-02,\n",
      "        -8.4983e-03, -1.9717e-04,  1.0207e-01,  8.7202e-05, -1.4930e-02,\n",
      "        -3.4840e-02, -3.9399e-05, -8.0585e-04, -2.3764e-04,  6.5530e-02,\n",
      "        -4.2379e-03, -4.4882e-05, -2.1291e-04, -1.1861e-05, -2.0033e-04,\n",
      "        -2.2519e-02,  4.0098e-03, -6.3769e-03, -3.1388e-03, -7.3661e-03,\n",
      "         1.4216e-02, -2.2588e-02, -4.2368e-03,  7.3913e-03,  4.4354e-02,\n",
      "        -1.7786e-04,  1.8443e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[ 8.8811e-06, -1.0853e-03,  1.0681e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 8.8215e-06,  2.5772e-02,  3.7781e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-4.6492e-06, -3.6072e-02, -2.4643e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [-1.1086e-05, -4.1748e-02, -2.9587e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 2.6226e-06,  2.6733e-02,  3.0930e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-2.1279e-05, -8.6670e-03, -8.8730e-03,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([-0.0034,  0.0165, -0.0177, -0.0336, -0.0027, -0.0271, -0.0056,  0.0174,\n",
      "         0.0087, -0.0347, -0.0329,  0.0001, -0.0102, -0.0192,  0.0164, -0.0071],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([-0.0004, -0.0008, -0.0010,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0')}}, 15000: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([ 9.6687e-40,  1.2183e-39, -2.4044e-31,  ..., -8.6480e-03,\n",
      "        -8.1233e-03, -1.3661e-02], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-5.7879e-01, -1.0401e-01, -2.6658e-01,  ..., -5.7811e-02,\n",
      "          6.4797e-02, -2.7667e-02],\n",
      "        [ 2.5496e-01, -5.9710e-01,  7.1032e-01,  ...,  2.0116e-03,\n",
      "         -1.2223e-01, -8.8973e-02],\n",
      "        [ 3.7878e-01,  2.7032e-01, -2.4892e-01,  ...,  3.9770e-02,\n",
      "          1.2925e-01, -1.5413e-01],\n",
      "        ...,\n",
      "        [-3.5600e-04,  4.4342e-05, -2.2160e-04,  ..., -1.0703e-40,\n",
      "         -5.0449e-40, -4.4662e-25],\n",
      "        [-3.0373e-02,  2.1999e-02, -2.9220e-02,  ..., -1.5708e-06,\n",
      "          6.9499e-08, -6.4648e-05],\n",
      "        [-1.3680e-01, -8.0355e-02, -1.2901e-01,  ..., -7.8042e-02,\n",
      "          1.2580e-02,  8.5805e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 8.9824e-01,  4.7789e-02,  2.7687e-01, -8.7183e-02,  3.5855e-01,\n",
      "         2.2737e-01,  5.2647e-01,  1.3686e-01,  5.2493e-01,  4.8316e-01,\n",
      "        -3.2723e-02,  3.7671e-01,  3.1261e-01, -4.6043e-02,  1.0812e-01,\n",
      "        -1.2938e-02,  2.3590e-01,  7.7356e-02,  4.8101e-02, -1.4279e-02,\n",
      "         3.0287e-01,  2.2949e-01,  1.9682e-01,  2.8601e-01, -5.5504e-01,\n",
      "         7.4194e-02,  3.8212e-01,  7.9976e-03,  2.3292e-01,  2.1396e-01,\n",
      "         1.1275e-01,  3.3877e-02, -1.0755e-01, -9.8098e-02, -5.8042e-02,\n",
      "         3.7229e-02, -7.5929e-02, -4.3198e-02, -3.7762e-03, -3.0122e-02,\n",
      "        -5.5665e-02, -8.6317e-02, -4.4446e-02, -6.2881e-02, -2.9286e-02,\n",
      "        -3.2633e-02,  7.4665e-02,  6.3511e-02, -4.9891e-05, -1.3124e-01,\n",
      "         4.8916e-02, -2.1706e-02, -5.4911e-02,  2.1710e-01, -1.8775e-02,\n",
      "         7.6591e-03, -5.6916e-02,  2.2894e-01, -1.8774e-01, -3.2401e-02,\n",
      "        -3.3078e-01, -2.8352e-04, -9.7763e-03, -1.4612e-01], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-3.6012e+00,  1.0102e+00,  1.3931e+00,  ..., -2.1231e-04,\n",
      "          4.9834e-03, -6.4801e-01],\n",
      "        [ 7.5048e-01,  5.4603e-02, -5.4483e-02,  ..., -1.1762e-09,\n",
      "          1.1534e-04,  7.0905e-02],\n",
      "        [-4.3694e-01, -3.8741e-01,  2.2813e-01,  ..., -3.5150e-11,\n",
      "          4.3797e-05, -2.8202e-01],\n",
      "        ...,\n",
      "        [ 8.0665e-01,  3.7121e-01,  1.8494e-02,  ...,  2.0690e-05,\n",
      "         -1.6097e-03, -6.1884e-02],\n",
      "        [-4.6969e-01,  3.3995e-01, -7.0984e-02,  ..., -2.9664e-06,\n",
      "          2.1969e-04,  1.2602e-01],\n",
      "        [ 2.5738e-01, -4.1137e-01, -2.7811e-01,  ...,  4.8582e-08,\n",
      "         -1.0518e-03, -3.9486e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([ 0.0205,  0.2315,  0.1150,  0.2452, -0.3666,  0.8302, -0.1599,  0.1828,\n",
      "        -0.0406,  0.2148,  0.2539,  0.4417,  0.2131,  0.5966, -0.2450,  0.2764],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-3.2548e-01,  4.6560e-01,  1.1510e-01,  ..., -6.5355e-16,\n",
      "        -2.5171e-15, -9.9296e-15], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "        -1.1921e-07,  0.0000e+00], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[ 6.1951e-03, -2.6855e-03, -1.1473e-03,  ...,  3.3677e-05,\n",
      "         -5.4240e-05, -1.4603e-05],\n",
      "        [ 9.4757e-03, -7.1716e-03, -4.6196e-03,  ..., -1.2434e-04,\n",
      "          3.0756e-05, -3.0637e-05],\n",
      "        [-8.7967e-03,  5.7983e-03,  6.3133e-03,  ..., -3.5167e-06,\n",
      "         -1.0312e-04,  6.2346e-05],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([ 1.2425e-02, -1.4565e-02, -7.2827e-03,  8.4452e-02, -2.0689e-02,\n",
      "         1.1078e-02, -3.8207e-04,  7.4370e-02,  2.6379e-03,  5.5190e-03,\n",
      "        -2.8444e-02, -8.6057e-04, -1.3858e-03, -1.8245e-04,  7.2239e-03,\n",
      "         7.9933e-03, -8.0132e-04,  2.1875e-05,  4.7624e-04,  0.0000e+00,\n",
      "        -3.7659e-03, -2.0764e-03, -5.4563e-03,  1.5841e-02, -4.2534e-04,\n",
      "        -6.6930e-04, -1.1191e-02, -3.1762e-03, -3.9458e-03, -3.1565e-03,\n",
      "        -1.7169e-03,  1.3262e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[-5.5504e-04,  1.1377e-03, -1.6537e-03,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-3.3808e-04, -1.7105e-02, -2.1576e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-4.3988e-04, -2.3590e-02, -3.1464e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [-3.2616e-04, -4.6387e-02, -5.3162e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-5.7936e-05, -1.7471e-02, -1.6815e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-1.1700e-04,  1.4849e-03,  7.4120e-03,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([-0.0029, -0.0159, -0.0244,  0.0121, -0.0013, -0.0339,  0.0032,  0.0128,\n",
      "         0.0110, -0.0172, -0.0076,  0.0060, -0.0409, -0.0373, -0.0104,  0.0019],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([0.0008, 0.0002, 0.0003,  ..., 0.0000, 0.0000, 0.0000], device='cuda:0')}}, 15500: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([-8.1825e-40, -1.0704e-39,  1.3831e-39,  ..., -1.2566e-02,\n",
      "        -5.2309e-03,  8.0090e-03], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-5.7265e-01, -1.0242e-01, -2.6278e-01,  ..., -6.4396e-02,\n",
      "          7.7749e-02, -1.7894e-02],\n",
      "        [ 2.5828e-01, -6.0098e-01,  7.0292e-01,  ...,  1.7583e-02,\n",
      "         -1.6284e-01, -1.7204e-01],\n",
      "        [ 3.7913e-01,  2.6127e-01, -2.4966e-01,  ...,  9.7333e-02,\n",
      "          2.1556e-01, -2.6649e-01],\n",
      "        ...,\n",
      "        [-1.9301e-04,  1.8143e-05, -1.1519e-04,  ...,  7.6538e-41,\n",
      "         -6.2084e-40, -2.1913e-27],\n",
      "        [-1.8544e-02,  1.0378e-02, -1.4707e-02,  ..., -5.5811e-09,\n",
      "          6.3813e-12, -3.2843e-06],\n",
      "        [-1.4213e-01, -5.6736e-02, -9.1935e-02,  ..., -2.9232e-02,\n",
      "         -7.4984e-03,  3.2459e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 9.1315e-01,  4.7945e-02,  2.7638e-01, -8.9702e-02,  3.5519e-01,\n",
      "         2.2692e-01,  5.3005e-01,  1.3610e-01,  5.3398e-01,  4.8215e-01,\n",
      "        -3.1083e-02,  3.8125e-01,  3.1537e-01, -3.9199e-02,  1.0774e-01,\n",
      "        -1.3664e-02,  2.3823e-01,  7.8798e-02,  6.3005e-02, -1.3785e-02,\n",
      "         2.9893e-01,  2.4050e-01,  2.0463e-01,  2.8174e-01, -5.5601e-01,\n",
      "         7.5912e-02,  3.8340e-01,  1.3651e-02,  2.3189e-01,  2.1250e-01,\n",
      "         1.1249e-01,  3.3800e-02, -1.1231e-01, -8.9956e-02, -5.7377e-02,\n",
      "         4.6574e-02, -7.7470e-02, -4.1435e-02, -3.6118e-03, -2.7457e-02,\n",
      "        -5.1876e-02, -8.3630e-02, -3.5555e-02, -5.6441e-02, -2.8505e-02,\n",
      "        -3.2906e-02,  7.7128e-02,  6.0839e-02, -3.7763e-05, -1.2648e-01,\n",
      "         4.5417e-02, -1.9204e-02, -5.3121e-02,  2.1734e-01, -1.7170e-02,\n",
      "         8.3819e-03, -5.2593e-02,  2.4360e-01, -1.8562e-01, -3.1304e-02,\n",
      "        -3.3317e-01, -2.7310e-04, -9.4111e-03, -1.4233e-01], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-3.6625e+00,  1.0237e+00,  1.4031e+00,  ..., -1.1066e-04,\n",
      "          2.9331e-03, -6.6497e-01],\n",
      "        [ 7.5560e-01,  5.7770e-02, -5.5758e-02,  ..., -1.4531e-10,\n",
      "          3.0751e-06,  8.5564e-02],\n",
      "        [-4.3516e-01, -3.9038e-01,  2.2904e-01,  ..., -3.0730e-12,\n",
      "          6.9104e-07, -2.7670e-01],\n",
      "        ...,\n",
      "        [ 8.2392e-01,  3.7283e-01,  1.7770e-02,  ...,  7.8063e-06,\n",
      "         -7.2138e-05, -5.3074e-02],\n",
      "        [-4.7421e-01,  3.4499e-01, -6.7684e-02,  ..., -8.6565e-07,\n",
      "          5.2922e-06,  1.2796e-01],\n",
      "        [ 2.7440e-01, -4.1602e-01, -2.8119e-01,  ...,  8.8396e-09,\n",
      "         -3.3798e-05, -5.7503e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([ 0.0128,  0.2316,  0.1163,  0.2455, -0.3654,  0.8292, -0.1624,  0.1755,\n",
      "        -0.0451,  0.2175,  0.2532,  0.4418,  0.2149,  0.5964, -0.2422,  0.2780],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-3.2845e-01,  4.6958e-01,  1.0853e-01,  ..., -9.0200e-27,\n",
      "         5.1105e-26,  4.2265e-26], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[-1.8520e-03, -1.4722e-05,  2.7237e-03,  ...,  9.3579e-06,\n",
      "         -2.2054e-06, -1.0490e-05],\n",
      "        [ 3.4332e-03, -9.7427e-03, -4.1199e-03,  ...,  2.2590e-05,\n",
      "         -3.2008e-05,  1.2696e-05],\n",
      "        [ 4.9477e-03, -7.3738e-03,  7.4768e-03,  ..., -3.7074e-05,\n",
      "         -1.1212e-04, -2.4843e-04],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2398e-05,  1.5914e-05, -5.2595e-04,  ..., -2.5630e-06,\n",
      "         -6.6161e-06, -5.0664e-06]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([ 6.7822e-03, -7.0914e-03,  3.5171e-02, -5.1227e-02,  5.7083e-04,\n",
      "        -1.2997e-02, -2.9684e-03,  6.1449e-03, -4.2113e-03, -7.2899e-03,\n",
      "         7.9278e-03,  6.6954e-03,  5.0728e-03, -4.0460e-04,  2.7238e-03,\n",
      "        -9.4398e-03,  7.0498e-03,  2.0921e-05, -1.5520e-03,  0.0000e+00,\n",
      "        -7.8166e-04, -1.0463e-03,  6.3087e-03,  6.7627e-03,  1.7301e-03,\n",
      "        -6.5984e-03, -3.8022e-03, -1.4204e-03,  1.4762e-03, -3.6571e-03,\n",
      "        -3.6058e-03, -4.5305e-03,  9.6220e-04,  4.8133e-03,  0.0000e+00,\n",
      "        -4.7731e-04,  1.8184e-03,  4.6217e-04,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  1.3396e-03,  2.0199e-03,  0.0000e+00,\n",
      "        -2.0519e-03,  2.7877e-03, -1.0817e-03,  0.0000e+00, -3.4928e-05,\n",
      "         1.1188e-03,  0.0000e+00, -1.9965e-03, -5.9060e-03, -1.0772e-03,\n",
      "        -1.1233e-03,  4.2123e-04, -7.2050e-04, -1.7581e-03,  0.0000e+00,\n",
      "         1.3276e-03,  0.0000e+00,  0.0000e+00, -1.4933e-03], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[-5.0974e-04,  3.5896e-03, -7.2746e-03,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  2.1386e-04],\n",
      "        [ 6.6996e-05,  2.1271e-02,  2.8534e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00, -6.4671e-05],\n",
      "        [ 1.8382e-04,  1.6937e-02,  2.2842e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00, -4.2677e-05],\n",
      "        ...,\n",
      "        [-1.0788e-05,  6.1989e-03,  1.5656e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00, -1.3757e-04],\n",
      "        [ 1.4520e-04,  8.3084e-03,  5.9929e-03,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  2.7895e-05],\n",
      "        [-7.9453e-05, -8.2550e-03, -1.1276e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  1.4305e-05]], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([ 0.0005,  0.0187,  0.0108,  0.0175,  0.0098,  0.0099, -0.0052, -0.0090,\n",
      "         0.0014,  0.0187, -0.0001, -0.0161,  0.0114,  0.0091,  0.0050, -0.0072],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([-0.0013,  0.0003, -0.0008,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0')}}, 16000: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([ 1.9470e-40,  2.0113e-39,  5.7445e-11,  ...,  9.1193e-03,\n",
      "        -5.4347e-02,  1.2183e-02], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-5.7748e-01, -1.0058e-01, -2.6625e-01,  ..., -4.8003e-02,\n",
      "          1.5195e-02, -2.9218e-02],\n",
      "        [ 2.5851e-01, -6.0247e-01,  6.9812e-01,  ...,  3.9766e-02,\n",
      "         -1.9842e-01, -2.4229e-01],\n",
      "        [ 3.7531e-01,  2.5540e-01, -2.4963e-01,  ...,  7.3989e-02,\n",
      "          2.7361e-01, -3.2185e-01],\n",
      "        ...,\n",
      "        [-8.7716e-05,  5.7289e-06, -4.9584e-05,  ...,  3.1586e-40,\n",
      "          3.8827e-40, -1.9416e-30],\n",
      "        [-9.8265e-03,  3.9405e-03, -6.0724e-03,  ..., -3.2190e-12,\n",
      "          1.4358e-17, -6.7212e-08],\n",
      "        [-1.4205e-01, -4.6458e-02, -8.6984e-02,  ..., -2.6030e-02,\n",
      "         -4.9045e-04,  5.0699e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 9.1542e-01,  4.3888e-02,  2.7124e-01, -9.2575e-02,  3.4652e-01,\n",
      "         2.2654e-01,  5.3422e-01,  1.3582e-01,  5.3776e-01,  4.7580e-01,\n",
      "        -2.7831e-02,  3.7761e-01,  3.1205e-01, -3.8325e-02,  1.0515e-01,\n",
      "        -1.8240e-02,  2.4139e-01,  8.1935e-02,  6.8050e-02, -1.3175e-02,\n",
      "         2.9525e-01,  2.4114e-01,  2.0616e-01,  2.8412e-01, -5.4542e-01,\n",
      "         7.4507e-02,  3.7721e-01,  1.5497e-02,  2.3087e-01,  2.0530e-01,\n",
      "         1.1314e-01,  4.1290e-02, -1.0900e-01, -9.5953e-02, -5.6533e-02,\n",
      "         4.1074e-02, -8.0283e-02, -2.0803e-02, -3.4112e-03, -2.4377e-02,\n",
      "        -4.7385e-02, -8.0301e-02, -2.9202e-02, -5.7715e-02, -2.7532e-02,\n",
      "        -2.0926e-02,  8.0029e-02,  7.0522e-02, -2.6395e-05, -1.2766e-01,\n",
      "         5.3038e-02, -1.6408e-02, -5.4013e-02,  2.2145e-01, -2.9948e-02,\n",
      "         1.6313e-02, -4.4555e-02,  2.3930e-01, -1.7328e-01, -2.9951e-02,\n",
      "        -3.3299e-01, -2.6026e-04, -8.9619e-03, -1.3565e-01], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-3.7323e+00,  1.0435e+00,  1.4221e+00,  ..., -4.7793e-05,\n",
      "          1.4822e-03, -6.4119e-01],\n",
      "        [ 7.6998e-01,  5.9953e-02, -5.6555e-02,  ..., -9.6173e-12,\n",
      "          2.6638e-08,  9.9137e-02],\n",
      "        [-4.3832e-01, -3.9500e-01,  2.2986e-01,  ..., -1.2901e-13,\n",
      "          2.9598e-09, -2.5449e-01],\n",
      "        ...,\n",
      "        [ 8.4229e-01,  3.7566e-01,  1.6462e-02,  ...,  2.2189e-06,\n",
      "         -1.2496e-06, -6.4591e-02],\n",
      "        [-4.7950e-01,  3.4599e-01, -6.8014e-02,  ..., -1.7624e-07,\n",
      "          4.0018e-08,  1.2723e-01],\n",
      "        [ 2.9297e-01, -4.2016e-01, -2.8433e-01,  ...,  9.7188e-10,\n",
      "         -3.7580e-07, -5.1180e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([-4.9559e-05,  2.3234e-01,  1.1638e-01,  2.4575e-01, -3.6357e-01,\n",
      "         8.2843e-01, -1.5957e-01,  1.7095e-01, -4.4399e-02,  2.1810e-01,\n",
      "         2.5259e-01,  4.4481e-01,  2.1473e-01,  5.9658e-01, -2.4249e-01,\n",
      "         2.7845e-01], device='cuda:0')), ('mlp_head.params', tensor([-3.2625e-01,  4.6666e-01,  1.0767e-01,  ...,  2.4772e-38,\n",
      "        -1.6808e-37, -1.6154e-37], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 6.5565e-07, 0.0000e+00,\n",
      "        0.0000e+00], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[ 6.6605e-03, -8.0032e-03,  3.3855e-03,  ...,  7.3493e-05,\n",
      "          5.9605e-05, -9.5129e-05],\n",
      "        [-1.2741e-02,  1.0895e-02,  1.3113e-05,  ..., -1.5616e-04,\n",
      "          4.4227e-05,  1.0955e-04],\n",
      "        [-9.5139e-03,  1.0406e-02, -1.2924e-02,  ..., -8.7619e-06,\n",
      "          1.1683e-04,  2.1160e-05],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([ 0.0203, -0.0366, -0.0231, -0.0263, -0.0405,  0.0202,  0.0021, -0.0275,\n",
      "         0.0070, -0.0038, -0.0204, -0.0206,  0.0144,  0.0153, -0.0085,  0.0100,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[-1.0449e-04, -1.4923e-02, -1.3756e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2863e-04, -4.4823e-03, -1.9958e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 2.4974e-05, -1.9703e-03, -6.3667e-03,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 6.7139e-04, -5.1928e-04, -4.1618e-03,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-4.2868e-04, -3.0937e-03, -8.9264e-03,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 3.1376e-04, -3.7689e-03, -7.3166e-03,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([-0.0141, -0.0070, -0.0025,  0.0117,  0.0097,  0.0163, -0.0187,  0.0139,\n",
      "         0.0048, -0.0029,  0.0140,  0.0149,  0.0414,  0.0011, -0.0069, -0.0013],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([-0.0021, -0.0009, -0.0015,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0')}}, 16500: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([ 1.0139e-39, -9.6184e-40,  6.8642e-23,  ..., -4.1025e-04,\n",
      "        -3.4590e-02, -3.0290e-03], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-5.7709e-01, -9.9849e-02, -2.6559e-01,  ..., -2.7947e-02,\n",
      "          2.2994e-02, -4.1083e-02],\n",
      "        [ 2.5938e-01, -6.0406e-01,  6.9334e-01,  ...,  1.6397e-02,\n",
      "         -2.0177e-01, -2.7249e-01],\n",
      "        [ 3.7233e-01,  2.5179e-01, -2.5033e-01,  ...,  9.6394e-02,\n",
      "          2.9768e-01, -3.7781e-01],\n",
      "        ...,\n",
      "        [-3.1718e-05,  1.2910e-06, -1.6710e-05,  ..., -5.5397e-40,\n",
      "          4.9463e-40, -1.3731e-34],\n",
      "        [-4.3347e-03,  1.1285e-03, -1.9390e-03,  ..., -1.2003e-16,\n",
      "          7.6139e-27, -3.9998e-10],\n",
      "        [-1.4085e-01, -5.4234e-02, -7.0822e-02,  ..., -2.5561e-02,\n",
      "         -1.4528e-02,  2.2995e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 9.1919e-01,  3.9623e-02,  2.6497e-01, -9.6016e-02,  3.3926e-01,\n",
      "         2.2485e-01,  5.2914e-01,  1.3625e-01,  5.3732e-01,  4.6930e-01,\n",
      "        -2.4381e-02,  3.7674e-01,  3.0768e-01, -3.3924e-02,  1.0446e-01,\n",
      "        -1.3829e-02,  2.4228e-01,  9.0003e-02,  6.3645e-02, -1.2431e-02,\n",
      "         2.9071e-01,  2.4227e-01,  2.0784e-01,  2.8295e-01, -5.3127e-01,\n",
      "         7.3245e-02,  3.6953e-01,  1.8233e-02,  2.3030e-01,  2.0523e-01,\n",
      "         1.1138e-01,  3.9708e-02, -1.0783e-01, -9.2923e-02, -5.5466e-02,\n",
      "         4.5018e-02, -7.4983e-02, -1.3895e-02, -3.1697e-03, -2.0921e-02,\n",
      "        -4.2181e-02, -7.6219e-02, -2.2269e-02, -5.7922e-02, -2.6331e-02,\n",
      "        -2.1455e-02,  8.2689e-02,  7.2936e-02, -1.6649e-05, -1.1851e-01,\n",
      "         6.2473e-02, -1.3404e-02, -5.9262e-02,  2.1697e-01, -1.8631e-02,\n",
      "         2.9636e-02, -4.9318e-02,  2.3997e-01, -1.6434e-01, -2.8298e-02,\n",
      "        -3.2328e-01, -2.4466e-04, -8.4163e-03, -1.2703e-01], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-3.7926e+00,  1.0631e+00,  1.4412e+00,  ..., -1.6178e-05,\n",
      "          6.1493e-04, -6.3969e-01],\n",
      "        [ 7.7328e-01,  5.9890e-02, -5.8540e-02,  ..., -2.7737e-13,\n",
      "          4.8770e-11,  1.0586e-01],\n",
      "        [-4.5844e-01, -3.9716e-01,  2.3130e-01,  ..., -2.0254e-15,\n",
      "          2.0275e-12, -2.6892e-01],\n",
      "        ...,\n",
      "        [ 8.5082e-01,  3.7656e-01,  1.4507e-02,  ...,  4.3599e-07,\n",
      "         -5.9272e-09, -5.7364e-02],\n",
      "        [-4.6449e-01,  3.4411e-01, -7.0395e-02,  ..., -2.2396e-08,\n",
      "          6.0685e-11,  1.1936e-01],\n",
      "        [ 2.9502e-01, -4.2396e-01, -2.8487e-01,  ...,  5.4934e-11,\n",
      "         -9.7100e-10, -5.9485e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([-0.0134,  0.2332,  0.1178,  0.2441, -0.3619,  0.8274, -0.1590,  0.1669,\n",
      "        -0.0451,  0.2181,  0.2514,  0.4446,  0.2139,  0.5960, -0.2422,  0.2815],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-3.2659e-01,  4.6537e-01,  1.0210e-01,  ..., -6.0287e-39,\n",
      "         5.1382e-39,  2.7563e-39], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "        -0.0000e+00, -5.9605e-08], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[ 4.3869e-03, -5.6839e-04,  3.8414e-03,  ...,  4.6015e-05,\n",
      "          3.4213e-05,  4.3631e-05],\n",
      "        [ 2.8549e-02, -2.4094e-02,  1.7212e-02,  ..., -1.6081e-04,\n",
      "          6.9201e-05,  1.9908e-04],\n",
      "        [-1.1612e-02,  4.2839e-03,  4.4594e-03,  ..., -3.4511e-05,\n",
      "          5.3406e-05,  8.4043e-06],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([ 0.0068,  0.0980, -0.0038,  0.0537,  0.0073, -0.0406, -0.0078,  0.1190,\n",
      "        -0.0043,  0.0012, -0.0005,  0.0060,  0.0216, -0.0094, -0.0103, -0.0149,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[-0.0009,  0.0111,  0.0143,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0002,  0.0139,  0.0115,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0003, -0.0267, -0.0330,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.0002, -0.0166, -0.0009,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0006,  0.0105,  0.0084,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0001, -0.0085,  0.0048,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([ 0.0114,  0.0073, -0.0298, -0.0255, -0.0207, -0.0463, -0.0210, -0.0040,\n",
      "         0.0027, -0.0209, -0.0443, -0.0380, -0.0567, -0.0100,  0.0094, -0.0012],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([-0.0011, -0.0001, -0.0003,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0')}}, 17000: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([ 3.2090e-40,  1.7197e-39, -6.6606e-34,  ...,  1.0300e-02,\n",
      "        -3.4548e-02, -2.9020e-03], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-5.7949e-01, -9.8753e-02, -2.7409e-01,  ..., -1.3086e-02,\n",
      "          2.1224e-02, -4.6150e-02],\n",
      "        [ 2.5758e-01, -6.0329e-01,  6.8693e-01,  ...,  2.4551e-02,\n",
      "         -2.1939e-01, -2.5662e-01],\n",
      "        [ 3.6896e-01,  2.4870e-01, -2.5334e-01,  ...,  1.1142e-01,\n",
      "          3.2826e-01, -4.2801e-01],\n",
      "        ...,\n",
      "        [-8.5254e-06,  1.8734e-07, -4.0985e-06,  ..., -4.4221e-40,\n",
      "         -1.5029e-40,  1.2817e-40],\n",
      "        [-1.5081e-03,  2.2394e-04, -4.4336e-04,  ..., -5.3000e-23,\n",
      "          2.1973e-38, -4.3454e-13],\n",
      "        [-1.2887e-01, -4.1858e-02, -7.8935e-02,  ..., -7.5132e-03,\n",
      "         -3.6847e-03,  2.5666e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 9.1702e-01,  3.5907e-02,  2.5751e-01, -1.0070e-01,  3.2761e-01,\n",
      "         2.2508e-01,  5.2967e-01,  1.3523e-01,  5.3410e-01,  4.6406e-01,\n",
      "        -2.2073e-02,  3.7656e-01,  3.0773e-01, -3.3341e-02,  1.0639e-01,\n",
      "        -1.7276e-02,  2.4009e-01,  9.2806e-02,  6.2032e-02, -1.1536e-02,\n",
      "         2.8209e-01,  2.3681e-01,  2.1294e-01,  2.8271e-01, -5.1778e-01,\n",
      "         6.8253e-02,  3.6153e-01,  2.2969e-02,  2.2816e-01,  1.9892e-01,\n",
      "         1.1459e-01,  4.7160e-02, -1.0691e-01, -9.4173e-02, -5.4126e-02,\n",
      "         4.3929e-02, -7.8004e-02, -2.9434e-02, -2.8843e-03, -1.7188e-02,\n",
      "        -3.6324e-02, -7.1278e-02, -2.3273e-02, -5.9852e-02, -2.4865e-02,\n",
      "        -1.6356e-02,  7.6526e-02,  6.9638e-02, -9.1986e-06, -1.2447e-01,\n",
      "         5.3141e-02, -1.0335e-02, -5.6969e-02,  2.0862e-01, -2.4747e-02,\n",
      "         2.6117e-02, -4.9786e-02,  2.4764e-01, -1.5101e-01, -2.6307e-02,\n",
      "        -3.1795e-01, -2.2598e-04, -7.7638e-03, -1.2945e-01], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-3.8489e+00,  1.0825e+00,  1.4608e+00,  ..., -3.9908e-06,\n",
      "          1.9757e-04, -6.1351e-01],\n",
      "        [ 7.7596e-01,  6.0121e-02, -6.1323e-02,  ..., -2.6272e-15,\n",
      "          9.9524e-15,  1.2220e-01],\n",
      "        [-4.7459e-01, -3.9955e-01,  2.3169e-01,  ..., -8.3991e-18,\n",
      "          9.7826e-17, -2.4892e-01],\n",
      "        ...,\n",
      "        [ 8.6269e-01,  3.7951e-01,  1.4887e-02,  ...,  5.2886e-08,\n",
      "         -4.6865e-12, -3.8926e-02],\n",
      "        [-4.6922e-01,  3.4509e-01, -7.0287e-02,  ..., -1.5323e-09,\n",
      "          9.4286e-15,  1.3572e-01],\n",
      "        [ 2.9940e-01, -4.2740e-01, -2.8749e-01,  ...,  1.2838e-12,\n",
      "         -3.2488e-13, -6.8333e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([-0.0285,  0.2320,  0.1176,  0.2429, -0.3615,  0.8292, -0.1577,  0.1621,\n",
      "        -0.0486,  0.2187,  0.2513,  0.4464,  0.2144,  0.5990, -0.2410,  0.2821],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-3.2286e-01,  4.5589e-01,  1.0222e-01,  ...,  1.1663e-38,\n",
      "         2.0060e-39,  3.4640e-39], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "         1.7285e-06, -5.3644e-07], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[-2.9421e-04,  3.4237e-04,  7.7009e-04,  ...,  2.3544e-05,\n",
      "          1.9491e-05,  9.9301e-05],\n",
      "        [-6.5804e-04, -2.0905e-03,  2.5768e-03,  ...,  1.2052e-04,\n",
      "         -6.1452e-05,  6.2943e-05],\n",
      "        [-2.9135e-04,  9.4318e-04,  9.0742e-04,  ..., -1.7893e-04,\n",
      "         -9.0182e-05,  1.3125e-04],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-5.5969e-05,  9.5904e-05, -3.2711e-04,  ..., -1.0729e-05,\n",
      "         -2.1458e-06, -2.2650e-06]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([ 5.9400e-03,  1.3357e-02, -2.5766e-03, -3.2187e-06, -3.3510e-03,\n",
      "         9.4942e-03,  3.2328e-03,  1.2510e-02, -3.0482e-03, -3.1052e-03,\n",
      "         2.7388e-03, -3.8743e-06,  8.8300e-03, -4.7384e-03,  1.1145e-03,\n",
      "        -1.4420e-02, -6.3664e-03, -3.0196e-04,  3.5510e-03,  0.0000e+00,\n",
      "         8.1406e-03,  7.1508e-04, -9.4921e-03, -7.8386e-04, -8.8455e-03,\n",
      "         2.6332e-03,  6.9721e-03, -4.7004e-03, -4.4885e-03, -2.9839e-03,\n",
      "        -4.1182e-03,  2.9510e-03, -1.3203e-03,  6.4564e-04,  0.0000e+00,\n",
      "        -3.4545e-03, -5.0426e-04, -1.8609e-04,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  1.6466e-03,  4.9865e-04,  0.0000e+00,\n",
      "        -5.2017e-04,  1.2418e-03, -7.9465e-04,  0.0000e+00, -4.0811e-04,\n",
      "         1.4067e-05,  0.0000e+00,  1.9112e-03, -2.1083e-03, -1.1877e-03,\n",
      "        -8.8555e-04, -2.1992e-03, -1.3154e-03,  5.5385e-04,  0.0000e+00,\n",
      "         1.5491e-04,  0.0000e+00,  0.0000e+00,  1.6928e-05], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[-2.0862e-05,  3.1166e-03, -9.0694e-04,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  8.1003e-05],\n",
      "        [ 2.0504e-04, -2.7776e-04,  3.9177e-03,  ...,  0.0000e+00,\n",
      "          0.0000e+00, -3.1233e-05],\n",
      "        [ 4.1127e-06, -2.5883e-03, -5.8022e-03,  ...,  0.0000e+00,\n",
      "          0.0000e+00, -2.2471e-05],\n",
      "        ...,\n",
      "        [ 2.6107e-04,  6.1378e-03,  5.8289e-03,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  5.4240e-06],\n",
      "        [ 2.2697e-04, -1.2999e-03, -5.6763e-03,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  1.2219e-04],\n",
      "        [ 8.9765e-05, -8.5907e-03, -1.1978e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00, -1.2183e-04]], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([ 0.0025,  0.0018, -0.0005, -0.0045, -0.0026,  0.0007, -0.0012,  0.0118,\n",
      "        -0.0015,  0.0005, -0.0115, -0.0015, -0.0018,  0.0062, -0.0034, -0.0080],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([6.1846e-04, 6.9499e-05, 1.5059e-03,  ..., 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00], device='cuda:0')}}, 17500: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([ 1.3590e-39, -2.9391e-39, -2.4717e-39,  ..., -5.6947e-03,\n",
      "         5.0669e-03, -4.9659e-02], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-5.8113e-01, -9.6803e-02, -2.6909e-01,  ..., -2.6342e-02,\n",
      "          3.3899e-02, -5.8882e-02],\n",
      "        [ 2.5680e-01, -6.0214e-01,  6.8444e-01,  ...,  4.7985e-02,\n",
      "         -2.0678e-01, -2.8308e-01],\n",
      "        [ 3.6824e-01,  2.4687e-01, -2.5380e-01,  ...,  9.0605e-02,\n",
      "          3.1452e-01, -4.4821e-01],\n",
      "        ...,\n",
      "        [-1.5574e-06,  1.5265e-08, -6.6439e-07,  ..., -4.0453e-40,\n",
      "         -4.8618e-40, -4.5572e-40],\n",
      "        [-3.8551e-04,  2.7516e-05, -6.5576e-05,  ...,  1.8215e-33,\n",
      "          1.1983e-40, -4.1495e-17],\n",
      "        [-1.2879e-01, -4.5082e-02, -7.6137e-02,  ...,  6.7064e-03,\n",
      "          2.0496e-02,  2.4482e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 9.2019e-01,  3.2318e-02,  2.5198e-01, -1.0309e-01,  3.1721e-01,\n",
      "         2.2413e-01,  5.3175e-01,  1.3538e-01,  5.3064e-01,  4.5701e-01,\n",
      "        -2.0285e-02,  3.7378e-01,  3.0529e-01, -3.2739e-02,  1.0272e-01,\n",
      "        -1.7871e-02,  2.4298e-01,  8.9163e-02,  6.1764e-02, -1.0480e-02,\n",
      "         2.8174e-01,  2.3271e-01,  2.1738e-01,  2.7868e-01, -5.0699e-01,\n",
      "         5.7253e-02,  3.6070e-01,  2.0759e-02,  2.2323e-01,  1.9455e-01,\n",
      "         1.1313e-01,  4.2908e-02, -1.0027e-01, -8.5850e-02, -5.2452e-02,\n",
      "         4.6976e-02, -7.2439e-02, -2.2571e-02, -2.5551e-03, -1.3351e-02,\n",
      "        -2.9975e-02, -6.5398e-02, -2.4848e-02, -6.0658e-02, -2.3102e-02,\n",
      "        -1.3605e-02,  8.2464e-02,  7.3771e-02, -4.2829e-06, -1.2733e-01,\n",
      "         5.9957e-02, -7.3982e-03, -5.4432e-02,  2.1463e-01, -1.4094e-02,\n",
      "         2.7077e-02, -4.2359e-02,  2.4680e-01, -1.3685e-01, -2.3954e-02,\n",
      "        -3.1649e-01, -2.0406e-04, -6.9992e-03, -1.2093e-01], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-3.9031e+00,  1.0988e+00,  1.4794e+00,  ..., -6.5179e-07,\n",
      "          4.5537e-05, -6.0994e-01],\n",
      "        [ 7.7917e-01,  6.3849e-02, -6.1065e-02,  ..., -5.4421e-18,\n",
      "          7.5002e-20,  1.4740e-01],\n",
      "        [-4.8855e-01, -4.0078e-01,  2.3369e-01,  ..., -5.4973e-21,\n",
      "          6.8031e-23, -2.3505e-01],\n",
      "        ...,\n",
      "        [ 8.6848e-01,  3.8133e-01,  1.3156e-02,  ...,  3.4033e-09,\n",
      "         -2.7997e-16, -3.9601e-02],\n",
      "        [-4.6131e-01,  3.4697e-01, -7.0459e-02,  ..., -4.6190e-11,\n",
      "          4.6054e-20,  1.1589e-01],\n",
      "        [ 2.9422e-01, -4.2985e-01, -2.8910e-01,  ...,  9.1489e-15,\n",
      "         -5.2911e-18, -7.6093e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([-0.0420,  0.2327,  0.1175,  0.2419, -0.3602,  0.8275, -0.1576,  0.1571,\n",
      "        -0.0485,  0.2183,  0.2506,  0.4461,  0.2129,  0.5984, -0.2402,  0.2845],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-3.1787e-01,  4.4252e-01,  9.5834e-02,  ...,  3.2380e-07,\n",
      "         1.2376e-13,  1.1796e-14], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "        -1.1921e-07, -0.0000e+00], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[-2.6093e-03,  2.9144e-03,  1.2293e-03,  ...,  2.8610e-05,\n",
      "         -7.9274e-06,  1.5974e-04],\n",
      "        [ 1.0551e-02, -1.3313e-02,  1.5383e-03,  ...,  1.3721e-04,\n",
      "          6.7532e-05, -1.0490e-04],\n",
      "        [ 2.8443e-04, -9.2087e-03, -6.8207e-03,  ...,  1.6522e-04,\n",
      "          1.9848e-05,  2.7418e-05],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([ 0.0045, -0.0025, -0.0311,  0.0319, -0.0433,  0.0288,  0.0101,  0.0283,\n",
      "        -0.0060,  0.0008,  0.0133, -0.0052, -0.0023, -0.0028, -0.0187, -0.0032,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[-1.4508e-04, -1.2100e-02, -2.8320e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 1.1301e-04, -3.8075e-04, -1.0765e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-6.3241e-05, -9.9373e-04, -4.6997e-03,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [-3.9458e-04, -2.1317e-02, -2.0920e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 6.2227e-05, -1.4618e-02, -2.6245e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 3.4642e-04, -2.3483e-02, -2.2446e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([-0.0193, -0.0044, -0.0066, -0.0110, -0.0023, -0.0285, -0.0022, -0.0155,\n",
      "        -0.0062, -0.0177,  0.0061,  0.0028, -0.0225, -0.0208, -0.0158, -0.0173],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([-0.0007, -0.0004, -0.0009,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0')}}, 18000: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([ 1.6182e-39, -2.6856e-39, -2.8305e-41,  ..., -8.7267e-04,\n",
      "        -2.0611e-02, -1.9145e-02], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-5.8737e-01, -9.8276e-02, -2.7298e-01,  ..., -6.9136e-02,\n",
      "          2.9389e-02, -2.5814e-02],\n",
      "        [ 2.5703e-01, -6.0312e-01,  6.8205e-01,  ...,  4.9106e-02,\n",
      "         -1.9839e-01, -2.6116e-01],\n",
      "        [ 3.6601e-01,  2.4522e-01, -2.5098e-01,  ...,  1.0300e-01,\n",
      "          2.9886e-01, -4.6856e-01],\n",
      "        ...,\n",
      "        [-1.7229e-07,  5.8331e-10, -6.2845e-08,  ...,  5.1783e-40,\n",
      "          1.3261e-40, -1.4767e-40],\n",
      "        [-6.6139e-05,  1.8085e-06, -5.5000e-06,  ...,  4.7781e-40,\n",
      "          1.3500e-40, -9.3761e-23],\n",
      "        [-1.2596e-01, -5.2444e-02, -7.2973e-02,  ..., -1.1364e-02,\n",
      "          3.3915e-03,  3.7823e-03]], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 9.1638e-01,  3.0312e-02,  2.4869e-01, -1.0564e-01,  3.0992e-01,\n",
      "         2.2291e-01,  5.2761e-01,  1.3582e-01,  5.3221e-01,  4.4899e-01,\n",
      "        -1.8174e-02,  3.7176e-01,  3.0404e-01, -3.0219e-02,  1.0399e-01,\n",
      "        -1.8262e-02,  2.4217e-01,  8.5571e-02,  6.4893e-02, -9.2664e-03,\n",
      "         2.7723e-01,  2.3203e-01,  2.2032e-01,  2.7996e-01, -4.9285e-01,\n",
      "         5.8471e-02,  3.5419e-01,  2.3861e-02,  2.2581e-01,  1.9449e-01,\n",
      "         1.1313e-01,  4.4622e-02, -1.0379e-01, -9.0563e-02, -5.0381e-02,\n",
      "         5.2007e-02, -7.6181e-02, -2.0222e-02, -2.1871e-03, -9.6525e-03,\n",
      "        -2.3424e-02, -5.8559e-02, -1.7451e-02, -5.4025e-02, -2.1021e-02,\n",
      "        -1.8657e-02,  8.1978e-02,  7.0848e-02, -1.6004e-06, -1.1863e-01,\n",
      "         5.7380e-02, -4.8150e-03, -5.9408e-02,  2.1011e-01, -1.8467e-02,\n",
      "         2.7942e-02, -4.1423e-02,  2.3662e-01, -1.3485e-01, -2.1241e-02,\n",
      "        -3.0848e-01, -1.7903e-04, -6.1275e-03, -1.2657e-01], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-3.9398e+00,  1.1179e+00,  1.4974e+00,  ..., -6.2262e-08,\n",
      "          6.8257e-06, -5.7985e-01],\n",
      "        [ 7.8436e-01,  6.3737e-02, -6.1320e-02,  ..., -1.3441e-21,\n",
      "          1.4423e-27,  1.6927e-01],\n",
      "        [-4.9562e-01, -4.0269e-01,  2.3452e-01,  ..., -2.5174e-25,\n",
      "         -6.2392e-33, -2.4547e-01],\n",
      "        ...,\n",
      "        [ 8.7268e-01,  3.8157e-01,  1.2685e-02,  ...,  9.5067e-11,\n",
      "         -2.8797e-22, -6.0537e-03],\n",
      "        [-4.5677e-01,  3.4586e-01, -7.1419e-02,  ..., -4.6769e-13,\n",
      "          3.1272e-28,  1.1442e-01],\n",
      "        [ 3.0343e-01, -4.3313e-01, -2.9048e-01,  ...,  1.2907e-17,\n",
      "         -5.1130e-25, -8.2475e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([-0.0525,  0.2346,  0.1187,  0.2408, -0.3595,  0.8271, -0.1560,  0.1526,\n",
      "        -0.0501,  0.2194,  0.2492,  0.4457,  0.2123,  0.5976, -0.2406,  0.2857],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-3.1757e-01,  4.3606e-01,  8.3024e-02,  ...,  3.3038e-18,\n",
      "        -5.6212e-15,  8.9110e-15], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "        -5.9605e-08, -1.7285e-06], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[-2.0332e-03,  2.8300e-04,  4.2038e-03,  ...,  1.1444e-05,\n",
      "          2.0325e-05,  8.5950e-05],\n",
      "        [ 1.9207e-03,  6.9923e-03, -6.9923e-03,  ...,  4.4644e-05,\n",
      "         -1.6391e-05,  4.8935e-05],\n",
      "        [ 1.8219e-02, -1.2619e-02,  1.4030e-02,  ..., -1.4162e-04,\n",
      "          2.1613e-04, -2.2578e-04],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-2.0146e-05,  1.0926e-04,  5.0163e-04,  ...,  2.0266e-06,\n",
      "         -9.3579e-06, -1.2517e-06]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([ 7.8183e-04, -7.2535e-03,  5.4093e-02,  1.0560e-01,  1.2739e-02,\n",
      "        -4.3774e-02, -8.7045e-03,  8.7821e-02, -5.0644e-03, -4.2270e-03,\n",
      "         6.1521e-03,  1.7015e-02,  3.4967e-02, -6.0636e-03, -1.3107e-02,\n",
      "        -3.3534e-02, -4.2980e-03, -1.5386e-03, -7.3422e-03,  0.0000e+00,\n",
      "         4.3064e-03, -7.3051e-03, -2.5522e-03,  1.4470e-02, -1.2811e-02,\n",
      "         1.4556e-03,  3.1626e-04, -6.6316e-04,  1.4217e-02, -2.0123e-03,\n",
      "        -4.9233e-05, -7.1834e-03,  3.8266e-04, -1.1373e-03,  0.0000e+00,\n",
      "        -5.3937e-03, -3.1519e-03,  5.1677e-05,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -7.4821e-03,  1.4788e-04,  0.0000e+00,\n",
      "        -1.4555e-03, -3.0369e-04, -4.5167e-03,  0.0000e+00, -1.0610e-05,\n",
      "         1.5090e-03,  0.0000e+00,  3.0764e-03,  5.6133e-03, -4.1741e-04,\n",
      "         1.4417e-03, -7.7242e-03,  5.2387e-03,  7.2640e-04,  0.0000e+00,\n",
      "         7.1818e-04,  0.0000e+00,  0.0000e+00,  7.0071e-04], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[-5.7983e-04,  1.5747e-02,  1.3397e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00, -1.6093e-06],\n",
      "        [-8.5533e-05, -1.4320e-02, -5.4512e-03,  ...,  0.0000e+00,\n",
      "          0.0000e+00, -2.7001e-05],\n",
      "        [-1.9789e-05, -1.1040e-02, -1.1330e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  2.6226e-06],\n",
      "        ...,\n",
      "        [-7.0620e-04, -3.1555e-02, -2.2202e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00, -8.1539e-05],\n",
      "        [-4.4537e-04, -4.4891e-02, -5.0354e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00, -8.9407e-06],\n",
      "        [-1.2046e-04,  1.1368e-02,  1.7670e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  5.1081e-05]], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([ 0.0137, -0.0067, -0.0066,  0.0198, -0.0054, -0.0322,  0.0034, -0.0011,\n",
      "         0.0053,  0.0042, -0.0201, -0.0231, -0.0798, -0.0252, -0.0405,  0.0143],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([0.0010, 0.0011, 0.0008,  ..., 0.0000, 0.0000, 0.0000], device='cuda:0')}}, 18500: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([-1.9829e-40,  1.6091e-39,  1.7346e-39,  ...,  3.4137e-03,\n",
      "        -1.7725e-02, -3.7702e-03], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-5.8221e-01, -1.0253e-01, -2.7150e-01,  ..., -6.4942e-02,\n",
      "          2.6561e-02, -3.6817e-02],\n",
      "        [ 2.5699e-01, -6.0392e-01,  6.7836e-01,  ...,  4.7771e-02,\n",
      "         -2.0372e-01, -3.0107e-01],\n",
      "        [ 3.6542e-01,  2.4521e-01, -2.5346e-01,  ...,  1.0434e-01,\n",
      "          3.2907e-01, -5.0643e-01],\n",
      "        ...,\n",
      "        [-6.9244e-08,  1.5360e-10, -2.3716e-08,  ..., -1.0059e-41,\n",
      "          5.4520e-40,  1.9843e-40],\n",
      "        [-3.1758e-05,  5.9003e-07, -1.9778e-06,  ..., -6.3787e-40,\n",
      "         -3.9342e-40, -9.7227e-25],\n",
      "        [-1.1796e-01, -5.3312e-02, -6.0987e-02,  ..., -1.1759e-02,\n",
      "          4.6372e-03, -2.8231e-03]], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 9.1874e-01,  2.9576e-02,  2.4643e-01, -1.0718e-01,  3.0752e-01,\n",
      "         2.2260e-01,  5.3143e-01,  1.3597e-01,  5.3409e-01,  4.4613e-01,\n",
      "        -1.7716e-02,  3.7204e-01,  3.0233e-01, -2.9419e-02,  1.0472e-01,\n",
      "        -1.8259e-02,  2.4310e-01,  8.7672e-02,  6.3103e-02, -8.7953e-03,\n",
      "         2.7529e-01,  2.3134e-01,  2.2064e-01,  2.7964e-01, -4.9148e-01,\n",
      "         6.0440e-02,  3.5241e-01,  2.4016e-02,  2.2446e-01,  1.9364e-01,\n",
      "         1.1267e-01,  4.5852e-02, -1.0209e-01, -9.1551e-02, -4.9527e-02,\n",
      "         5.1274e-02, -7.5077e-02, -1.6276e-02, -2.0477e-03, -8.4151e-03,\n",
      "        -2.1103e-02, -5.5881e-02, -1.4324e-02, -5.3540e-02, -2.0196e-02,\n",
      "        -1.3251e-02,  8.1493e-02,  7.2010e-02, -1.0586e-06, -1.1752e-01,\n",
      "         5.1697e-02, -4.0161e-03, -5.3909e-02,  2.1483e-01, -1.4899e-02,\n",
      "         2.8693e-02, -4.3679e-02,  2.4219e-01, -1.2766e-01, -2.0186e-02,\n",
      "        -3.0595e-01, -1.6937e-04, -5.7917e-03, -1.1868e-01], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-3.9614e+00,  1.1240e+00,  1.5048e+00,  ..., -2.3589e-08,\n",
      "          3.1023e-06, -5.7568e-01],\n",
      "        [ 7.8818e-01,  6.5438e-02, -6.0972e-02,  ..., -5.6684e-23,\n",
      "          5.1581e-30,  1.6881e-01],\n",
      "        [-4.9662e-01, -4.0407e-01,  2.3577e-01,  ..., -6.1845e-27,\n",
      "         -9.5860e-36, -2.4119e-01],\n",
      "        ...,\n",
      "        [ 8.7690e-01,  3.8311e-01,  1.2918e-02,  ...,  2.2150e-11,\n",
      "         -2.4391e-24, -9.8051e-03],\n",
      "        [-4.5289e-01,  3.4659e-01, -7.1257e-02,  ..., -7.3852e-14,\n",
      "          9.3479e-31,  1.0847e-01],\n",
      "        [ 3.0244e-01, -4.3357e-01, -2.9121e-01,  ...,  9.9032e-19,\n",
      "         -2.5090e-27, -8.0341e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([-0.0571,  0.2356,  0.1194,  0.2403, -0.3580,  0.8264, -0.1564,  0.1511,\n",
      "        -0.0512,  0.2184,  0.2490,  0.4462,  0.2121,  0.5980, -0.2397,  0.2866],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-3.1773e-01,  4.3672e-01,  8.7590e-02,  ..., -2.2408e-29,\n",
      "         2.4220e-26, -7.5954e-26], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.1921e-07, 1.1921e-07,\n",
      "        2.9802e-07], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[ 5.5771e-03,  1.5974e-03,  6.8665e-03,  ..., -7.0930e-06,\n",
      "         -2.3782e-05, -6.4969e-06],\n",
      "        [ 2.1572e-03, -4.0932e-03, -4.9820e-03,  ...,  2.6405e-05,\n",
      "          7.7605e-05,  1.2851e-04],\n",
      "        [-9.2850e-03,  7.4005e-03, -1.3863e-02,  ...,  1.9884e-04,\n",
      "         -4.0293e-05,  2.2364e-04],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([ 0.0221, -0.0040, -0.0324, -0.0565, -0.0008,  0.0245,  0.0075,  0.0117,\n",
      "         0.0006, -0.0052, -0.0035, -0.0162, -0.0164,  0.0129, -0.0103,  0.0245,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[ 0.0002, -0.0174, -0.0167,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0002,  0.0150,  0.0241,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0001,  0.0079,  0.0180,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0003, -0.0056, -0.0031,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0003,  0.0208,  0.0279,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0005,  0.0030, -0.0096,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([-0.0166,  0.0163,  0.0084, -0.0153,  0.0192, -0.0008, -0.0036, -0.0170,\n",
      "        -0.0019, -0.0114,  0.0088,  0.0039,  0.0113, -0.0036,  0.0232, -0.0004],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([ 1.2665e-03, -7.8559e-05,  1.5774e-03,  ...,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0')}}, 19000: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([ 1.6413e-40,  2.3072e-39,  2.0008e-39,  ..., -8.5915e-03,\n",
      "        -9.6692e-04, -6.3175e-03], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-5.8204e-01, -1.0176e-01, -2.7536e-01,  ..., -5.3309e-02,\n",
      "          3.1980e-02, -3.5233e-02],\n",
      "        [ 2.5799e-01, -6.0551e-01,  6.7696e-01,  ...,  5.2119e-02,\n",
      "         -2.4510e-01, -3.5541e-01],\n",
      "        [ 3.6423e-01,  2.4318e-01, -2.5327e-01,  ...,  1.2741e-01,\n",
      "          3.8156e-01, -6.0020e-01],\n",
      "        ...,\n",
      "        [-2.1363e-08,  2.7358e-11, -6.7428e-09,  ...,  6.4886e-40,\n",
      "         -4.3215e-40,  5.1695e-40],\n",
      "        [-1.2337e-05,  1.3887e-07, -5.2820e-07,  ..., -5.8340e-40,\n",
      "          3.4614e-40, -2.3642e-27],\n",
      "        [-1.2463e-01, -5.2065e-02, -5.5235e-02,  ...,  1.1760e-03,\n",
      "          3.8593e-04, -4.4902e-04]], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 9.1820e-01,  2.8220e-02,  2.4445e-01, -1.0822e-01,  3.0368e-01,\n",
      "         2.2169e-01,  5.3040e-01,  1.3505e-01,  5.3477e-01,  4.4637e-01,\n",
      "        -1.5117e-02,  3.7086e-01,  3.0158e-01, -2.7813e-02,  1.0393e-01,\n",
      "        -1.8436e-02,  2.4374e-01,  9.4678e-02,  6.4352e-02, -8.2251e-03,\n",
      "         2.7269e-01,  2.3297e-01,  2.2251e-01,  2.8438e-01, -4.8886e-01,\n",
      "         5.8328e-02,  3.5098e-01,  2.6280e-02,  2.2180e-01,  1.9191e-01,\n",
      "         1.1454e-01,  4.8982e-02, -1.0081e-01, -9.1148e-02, -4.8452e-02,\n",
      "         5.5185e-02, -7.1673e-02, -2.1627e-02, -1.8815e-03, -7.0550e-03,\n",
      "        -1.8454e-02, -5.2620e-02, -1.1296e-02, -4.8413e-02, -1.9185e-02,\n",
      "        -1.1267e-02,  8.1834e-02,  7.3083e-02, -6.2195e-07, -1.1092e-01,\n",
      "         5.4055e-02, -3.1807e-03, -5.9122e-02,  2.1201e-01, -1.5682e-02,\n",
      "         2.9936e-02, -4.2640e-02,  2.4462e-01, -1.1894e-01, -1.8907e-02,\n",
      "        -3.0551e-01, -1.5772e-04, -5.3871e-03, -1.1538e-01], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-3.9827e+00,  1.1345e+00,  1.5135e+00,  ..., -6.7410e-09,\n",
      "          1.1224e-06, -5.6862e-01],\n",
      "        [ 7.9742e-01,  6.6083e-02, -6.2014e-02,  ..., -9.0566e-25,\n",
      "          3.0031e-33,  1.6571e-01],\n",
      "        [-4.9612e-01, -4.0481e-01,  2.3745e-01,  ..., -4.8013e-29,\n",
      "         -1.4946e-39, -2.4386e-01],\n",
      "        ...,\n",
      "        [ 8.8754e-01,  3.8382e-01,  1.1770e-02,  ...,  3.3637e-12,\n",
      "         -4.5123e-27, -1.7060e-02],\n",
      "        [-4.5382e-01,  3.4737e-01, -7.0745e-02,  ..., -6.7450e-15,\n",
      "          4.3212e-34,  8.7194e-02],\n",
      "        [ 2.9781e-01, -4.3576e-01, -2.9210e-01,  ...,  3.4993e-20,\n",
      "         -2.2236e-30, -8.7107e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([-0.0624,  0.2354,  0.1205,  0.2400, -0.3576,  0.8257, -0.1555,  0.1482,\n",
      "        -0.0515,  0.2198,  0.2485,  0.4465,  0.2117,  0.5975, -0.2400,  0.2861],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-3.1446e-01,  4.3303e-01,  8.6784e-02,  ...,  7.8766e-39,\n",
      "         1.7348e-37,  2.8001e-37], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -8.9407e-07,\n",
      "         0.0000e+00, -0.0000e+00], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[ 1.0170e-02, -5.3329e-03,  3.6507e-03,  ..., -4.3511e-06,\n",
      "          3.6001e-05, -2.5034e-05],\n",
      "        [ 7.3814e-03, -3.5782e-03,  5.4512e-03,  ..., -7.7307e-05,\n",
      "          8.9407e-05,  2.7299e-05],\n",
      "        [-5.5733e-03,  4.9057e-03, -6.3477e-03,  ..., -1.5819e-04,\n",
      "         -2.0838e-04,  5.5492e-05],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 1.6069e-04, -8.5294e-05,  3.1853e-04,  ...,  6.8545e-06,\n",
      "          1.9073e-06, -6.0797e-06]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([ 2.2037e-02,  1.2020e-02, -2.8417e-02,  3.3059e-02, -2.8988e-02,\n",
      "         4.0858e-02, -2.5759e-03,  8.0155e-03, -1.1251e-03,  1.4494e-02,\n",
      "         5.2130e-03, -9.0332e-03,  3.9624e-03,  8.4149e-03, -1.9178e-03,\n",
      "        -3.7804e-03, -2.7401e-03, -1.4621e-04, -6.2466e-04,  0.0000e+00,\n",
      "        -2.7226e-03, -3.9567e-03, -3.3808e-04, -6.2527e-03, -1.1157e-03,\n",
      "         4.3919e-03, -8.9953e-03,  3.2879e-03,  2.3508e-04, -1.7005e-04,\n",
      "         4.1854e-04, -3.9736e-03,  5.3900e-04, -7.3719e-04,  0.0000e+00,\n",
      "         3.2364e-03,  6.0296e-04,  2.9588e-04,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  9.8503e-04, -3.3480e-03,  0.0000e+00,\n",
      "         8.0860e-04, -3.1710e-05,  1.9320e-03,  0.0000e+00, -4.5335e-04,\n",
      "         1.1844e-03,  0.0000e+00,  2.3466e-03, -1.8297e-03, -1.6442e-03,\n",
      "        -1.9866e-04, -2.4791e-03,  7.2145e-04,  1.0693e-04,  0.0000e+00,\n",
      "         9.7531e-04,  0.0000e+00,  0.0000e+00,  1.9587e-03], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[-3.6001e-04, -4.5929e-03, -9.0256e-03,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  4.5478e-05],\n",
      "        [-1.6415e-04, -1.1414e-02, -9.8190e-03,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  1.0484e-04],\n",
      "        [ 1.7881e-06, -3.0575e-03, -1.7128e-03,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  8.4698e-05],\n",
      "        ...,\n",
      "        [ 2.5392e-05, -1.2718e-02, -2.6398e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  4.7863e-05],\n",
      "        [-4.5705e-04, -1.1719e-02, -1.1902e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  2.5272e-05],\n",
      "        [ 3.0088e-04, -2.4261e-02, -2.9343e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  5.3644e-07]], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([-7.6617e-03, -8.8597e-03, -7.1421e-05, -1.3331e-02, -1.1957e-02,\n",
      "        -1.8085e-02,  1.0539e-03, -1.4275e-03,  1.9757e-04, -1.8362e-02,\n",
      "         5.3281e-06,  1.1129e-02, -8.7634e-03, -1.4035e-02, -1.0671e-02,\n",
      "        -2.1364e-02], device='cuda:0'), 'mlp_head.params': tensor([ 0.0003, -0.0003,  0.0003,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0')}}, 19500: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([-6.2477e-41, -7.5000e-40,  2.5645e-39,  ..., -1.4793e-02,\n",
      "        -1.1577e-02, -4.8306e-03], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-5.8380e-01, -1.0209e-01, -2.7523e-01,  ..., -5.3016e-02,\n",
      "          3.5327e-02, -1.5961e-02],\n",
      "        [ 2.5738e-01, -6.0334e-01,  6.7280e-01,  ...,  5.4251e-02,\n",
      "         -2.8467e-01, -4.1122e-01],\n",
      "        [ 3.6359e-01,  2.4012e-01, -2.5439e-01,  ...,  1.3348e-01,\n",
      "          4.4969e-01, -6.9681e-01],\n",
      "        ...,\n",
      "        [-4.6708e-09,  2.9176e-12, -1.3254e-09,  ..., -6.2191e-40,\n",
      "         -1.7670e-40, -5.0802e-40],\n",
      "        [-3.6395e-06,  2.1331e-08, -9.5688e-08,  ...,  5.6709e-40,\n",
      "          1.9023e-41, -7.2530e-31],\n",
      "        [-1.1811e-01, -5.1432e-02, -5.5579e-02,  ...,  1.1756e-02,\n",
      "          3.4909e-03,  1.4127e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 9.1721e-01,  2.6159e-02,  2.4078e-01, -1.0998e-01,  2.9839e-01,\n",
      "         2.2164e-01,  5.3029e-01,  1.3500e-01,  5.3428e-01,  4.4245e-01,\n",
      "        -1.4077e-02,  3.7216e-01,  3.0028e-01, -2.8870e-02,  1.0197e-01,\n",
      "        -2.0581e-02,  2.4491e-01,  8.9987e-02,  6.6060e-02, -7.5465e-03,\n",
      "         2.7017e-01,  2.3162e-01,  2.2228e-01,  2.8332e-01, -4.8415e-01,\n",
      "         5.8578e-02,  3.4819e-01,  2.8346e-02,  2.2250e-01,  1.8774e-01,\n",
      "         1.1357e-01,  4.8165e-02, -1.0158e-01, -9.3417e-02, -4.7105e-02,\n",
      "         5.4761e-02, -7.1055e-02, -1.8410e-02, -1.6876e-03, -5.6245e-03,\n",
      "        -1.5533e-02, -4.8709e-02, -1.0815e-02, -4.9019e-02, -1.7959e-02,\n",
      "        -1.5924e-02,  8.2975e-02,  7.4303e-02, -3.1352e-07, -1.1425e-01,\n",
      "         5.6229e-02, -2.3566e-03, -5.6317e-02,  2.1211e-01, -1.6874e-02,\n",
      "         3.3091e-02, -4.1563e-02,  2.4298e-01, -1.1583e-01, -1.7383e-02,\n",
      "        -3.0326e-01, -1.4392e-04, -4.9086e-03, -1.1336e-01], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-4.0045e+00,  1.1448e+00,  1.5243e+00,  ..., -1.3339e-09,\n",
      "          3.0190e-07, -5.6582e-01],\n",
      "        [ 7.9490e-01,  6.7750e-02, -6.2774e-02,  ..., -3.8468e-27,\n",
      "          1.1359e-37,  1.7128e-01],\n",
      "        [-5.0875e-01, -4.0704e-01,  2.3714e-01,  ..., -7.5518e-32,\n",
      "         -4.0876e-40, -2.4836e-01],\n",
      "        ...,\n",
      "        [ 8.9393e-01,  3.8489e-01,  1.1978e-02,  ...,  2.9096e-13,\n",
      "         -9.3472e-31, -1.1484e-02],\n",
      "        [-4.5202e-01,  3.4792e-01, -7.0209e-02,  ..., -2.9832e-16,\n",
      "          1.1536e-38,  8.7593e-02],\n",
      "        [ 3.0311e-01, -4.3730e-01, -2.9361e-01,  ...,  4.3582e-22,\n",
      "         -1.5730e-34, -8.5519e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([-0.0698,  0.2355,  0.1204,  0.2395, -0.3566,  0.8251, -0.1554,  0.1455,\n",
      "        -0.0518,  0.2196,  0.2490,  0.4466,  0.2114,  0.5974, -0.2391,  0.2867],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-3.1454e-01,  4.3306e-01,  8.8531e-02,  ...,  6.9229e-39,\n",
      "         8.1692e-39, -9.3273e-39], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([0., 0., 0.,  ..., 0., 0., -0.], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[ 3.9520e-03, -4.3983e-03, -1.1072e-03,  ..., -6.7949e-06,\n",
      "          1.1265e-05, -1.7881e-07],\n",
      "        [ 4.5547e-03, -2.4300e-03,  9.0103e-03,  ..., -1.0073e-05,\n",
      "         -6.5684e-05,  2.9922e-05],\n",
      "        [ 4.2953e-03, -4.6992e-04,  3.3455e-03,  ...,  2.2650e-06,\n",
      "          7.6890e-05,  2.3007e-04],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([ 0.0015,  0.0288,  0.0207, -0.0011,  0.0130,  0.0204,  0.0025, -0.0047,\n",
      "        -0.0004, -0.0177, -0.0111, -0.0212,  0.0026, -0.0006,  0.0161,  0.0108,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[ 1.8227e-04,  1.4320e-02,  2.1301e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-1.0198e-04,  9.5520e-03,  4.1199e-03,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-1.7977e-04, -7.6027e-03, -9.7427e-03,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 1.1468e-04, -6.6805e-04,  9.4557e-04,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 1.6153e-04,  1.4046e-02,  1.6907e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 3.7551e-05, -8.3389e-03, -7.2746e-03,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([ 0.0171,  0.0051, -0.0089,  0.0069,  0.0002, -0.0004, -0.0155,  0.0055,\n",
      "         0.0072, -0.0084,  0.0023,  0.0111,  0.0117,  0.0003,  0.0149, -0.0077],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([-0.0010,  0.0001, -0.0002,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0')}}, 2000: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([-0.0223,  0.0048, -0.0074,  ..., -0.0017,  0.0458, -0.0102],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-0.3574,  0.2644, -0.3000,  ..., -0.3062,  0.1931,  0.0355],\n",
      "        [ 0.5850, -0.3988,  0.6157,  ..., -0.0766,  0.1920,  0.2090],\n",
      "        [ 0.2259,  0.2036,  0.0863,  ...,  0.1389, -0.0986, -0.1233],\n",
      "        ...,\n",
      "        [ 0.0822,  0.2016, -0.0690,  ..., -0.2155,  0.1754,  0.1506],\n",
      "        [-0.0114,  0.2373, -0.0299,  ...,  0.1405, -0.1564, -0.0697],\n",
      "        [ 0.0216,  0.0116,  0.1878,  ...,  0.0706, -0.0622,  0.2456]],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 0.1234, -0.0063,  0.1246, -0.0389,  0.1566,  0.0915,  0.1287,  0.1746,\n",
      "         0.1021,  0.3297, -0.0246,  0.0033, -0.0414,  0.1353, -0.0361, -0.0394,\n",
      "        -0.0709,  0.1127,  0.0628,  0.1068,  0.0042,  0.2822, -0.0229,  0.1720,\n",
      "         0.0502, -0.0504,  0.0046,  0.0632, -0.0248,  0.1003,  0.1206, -0.0412,\n",
      "         0.0876,  0.0748,  0.0705, -0.0672, -0.0854, -0.0200,  0.0448,  0.0525,\n",
      "        -0.0922,  0.0886,  0.0576,  0.0383,  0.0713,  0.0802, -0.0534, -0.0151,\n",
      "         0.1152, -0.0788, -0.0285, -0.1003, -0.0405, -0.0307, -0.0474, -0.0576,\n",
      "        -0.0888, -0.0184, -0.0159,  0.0816, -0.1575,  0.0497,  0.0694,  0.0639],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-0.5137,  0.6907,  0.9890,  ..., -0.3425, -0.3472, -0.2606],\n",
      "        [-0.0732, -0.0553,  0.0696,  ...,  0.1876,  0.0709, -0.3482],\n",
      "        [ 0.2045, -0.3115,  0.1259,  ...,  0.1186,  0.2383, -0.0349],\n",
      "        ...,\n",
      "        [ 0.1700,  0.0448, -0.0081,  ..., -0.0309,  0.1643, -0.3766],\n",
      "        [ 0.1650,  0.2449,  0.0964,  ...,  0.1124,  0.1883,  0.0696],\n",
      "        [ 0.1481, -0.2582, -0.0559,  ...,  0.0987,  0.2177, -0.2545]],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([-0.0223,  0.0921,  0.1740,  0.0235, -0.1324,  0.3721,  0.0027,  0.1637,\n",
      "        -0.0763, -0.0059,  0.2586,  0.2008,  0.0850,  0.1861, -0.0918,  0.0984],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-1.6262e-01,  2.3228e-01, -1.7236e-02,  ...,  3.6535e-40,\n",
      "         1.0243e-39, -5.8234e-39], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.6093e-06,\n",
      "        -5.9605e-08,  5.9605e-08], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[ 6.8009e-05,  8.6188e-05, -6.6996e-05,  ...,  3.3379e-06,\n",
      "          1.5140e-05,  5.9605e-06],\n",
      "        [ 1.4610e-02, -1.7365e-02,  6.0005e-03,  ..., -1.4162e-04,\n",
      "          7.8142e-05,  1.6654e-04],\n",
      "        [-2.4261e-03, -3.8700e-03, -4.2572e-03,  ..., -1.5604e-04,\n",
      "          1.4722e-04,  3.0446e-04],\n",
      "        ...,\n",
      "        [ 3.5942e-05, -1.9014e-05,  1.3590e-05,  ...,  4.7684e-07,\n",
      "         -4.7684e-07,  1.1921e-07],\n",
      "        [-3.6240e-05,  2.8133e-05, -2.6226e-06,  ..., -2.3842e-07,\n",
      "         -2.8610e-06, -4.7684e-07],\n",
      "        [ 1.3504e-03, -9.5701e-04,  1.9741e-03,  ..., -2.7716e-05,\n",
      "         -3.9339e-06, -3.0994e-06]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([ 5.2565e-04,  4.6068e-02, -1.9292e-02,  1.1472e-01, -2.6864e-02,\n",
      "        -3.1344e-02, -1.8644e-04,  1.5055e-01,  1.7011e-04, -1.4044e-02,\n",
      "        -5.4951e-02,  5.5194e-05,  3.8246e-02,  7.7009e-04,  5.0882e-02,\n",
      "        -1.5457e-02, -9.4420e-04, -4.3869e-05, -5.4777e-05,  2.7579e-04,\n",
      "        -8.1064e-03,  4.7083e-03,  6.4528e-03,  1.1831e-02, -5.8507e-03,\n",
      "        -2.2599e-02,  4.2582e-04, -4.3038e-03, -2.3749e-03,  2.9023e-03,\n",
      "         2.1166e-04,  5.7530e-04,  4.2123e-04,  7.0989e-05,  1.8418e-05,\n",
      "        -2.9969e-04,  4.3660e-04, -1.1734e-03,  1.3196e-04,  7.2539e-05,\n",
      "        -5.9009e-05,  1.8001e-04,  2.9111e-04, -2.0623e-03, -2.5338e-04,\n",
      "        -1.6510e-05, -2.8497e-04, -6.7297e-03, -1.0490e-04, -1.4240e-04,\n",
      "         1.0790e-03, -6.3777e-05, -3.9458e-05, -1.1647e-03,  7.9771e-03,\n",
      "         5.8645e-04, -2.1267e-03,  5.7937e-03,  2.4333e-03,  1.7416e-04,\n",
      "        -2.6792e-03,  1.2302e-04,  2.3758e-04,  6.6248e-03], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[-6.4075e-05,  1.4885e-02,  1.3596e-02,  ..., -1.1504e-05,\n",
      "         -6.3181e-06, -4.0889e-04],\n",
      "        [ 2.0504e-05, -3.5156e-02, -2.3209e-02,  ..., -8.3447e-07,\n",
      "          5.9605e-07, -1.2755e-05],\n",
      "        [ 1.9848e-05, -1.0681e-01, -9.0393e-02,  ...,  5.9605e-08,\n",
      "         -2.4438e-06, -1.0586e-03],\n",
      "        ...,\n",
      "        [-1.2398e-05, -1.0248e-01, -9.0881e-02,  ...,  4.1723e-07,\n",
      "         -9.8348e-06, -6.6042e-04],\n",
      "        [ 5.5432e-05, -4.4281e-02, -5.3589e-02,  ..., -7.1526e-07,\n",
      "          5.1856e-06, -2.1696e-05],\n",
      "        [ 3.0696e-05,  9.4070e-03,  7.5607e-03,  ...,  1.4305e-06,\n",
      "          2.9802e-06,  3.8147e-05]], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([-0.0036, -0.0143, -0.0564, -0.0190, -0.0039, -0.0439, -0.0156,  0.0136,\n",
      "         0.0204, -0.0395, -0.0436, -0.0206, -0.0461, -0.0529, -0.0211,  0.0030],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([-0.0046, -0.0010, -0.0027,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0')}}, 2500: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([ 0.0009,  0.0005, -0.0004,  ...,  0.0306,  0.0287, -0.0697],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-0.3679,  0.1607, -0.2949,  ..., -0.2934,  0.1766,  0.0339],\n",
      "        [ 0.4798, -0.4443,  0.7053,  ..., -0.0698,  0.1603,  0.2001],\n",
      "        [ 0.3659,  0.2436, -0.0292,  ...,  0.1115, -0.0561, -0.1124],\n",
      "        ...,\n",
      "        [ 0.0902,  0.1868, -0.0702,  ..., -0.1959,  0.1553,  0.1413],\n",
      "        [-0.0106,  0.1924, -0.0550,  ...,  0.1315, -0.1402, -0.0668],\n",
      "        [-0.0545,  0.0827,  0.1336,  ...,  0.0734, -0.0587,  0.2376]],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 0.1272, -0.0168,  0.1636, -0.0313,  0.2308,  0.0788,  0.1311,  0.1877,\n",
      "         0.1035,  0.3846, -0.0376,  0.0049, -0.0264,  0.1429, -0.0257, -0.0270,\n",
      "        -0.0629,  0.1136,  0.0625,  0.1073,  0.0261,  0.2531, -0.0210,  0.1860,\n",
      "        -0.0400, -0.0544,  0.0066,  0.0497,  0.0035,  0.0846,  0.1214, -0.0428,\n",
      "         0.0875,  0.0740,  0.0709, -0.0678, -0.0860, -0.0195,  0.0442,  0.0527,\n",
      "        -0.0923,  0.0885,  0.0571,  0.0202,  0.0716,  0.0798, -0.0543, -0.0216,\n",
      "         0.1204, -0.0828, -0.0254, -0.1003, -0.0400, -0.0421, -0.0560, -0.0594,\n",
      "        -0.1006, -0.0157, -0.0496,  0.0814, -0.1747,  0.0502,  0.0687,  0.0657],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-0.5250,  0.7159,  1.0361,  ..., -0.3412, -0.3476, -0.2513],\n",
      "        [-0.0825, -0.0202,  0.0716,  ...,  0.1652,  0.0642, -0.3450],\n",
      "        [ 0.2069, -0.3438,  0.1536,  ...,  0.0971,  0.2148, -0.0230],\n",
      "        ...,\n",
      "        [ 0.2006,  0.1217,  0.0034,  ..., -0.0357,  0.1513, -0.3865],\n",
      "        [ 0.1380,  0.2932,  0.0451,  ...,  0.0976,  0.1600,  0.0498],\n",
      "        [ 0.1567, -0.3163, -0.1021,  ...,  0.0657,  0.1699, -0.2707]],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([-0.0136,  0.0881,  0.1668,  0.0551, -0.1208,  0.4275, -0.0004,  0.2684,\n",
      "        -0.0921,  0.0044,  0.2829,  0.1996,  0.0811,  0.1957, -0.1117,  0.1383],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-1.8345e-01,  3.4205e-01,  1.1039e-01,  ...,  5.0079e-40,\n",
      "        -9.5623e-40,  1.6649e-39], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "        -8.9407e-07, -1.1921e-06], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[-6.1095e-05, -1.4186e-05,  3.8743e-06,  ..., -4.4107e-06,\n",
      "         -6.8545e-06,  1.9073e-06],\n",
      "        [ 1.3222e-02, -1.0986e-02,  4.3983e-03,  ...,  1.0532e-04,\n",
      "         -8.7082e-05,  1.4901e-06],\n",
      "        [-8.9417e-03,  1.0666e-02, -1.4391e-03,  ...,  1.6940e-04,\n",
      "         -9.3699e-05, -1.0592e-04],\n",
      "        ...,\n",
      "        [ 3.7491e-05, -2.7299e-05, -9.4175e-06,  ..., -2.9802e-07,\n",
      "         -1.2517e-06,  1.1325e-06],\n",
      "        [ 6.9737e-06,  2.3842e-07,  8.6427e-06,  ..., -2.0862e-06,\n",
      "          1.7285e-06,  1.0729e-06],\n",
      "        [ 5.3072e-04, -4.4179e-04, -6.2764e-05,  ...,  7.9870e-06,\n",
      "         -9.5963e-06,  6.3777e-06]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([-2.4146e-04,  4.6491e-02, -1.4618e-02,  8.5293e-02, -1.5026e-02,\n",
      "         3.6862e-02,  3.2681e-04,  1.9335e-02,  8.7857e-05, -1.7192e-02,\n",
      "        -2.6476e-02,  7.7486e-06,  2.3278e-02,  9.5087e-04,  1.3870e-02,\n",
      "        -2.6844e-02,  5.7160e-03, -1.2892e-04, -1.1045e-04,  3.9935e-06,\n",
      "         5.8763e-03, -1.4535e-02, -4.0355e-03, -5.4145e-04,  5.4334e-03,\n",
      "        -3.1571e-03,  4.3532e-03,  4.6812e-03, -1.1211e-02,  6.1222e-03,\n",
      "        -1.0812e-04,  2.5630e-03, -2.3723e-05, -3.2723e-05, -3.8743e-06,\n",
      "        -6.4337e-04, -1.1212e-04,  1.6791e-04,  1.2457e-05, -3.8922e-05,\n",
      "        -3.7134e-05, -6.8009e-05,  2.4080e-05, -4.7932e-03, -2.6035e-04,\n",
      "        -2.5266e-04,  4.8810e-04, -1.9900e-03, -2.8253e-05,  8.2326e-04,\n",
      "        -6.2298e-03, -1.9091e-04, -1.0059e-03,  3.7014e-04,  1.1086e-04,\n",
      "         1.6170e-03,  1.3930e-04, -3.3787e-03, -6.5327e-05, -1.2410e-04,\n",
      "         5.0183e-03, -2.9683e-05,  1.9348e-04, -3.5882e-05], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[ 3.7253e-05,  2.4460e-02,  3.4149e-02,  ...,  1.7881e-06,\n",
      "          1.7405e-05, -1.0014e-05],\n",
      "        [-7.7486e-07, -5.5237e-02, -5.7587e-02,  ...,  0.0000e+00,\n",
      "          5.4240e-06,  1.5080e-05],\n",
      "        [ 2.1458e-06, -7.1777e-02, -5.9143e-02,  ...,  8.9407e-07,\n",
      "          3.6955e-06,  6.9439e-05],\n",
      "        ...,\n",
      "        [ 4.7088e-06, -3.4332e-02, -1.9730e-02,  ...,  1.2517e-06,\n",
      "          6.8545e-06,  2.5094e-05],\n",
      "        [ 1.1802e-05, -3.6774e-02, -2.7008e-02,  ...,  2.8014e-06,\n",
      "          9.5367e-06,  4.6372e-05],\n",
      "        [-1.6153e-05, -3.2501e-02, -1.1490e-02,  ..., -1.3113e-06,\n",
      "         -4.3511e-06,  4.2260e-05]], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([ 0.0165, -0.0297, -0.0386, -0.0266, -0.0142, -0.0268, -0.0197,  0.0160,\n",
      "        -0.0024, -0.0254,  0.0030,  0.0062, -0.0073, -0.0176, -0.0157, -0.0143],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([0.0007, 0.0003, 0.0002,  ..., 0.0000, 0.0000, 0.0000], device='cuda:0')}}, 3000: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([-3.1526e-02,  2.3829e-04,  6.0359e-05,  ...,  3.0565e-02,\n",
      "         9.2170e-03,  6.7545e-02], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-0.3789, -0.0303, -0.3439,  ..., -0.2766,  0.1576,  0.0330],\n",
      "        [ 0.4080, -0.4527,  0.7453,  ..., -0.0659,  0.0956,  0.1807],\n",
      "        [ 0.4591,  0.2917, -0.1263,  ...,  0.0736, -0.0057, -0.1681],\n",
      "        ...,\n",
      "        [ 0.1506,  0.1669, -0.0491,  ..., -0.1722,  0.1313,  0.1296],\n",
      "        [-0.0104,  0.1444, -0.0887,  ...,  0.1207, -0.1218, -0.0633],\n",
      "        [-0.0183,  0.0267,  0.1200,  ...,  0.0663, -0.0581,  0.2295]],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 0.1349, -0.0136,  0.2101, -0.0175,  0.3046,  0.0678,  0.1450,  0.2010,\n",
      "         0.1090,  0.4492, -0.0387,  0.0339, -0.0045,  0.1531, -0.0245, -0.0197,\n",
      "        -0.0467,  0.1197,  0.0633,  0.1123,  0.0554,  0.3050, -0.0185,  0.1945,\n",
      "        -0.1234, -0.0483,  0.0280,  0.0339,  0.0423,  0.0973,  0.1250, -0.0420,\n",
      "         0.0905,  0.0745,  0.0728, -0.0678, -0.0819, -0.0168,  0.0446,  0.0550,\n",
      "        -0.0924,  0.0902,  0.0588,  0.0016,  0.0724,  0.0805, -0.0548, -0.0113,\n",
      "         0.1282, -0.0891, -0.0263, -0.0996, -0.0391, -0.0299, -0.0476, -0.0564,\n",
      "        -0.1029, -0.0117, -0.0447,  0.0816, -0.1603,  0.0524,  0.0690,  0.0753],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-5.4810e-01,  7.2896e-01,  1.0672e+00,  ..., -3.4369e-01,\n",
      "         -3.5032e-01, -2.2906e-01],\n",
      "        [-8.3717e-02,  4.9023e-03,  6.6853e-02,  ...,  1.3230e-01,\n",
      "          5.2848e-02, -3.4362e-01],\n",
      "        [ 2.0122e-01, -3.5406e-01,  1.8696e-01,  ...,  7.1997e-02,\n",
      "          1.8447e-01, -5.7908e-02],\n",
      "        ...,\n",
      "        [ 2.3426e-01,  1.7190e-01,  1.7508e-02,  ..., -4.7587e-02,\n",
      "          1.2502e-01, -4.2023e-01],\n",
      "        [ 1.2705e-01,  3.0926e-01, -9.6098e-06,  ...,  8.2318e-02,\n",
      "          1.2769e-01, -6.8072e-03],\n",
      "        [ 1.5791e-01, -3.2993e-01, -1.7451e-01,  ...,  2.0089e-02,\n",
      "          1.2044e-01, -3.3385e-01]], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([-0.0055,  0.1032,  0.1562,  0.0734, -0.1183,  0.4651, -0.0070,  0.3243,\n",
      "        -0.0929,  0.0171,  0.2770,  0.1859,  0.0789,  0.2136, -0.1327,  0.1456],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-1.8943e-01,  3.0075e-01,  1.2257e-01,  ..., -7.9665e-40,\n",
      "         1.2288e-39,  4.6055e-39], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.7881e-07,\n",
      "         5.9605e-08, -1.1325e-06], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[-1.0073e-05,  6.6042e-05,  1.5998e-04,  ..., -3.2187e-06,\n",
      "          4.9472e-06, -6.2585e-06],\n",
      "        [-4.3716e-03, -2.2125e-04,  1.0794e-04,  ..., -1.3053e-05,\n",
      "         -1.8477e-04,  2.1636e-05],\n",
      "        [-5.6219e-04, -1.3947e-02,  6.3629e-03,  ...,  7.0393e-05,\n",
      "         -1.6618e-04,  2.2113e-05],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([-1.4305e-04,  1.3914e-02,  1.6605e-02, -1.1403e-01, -2.1774e-02,\n",
      "         1.6624e-03, -1.6133e-03,  4.6543e-02, -5.3763e-05, -3.1739e-04,\n",
      "         5.5022e-02, -3.5340e-04,  1.0365e-02,  1.3787e-04, -3.3132e-02,\n",
      "        -1.4579e-02, -5.2566e-03, -3.8791e-04,  1.0014e-05, -1.3232e-04,\n",
      "        -7.2933e-03, -3.0169e-03,  9.1702e-04, -3.9642e-03,  1.9207e-02,\n",
      "         3.2836e-03,  1.9968e-04,  9.7269e-04,  2.7934e-03, -1.5217e-02,\n",
      "        -3.4702e-04, -2.1542e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[ 9.0003e-06, -2.3712e-02, -3.7994e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-4.2379e-05,  6.6040e-02,  8.4534e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-1.0550e-05,  4.5593e-02,  5.2246e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [-1.9908e-05,  5.2582e-02,  7.6904e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-3.0160e-05,  7.7400e-03,  2.0004e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-1.4186e-05, -4.3243e-02, -6.2286e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([-0.0193,  0.0432,  0.0270, -0.0059,  0.0139,  0.0044, -0.0335, -0.0166,\n",
      "         0.0219,  0.0243, -0.0181, -0.0334,  0.0111,  0.0370,  0.0062, -0.0270],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([-5.3787e-04,  7.5519e-05, -1.6451e-03,  ...,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0')}}, 3500: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([-2.8579e-02,  1.0257e-02,  4.2543e-07,  ..., -2.4773e-03,\n",
      "         8.6763e-03, -3.6097e-03], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-0.3852, -0.1129, -0.5127,  ..., -0.2572,  0.1499,  0.0318],\n",
      "        [ 0.3638, -0.4602,  0.7412,  ..., -0.0845,  0.0652,  0.1792],\n",
      "        [ 0.5018,  0.2749, -0.1681,  ...,  0.1185, -0.0802, -0.0557],\n",
      "        ...,\n",
      "        [ 0.1503,  0.1826, -0.0616,  ..., -0.1439,  0.1057,  0.1165],\n",
      "        [ 0.0207,  0.0807, -0.1322,  ...,  0.1088, -0.1023, -0.0596],\n",
      "        [-0.0116,  0.0510,  0.0438,  ...,  0.0650, -0.0474,  0.2127]],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 0.1525, -0.0040,  0.2467, -0.0053,  0.3612,  0.0640,  0.1675,  0.2097,\n",
      "         0.1194,  0.5282, -0.0334,  0.1677,  0.0183,  0.1645, -0.0202, -0.0170,\n",
      "        -0.0166,  0.1291,  0.0648,  0.1183,  0.0834,  0.3099, -0.0126,  0.2083,\n",
      "        -0.2433, -0.0375,  0.0612,  0.0219,  0.0744,  0.1169,  0.1309, -0.0397,\n",
      "         0.0923,  0.0763,  0.0754, -0.0601, -0.0792, -0.0233,  0.0470,  0.0594,\n",
      "        -0.0920,  0.0938,  0.0626, -0.0123,  0.0746,  0.0828, -0.0532, -0.0236,\n",
      "         0.1222, -0.0887, -0.0260, -0.0987, -0.0368, -0.0177, -0.0464, -0.0593,\n",
      "        -0.1067, -0.0105, -0.0462,  0.0835, -0.1574,  0.0549,  0.0706,  0.0810],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-0.5980,  0.7336,  1.0883,  ..., -0.3541, -0.3552, -0.2052],\n",
      "        [-0.0661,  0.0169,  0.0484,  ...,  0.1142,  0.0454, -0.3602],\n",
      "        [ 0.1653, -0.3576,  0.1905,  ...,  0.0649,  0.1557, -0.0913],\n",
      "        ...,\n",
      "        [ 0.2905,  0.2021,  0.0295,  ..., -0.0421,  0.0998, -0.4632],\n",
      "        [ 0.0671,  0.3201, -0.0207,  ...,  0.0585,  0.0983, -0.0086],\n",
      "        [ 0.1527, -0.3309, -0.2180,  ..., -0.0594,  0.0770, -0.3867]],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([ 0.0011,  0.1170,  0.1455,  0.0795, -0.1325,  0.4911, -0.0170,  0.3525,\n",
      "        -0.0979,  0.0238,  0.2750,  0.1973,  0.0796,  0.2358, -0.1464,  0.1253],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-2.0601e-01,  2.9043e-01,  1.3729e-01,  ...,  8.5044e-40,\n",
      "        -2.3279e-39, -3.7318e-40], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([0., 0., 0.,  ..., 0., 0., -0.], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[-1.7166e-04,  6.2656e-04, -1.1969e-04,  ..., -5.0664e-06,\n",
      "          1.7822e-05, -3.8445e-05],\n",
      "        [-3.3932e-03,  2.6779e-03, -9.8877e-03,  ..., -1.8144e-04,\n",
      "          1.8954e-05, -3.1710e-04],\n",
      "        [ 7.1678e-03, -5.1155e-03, -7.0572e-03,  ..., -4.9472e-05,\n",
      "         -5.9307e-05,  2.1732e-04],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([-5.5641e-04, -1.7039e-02, -3.6287e-03, -9.0778e-02, -3.0543e-02,\n",
      "        -1.4834e-02, -5.0747e-04,  3.7236e-02, -4.1664e-04,  1.1543e-02,\n",
      "         1.4271e-02,  4.6819e-03, -3.3862e-02,  2.3933e-03, -1.2069e-02,\n",
      "         4.6488e-03, -7.7027e-04,  3.7277e-04, -9.8228e-05, -7.7754e-04,\n",
      "        -7.6765e-03,  1.5442e-02,  3.1549e-03, -3.7184e-03,  2.5190e-02,\n",
      "         9.4992e-04, -1.4684e-02,  2.5830e-03, -4.9409e-03, -1.3521e-02,\n",
      "         4.3803e-04, -9.8768e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[ 1.7619e-04, -6.2988e-02, -6.7444e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-2.2411e-05,  5.8289e-02,  7.2815e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-4.6194e-05,  1.0612e-02,  1.3344e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [-5.4717e-05,  6.3858e-03,  1.5495e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 8.0049e-05,  2.2003e-02,  2.8763e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 4.0412e-05, -5.9547e-03, -2.8687e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([-0.0451,  0.0392,  0.0076,  0.0021,  0.0208,  0.0013,  0.0010, -0.0392,\n",
      "         0.0241,  0.0254, -0.0114, -0.0197, -0.0137,  0.0087,  0.0149, -0.0134],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([-0.0005, -0.0010,  0.0009,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0')}}, 4000: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([ 5.1339e-10,  2.0448e-12, -3.1460e-04,  ..., -1.2668e-02,\n",
      "         6.0250e-03, -9.7254e-03], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-0.3393, -0.1827, -0.5786,  ..., -0.2373,  0.1114,  0.0323],\n",
      "        [ 0.3294, -0.4702,  0.7298,  ..., -0.0431,  0.0972,  0.1622],\n",
      "        [ 0.5490,  0.2620, -0.1919,  ...,  0.0855, -0.0053, -0.0763],\n",
      "        ...,\n",
      "        [ 0.1882,  0.1887, -0.0549,  ..., -0.1138,  0.0749,  0.1034],\n",
      "        [-0.0037,  0.0948, -0.2104,  ...,  0.0981, -0.0808, -0.0544],\n",
      "        [-0.0224,  0.0791, -0.0346,  ...,  0.0466, -0.0614,  0.2004]],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 0.1813, -0.0013,  0.2797, -0.0022,  0.3976,  0.0673,  0.2002,  0.2009,\n",
      "         0.1339,  0.6056, -0.0368,  0.2645,  0.0474,  0.1786, -0.0146, -0.0058,\n",
      "         0.0187,  0.1430,  0.0669,  0.1258,  0.1131,  0.3200, -0.0043,  0.2266,\n",
      "        -0.3813, -0.0254,  0.1105,  0.0119,  0.0946,  0.1355,  0.1404, -0.0374,\n",
      "         0.0907,  0.0786,  0.0794, -0.0598, -0.0698, -0.0191,  0.0480,  0.0577,\n",
      "        -0.0909,  0.0972,  0.0681, -0.0192,  0.0774,  0.0865, -0.0509, -0.0281,\n",
      "         0.1436, -0.0978, -0.0260, -0.0981, -0.0327,  0.0066, -0.0446, -0.0547,\n",
      "        -0.1162, -0.0066, -0.0669,  0.0858, -0.1718,  0.0589,  0.0729,  0.0891],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-0.6837,  0.7362,  1.0994,  ..., -0.3718, -0.3685, -0.1759],\n",
      "        [-0.0485,  0.0275,  0.0311,  ...,  0.0872,  0.0460, -0.3691],\n",
      "        [ 0.1400, -0.3523,  0.1958,  ...,  0.0705,  0.1312, -0.1278],\n",
      "        ...,\n",
      "        [ 0.3230,  0.2266,  0.0347,  ..., -0.0521,  0.0844, -0.5069],\n",
      "        [ 0.0325,  0.3343, -0.0297,  ...,  0.0440,  0.0568,  0.0522],\n",
      "        [ 0.2320, -0.3350, -0.2468,  ..., -0.1882,  0.0422, -0.4381]],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([ 0.0079,  0.1271,  0.1463,  0.0887, -0.1491,  0.5172, -0.0208,  0.3511,\n",
      "        -0.0972,  0.0433,  0.2850,  0.2362,  0.0912,  0.2640, -0.1550,  0.1059],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-2.2201e-01,  3.6677e-01,  7.6738e-02,  ...,  8.3311e-40,\n",
      "         1.1406e-39,  7.7526e-39], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([0., 0., -0.,  ..., 0., 0., 0.], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[-1.2922e-04, -1.4138e-04, -5.0068e-04,  ...,  1.0669e-05,\n",
      "         -1.9372e-05,  5.9605e-06],\n",
      "        [ 1.3641e-02, -1.4372e-03,  9.2621e-03,  ...,  7.7009e-05,\n",
      "         -1.5998e-04, -7.9811e-05],\n",
      "        [ 1.8799e-02,  2.4052e-03,  1.9638e-02,  ..., -3.9887e-04,\n",
      "         -2.1601e-04, -1.5378e-04],\n",
      "        ...,\n",
      "        [ 1.9431e-04, -2.7394e-04, -3.7289e-04,  ..., -1.3411e-05,\n",
      "          2.5630e-06, -2.5630e-06],\n",
      "        [-2.6524e-05,  2.8789e-05, -1.4603e-05,  ...,  6.5565e-07,\n",
      "         -5.5432e-06,  8.9407e-07],\n",
      "        [ 3.8338e-04,  5.1117e-04,  8.4543e-04,  ..., -2.2590e-05,\n",
      "          7.4565e-05,  3.6597e-05]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([-3.1766e-03,  3.4299e-02,  1.2528e-01,  4.8115e-02,  5.7410e-02,\n",
      "        -9.3222e-02, -4.8947e-04,  9.0780e-02, -1.7103e-03, -1.8784e-02,\n",
      "        -1.0423e-02,  2.3755e-02, -2.8471e-02, -1.6347e-03, -8.4121e-03,\n",
      "         6.8273e-02,  1.3379e-02, -1.2483e-03, -4.0019e-04, -1.0116e-03,\n",
      "         2.3739e-03, -1.7933e-02,  5.1552e-04,  1.2248e-02, -3.2839e-02,\n",
      "         1.1725e-02,  1.3246e-02, -3.2772e-03,  3.2318e-04,  1.0877e-02,\n",
      "        -9.8693e-04,  2.5843e-02, -9.4950e-05,  1.6928e-05, -3.5745e-04,\n",
      "         1.0505e-03,  1.0090e-03,  5.7340e-05, -1.1897e-04, -5.4151e-04,\n",
      "         2.0623e-05,  3.2789e-04, -5.2637e-04,  7.1933e-03,  1.1265e-04,\n",
      "        -2.6131e-04, -2.9671e-04, -3.0644e-03,  1.3196e-04, -8.0049e-04,\n",
      "         8.7458e-04, -1.2517e-06,  3.1569e-03, -1.0302e-03,  1.7883e-03,\n",
      "        -5.5820e-04, -5.1987e-04,  7.8682e-03,  1.9341e-03,  1.4210e-04,\n",
      "         3.6650e-03,  3.8302e-04,  2.4736e-05,  5.3325e-03], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[ 1.4782e-04,  7.7026e-02,  1.2030e-01,  ...,  2.3305e-05,\n",
      "         -2.4736e-05,  8.7357e-04],\n",
      "        [-2.7239e-05,  1.4809e-02, -3.4218e-03,  ..., -5.0306e-05,\n",
      "         -2.4438e-06,  1.0532e-04],\n",
      "        [ 1.0669e-05, -1.0712e-02, -2.5345e-02,  ..., -2.1160e-05,\n",
      "          6.9141e-06, -1.4997e-04],\n",
      "        ...,\n",
      "        [-3.6955e-05, -4.8889e-02, -7.7515e-02,  ..., -4.6611e-05,\n",
      "         -7.8678e-06, -1.2422e-04],\n",
      "        [-3.5763e-06,  3.2410e-02,  4.9316e-02,  ..., -2.1338e-05,\n",
      "          4.4107e-06,  1.5378e-04],\n",
      "        [-6.9737e-05,  2.2888e-02,  3.4027e-02,  ...,  2.2233e-05,\n",
      "         -6.2585e-06, -2.6321e-04]], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([ 0.0559,  0.0002, -0.0105,  0.0405,  0.0356, -0.0385, -0.0193, -0.0186,\n",
      "        -0.0114,  0.0272, -0.0116, -0.0216, -0.0778, -0.0369,  0.0242,  0.0152],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([-0.0001, -0.0007, -0.0012,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0')}}, 4500: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([-0.0050,  0.0014, -0.0002,  ...,  0.0046, -0.0291, -0.0359],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-0.3246, -0.1260, -0.4738,  ..., -0.2026,  0.0711,  0.0298],\n",
      "        [ 0.3123, -0.4706,  0.7203,  ..., -0.0491,  0.0105,  0.1194],\n",
      "        [ 0.5755,  0.2740, -0.2144,  ...,  0.0475, -0.0612, -0.0520],\n",
      "        ...,\n",
      "        [ 0.1395,  0.2422, -0.1095,  ..., -0.0907,  0.0587,  0.0848],\n",
      "        [ 0.0019,  0.0667, -0.2413,  ...,  0.0798, -0.0613, -0.0485],\n",
      "        [-0.0358,  0.1288, -0.0296,  ...,  0.0206, -0.0441,  0.1784]],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 0.2115,  0.0087,  0.3016,  0.0020,  0.4172,  0.0737,  0.2347,  0.2017,\n",
      "         0.1532,  0.6792, -0.0276,  0.3295,  0.0694,  0.1934,  0.0082,  0.0111,\n",
      "         0.0387,  0.1552,  0.0689,  0.1347,  0.1374,  0.3343,  0.0013,  0.2474,\n",
      "        -0.5013, -0.0078,  0.1522,  0.0047,  0.1163,  0.1431,  0.1511, -0.0381,\n",
      "         0.0901,  0.0790,  0.0820, -0.0567, -0.0536, -0.0192,  0.0481,  0.0627,\n",
      "        -0.0905,  0.1001,  0.0726, -0.0270,  0.0811,  0.0900, -0.0452, -0.0336,\n",
      "         0.1571, -0.0918, -0.0259, -0.0973, -0.0333,  0.0325, -0.0407, -0.0504,\n",
      "        -0.1175,  0.0008, -0.0773,  0.0880, -0.1704,  0.0646,  0.0729,  0.0976],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-0.8022,  0.7380,  1.1117,  ..., -0.4060, -0.3760, -0.1577],\n",
      "        [-0.0181,  0.0257,  0.0246,  ...,  0.1074,  0.0287, -0.3663],\n",
      "        [ 0.0369, -0.3514,  0.2005,  ...,  0.0633,  0.1364, -0.1454],\n",
      "        ...,\n",
      "        [ 0.2817,  0.2436,  0.0428,  ..., -0.0362,  0.0422, -0.5506],\n",
      "        [ 0.0472,  0.3418, -0.0261,  ..., -0.0153,  0.0039,  0.1105],\n",
      "        [ 0.1569, -0.3371, -0.2562,  ..., -0.1576,  0.0837, -0.3954]],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([ 0.0123,  0.1373,  0.1375,  0.0892, -0.1591,  0.5335, -0.0280,  0.3634,\n",
      "        -0.0981,  0.0655,  0.2772,  0.2543,  0.0905,  0.2815, -0.1597,  0.0770],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-2.3190e-01,  3.6605e-01,  5.9078e-02,  ..., -1.3752e-39,\n",
      "         1.5399e-39,  1.0034e-38], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([ 5.9605e-08, -5.9605e-08,  0.0000e+00,  ..., -1.1921e-07,\n",
      "         5.9605e-08, -5.9605e-08], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[ 2.0862e-04, -4.1509e-04,  1.2465e-03,  ..., -5.0664e-06,\n",
      "          5.0664e-05,  1.3947e-05],\n",
      "        [-1.3382e-02,  8.0032e-03, -1.3763e-02,  ...,  9.2149e-05,\n",
      "          1.8620e-04,  1.8382e-04],\n",
      "        [-1.7807e-02,  1.8448e-02, -9.0179e-03,  ...,  5.1916e-05,\n",
      "         -1.3208e-04,  2.6870e-04],\n",
      "        ...,\n",
      "        [-5.9009e-06,  8.4043e-06,  1.2159e-05,  ..., -2.0266e-06,\n",
      "         -6.5565e-07, -2.8610e-06],\n",
      "        [-3.2723e-05,  4.8280e-06, -1.2398e-05,  ..., -1.7881e-07,\n",
      "         -2.9802e-07, -2.9802e-07],\n",
      "        [-8.5306e-04,  9.0790e-04, -9.5081e-04,  ...,  1.9491e-05,\n",
      "         -6.7949e-06, -1.1563e-05]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([ 3.7923e-03, -6.7492e-02, -1.0976e-01,  7.3540e-03, -2.2493e-02,\n",
      "         4.3899e-02,  1.4329e-04, -2.1044e-02,  4.1404e-03,  1.7953e-02,\n",
      "        -1.9668e-03, -4.9138e-03,  7.0731e-02,  4.5009e-03, -5.9054e-03,\n",
      "        -5.1527e-02, -1.2654e-02,  2.2470e-03,  1.4603e-05,  3.5776e-03,\n",
      "         1.1994e-03,  8.7082e-03, -1.3127e-03, -2.6504e-03,  2.8714e-02,\n",
      "        -1.2545e-03, -1.1921e-06,  7.9313e-03,  1.2563e-02, -2.3221e-02,\n",
      "         1.5490e-03, -1.0601e-02, -5.5116e-04,  2.2370e-04,  1.5457e-03,\n",
      "        -1.2113e-03,  2.8415e-03,  4.2349e-04,  1.1329e-03,  9.8759e-04,\n",
      "        -3.2663e-05,  1.7802e-03,  9.3263e-04, -1.5724e-04,  1.1249e-03,\n",
      "         2.9880e-04, -8.2928e-04, -6.6102e-05,  2.2001e-03,  2.7061e-05,\n",
      "        -3.6103e-04, -9.4771e-06, -4.0709e-03, -1.2061e-02,  1.1514e-03,\n",
      "        -1.7332e-03,  3.8677e-04, -3.0509e-03, -3.0428e-04, -1.5879e-04,\n",
      "         3.6401e-04, -8.6784e-05, -1.0920e-04, -1.5647e-03], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[-2.7347e-04, -6.6589e-02, -7.5378e-02,  ...,  2.2292e-05,\n",
      "          1.9372e-05, -7.1824e-05],\n",
      "        [ 3.7849e-05,  3.0632e-03,  1.8677e-02,  ...,  2.0862e-05,\n",
      "          4.4107e-06,  3.1757e-04],\n",
      "        [ 1.6999e-04,  1.7181e-02,  1.2024e-02,  ...,  2.1100e-05,\n",
      "          0.0000e+00,  1.3721e-04],\n",
      "        ...,\n",
      "        [ 1.0508e-04,  1.4086e-03, -1.5274e-02,  ...,  1.9431e-05,\n",
      "          1.5497e-06,  3.5107e-05],\n",
      "        [-1.3697e-04, -6.8542e-02, -1.0236e-01,  ..., -2.6286e-05,\n",
      "         -2.5034e-06, -2.0123e-04],\n",
      "        [ 1.1218e-04,  4.8828e-02,  6.9458e-02,  ...,  4.0591e-05,\n",
      "         -2.7418e-06,  2.9683e-04]], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([-0.0487,  0.0079,  0.0112, -0.0343, -0.0274,  0.0440,  0.0185,  0.0211,\n",
      "         0.0171, -0.0153, -0.0095,  0.0163,  0.0059,  0.0009, -0.0532,  0.0331],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([-0.0023,  0.0013, -0.0013,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0')}}, 500: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([-0.0053,  0.0026, -0.0024,  ..., -0.0249, -0.0211,  0.0146],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-0.4644,  0.4520, -0.3450,  ..., -0.3318,  0.2195,  0.0373],\n",
      "        [ 0.6351, -0.3688,  0.4642,  ..., -0.0758,  0.2354,  0.2300],\n",
      "        [ 0.1668,  0.0067,  0.1511,  ...,  0.1944, -0.2808, -0.0673],\n",
      "        ...,\n",
      "        [ 0.0665,  0.2341, -0.0782,  ..., -0.2520,  0.2146,  0.1670],\n",
      "        [-0.0623,  0.3232,  0.0147,  ...,  0.1568, -0.1878, -0.0744],\n",
      "        [ 0.2938, -0.1730,  0.3482,  ...,  0.0764, -0.0720,  0.2607]],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 0.1199,  0.0375,  0.1298,  0.0028,  0.1030,  0.1031,  0.1232,  0.1278,\n",
      "         0.0972,  0.2121, -0.0287,  0.0151, -0.0555,  0.1235, -0.0517, -0.0365,\n",
      "        -0.0751,  0.1130,  0.0661,  0.1030, -0.0335,  0.4899, -0.0312,  0.1416,\n",
      "         0.1298, -0.0344, -0.0222,  0.0927, -0.0309,  0.1106,  0.1223, -0.0656,\n",
      "         0.0955,  0.0760,  0.0695, -0.0418, -0.0736, -0.0286,  0.0491,  0.0558,\n",
      "        -0.0861,  0.0923,  0.0570,  0.0687,  0.0741,  0.0814, -0.0402, -0.0110,\n",
      "         0.1273, -0.0299, -0.0227, -0.0976, -0.0335, -0.0466, -0.0421, -0.0472,\n",
      "        -0.0377, -0.0213,  0.0126,  0.0896, -0.1021,  0.0492,  0.0725,  0.0748],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-0.4983,  0.5690,  0.7177,  ..., -0.3448, -0.3477, -0.3096],\n",
      "        [-0.0519, -0.1267,  0.0540,  ...,  0.2266,  0.0917, -0.3361],\n",
      "        [ 0.2096, -0.3342,  0.0266,  ...,  0.1532,  0.2889, -0.0151],\n",
      "        ...,\n",
      "        [ 0.1602, -0.0911, -0.0762,  ..., -0.0307,  0.1991, -0.3313],\n",
      "        [ 0.2202,  0.2015,  0.0741,  ...,  0.1483,  0.2510,  0.0386],\n",
      "        [ 0.1145, -0.2210, -0.1037,  ...,  0.1523,  0.3061, -0.1702]],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([-0.0365,  0.0914,  0.1335,  0.0103, -0.0286,  0.1514,  0.0174, -0.0012,\n",
      "        -0.0071,  0.0490,  0.0620,  0.0966,  0.0288,  0.0960, -0.0171,  0.1074],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-1.4179e-01,  1.4830e-01, -3.6617e-01,  ...,  3.1787e-12,\n",
      "         1.3063e-12,  2.5802e-13], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "        -5.9605e-08, -5.9605e-08], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[ 2.4557e-05, -1.9848e-05,  1.4424e-05,  ..., -7.1526e-07,\n",
      "          3.0994e-06,  2.2650e-06],\n",
      "        [ 2.0340e-02, -1.7105e-02,  2.0432e-02,  ..., -7.0155e-05,\n",
      "          6.6936e-05, -3.2663e-04],\n",
      "        [ 4.3526e-03, -4.7302e-03,  3.0174e-03,  ...,  2.4974e-05,\n",
      "         -6.6876e-05, -1.9860e-04],\n",
      "        ...,\n",
      "        [ 6.1035e-05, -3.7968e-05,  3.4750e-05,  ...,  4.1723e-07,\n",
      "          1.0729e-06,  5.3644e-07],\n",
      "        [ 7.5758e-05, -5.8055e-05, -6.4969e-06,  ...,  3.3975e-06,\n",
      "          4.8280e-06,  8.7619e-06],\n",
      "        [ 9.1858e-03, -6.9046e-03,  7.6828e-03,  ..., -6.0081e-05,\n",
      "          1.4949e-04,  3.4630e-05]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([ 4.0054e-05,  1.4430e-01,  3.5691e-02,  2.2702e-01,  1.1154e-02,\n",
      "         3.0053e-04,  2.4956e-04,  1.8532e-01,  2.6232e-04, -2.5684e-04,\n",
      "        -1.4113e-01,  2.5213e-04, -9.0625e-03,  6.2567e-04,  5.7445e-02,\n",
      "        -6.5361e-02,  2.7716e-05,  2.7597e-05, -1.6272e-04,  1.2881e-04,\n",
      "        -8.8586e-03, -8.3517e-02,  3.3337e-02,  3.8754e-02, -3.3885e-04,\n",
      "        -6.7170e-02, -9.3227e-03,  1.7761e-03, -6.9935e-02,  1.0740e-01,\n",
      "         3.5757e-04,  7.2620e-02, -5.4795e-04, -7.2002e-05,  2.1172e-04,\n",
      "         1.6508e-02, -2.3042e-02, -9.7156e-06,  5.2631e-05,  5.2571e-05,\n",
      "        -9.4779e-03,  3.6478e-05,  1.7768e-04, -1.7143e-03, -6.4361e-04,\n",
      "         2.4182e-04, -3.8653e-02, -2.7871e-02, -1.2457e-05, -3.3765e-02,\n",
      "        -1.9450e-02, -2.2869e-03, -4.0864e-02, -8.7358e-03,  3.1469e-02,\n",
      "         8.5855e-03, -6.3444e-03,  3.0965e-03,  2.5796e-03, -2.7559e-03,\n",
      "         8.7829e-02,  3.5882e-04, -4.4692e-04,  4.0924e-02], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[-3.8326e-05,  1.6785e-01,  1.7041e-01,  ..., -4.6551e-05,\n",
      "         -5.9426e-05,  1.7776e-02],\n",
      "        [-7.4506e-06, -1.6528e-01, -1.5088e-01,  ..., -9.5367e-07,\n",
      "         -3.8147e-06, -1.2985e-02],\n",
      "        [-1.0192e-05, -2.3901e-01, -2.1814e-01,  ..., -1.0133e-06,\n",
      "         -8.7619e-06, -2.0630e-02],\n",
      "        ...,\n",
      "        [-1.2755e-05, -1.7334e-01, -1.5417e-01,  ..., -1.8477e-06,\n",
      "         -6.6757e-06, -1.5137e-02],\n",
      "        [-2.6226e-06, -2.2568e-02, -2.0538e-02,  ..., -2.3842e-07,\n",
      "         -4.1723e-07, -1.9064e-03],\n",
      "        [-1.6689e-06, -8.4686e-03, -3.7766e-03,  ..., -4.7684e-07,\n",
      "          2.6822e-06, -3.4189e-04]], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([ 0.0636, -0.0794, -0.1131, -0.0328,  0.0080, -0.0788, -0.0122,  0.0323,\n",
      "         0.0209, -0.0738, -0.0583, -0.0142, -0.0701, -0.0849, -0.0124, -0.0080],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([-0.0046, -0.0020, -0.0005,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0')}}, 5000: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([-3.0108e-02,  1.5429e-03,  2.3512e-05,  ...,  8.1445e-03,\n",
      "        -6.0534e-03,  1.0841e-03], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-0.2034, -0.1455, -0.1770,  ..., -0.1549,  0.0377,  0.0346],\n",
      "        [ 0.2948, -0.4756,  0.7127,  ..., -0.0407,  0.0409,  0.0844],\n",
      "        [ 0.5746,  0.2562, -0.2417,  ...,  0.0250, -0.0833, -0.1148],\n",
      "        ...,\n",
      "        [ 0.1245,  0.2609, -0.1663,  ..., -0.0703,  0.0345,  0.0697],\n",
      "        [ 0.0924,  0.0537, -0.1622,  ...,  0.0640, -0.0440, -0.0394],\n",
      "        [-0.1091,  0.1130, -0.1519,  ...,  0.0042, -0.0350,  0.1545]],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 2.6607e-01,  1.1723e-02,  3.1004e-01,  1.6433e-04,  4.2276e-01,\n",
      "         8.8561e-02,  2.7394e-01,  2.0173e-01,  1.7842e-01,  7.2027e-01,\n",
      "        -3.1675e-02,  3.2691e-01,  8.5426e-02,  2.0366e-01,  6.9170e-03,\n",
      "         2.0000e-02,  7.1666e-02,  1.7116e-01,  7.0837e-02,  1.4288e-01,\n",
      "         1.5625e-01,  2.9287e-01,  1.6305e-02,  2.5959e-01, -5.9926e-01,\n",
      "         3.9653e-03,  1.9679e-01, -9.3441e-03,  1.3829e-01,  1.3993e-01,\n",
      "         1.6275e-01, -4.1050e-02,  8.5200e-02,  7.8976e-02,  8.2822e-02,\n",
      "        -5.7713e-02, -4.0155e-02, -1.6732e-02,  4.9576e-02,  4.0772e-02,\n",
      "        -8.9402e-02,  1.0141e-01,  7.1841e-02, -3.4469e-02,  8.4057e-02,\n",
      "         8.7881e-02, -4.3184e-02, -5.6747e-02,  1.5163e-01, -9.4219e-02,\n",
      "        -2.3034e-02, -9.7012e-02, -3.7626e-02,  6.1092e-02, -4.2622e-02,\n",
      "        -5.2039e-02, -1.4654e-01, -5.5150e-03, -8.9677e-02,  8.7770e-02,\n",
      "        -1.9866e-01,  6.7430e-02,  7.6066e-02,  9.4105e-02], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-1.0384,  0.7454,  1.1260,  ..., -0.4266, -0.3992, -0.1527],\n",
      "        [ 0.0866,  0.0314,  0.0118,  ...,  0.1095,  0.0571, -0.3781],\n",
      "        [ 0.0324, -0.3523,  0.1996,  ...,  0.0906,  0.1084, -0.1545],\n",
      "        ...,\n",
      "        [ 0.3057,  0.2548,  0.0471,  ..., -0.0254,  0.0371, -0.5850],\n",
      "        [-0.0971,  0.3431, -0.0464,  ..., -0.0113, -0.0273,  0.0677],\n",
      "        [ 0.3103, -0.3367, -0.2617,  ..., -0.1647,  0.0894, -0.3236]],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([ 0.0164,  0.1486,  0.1256,  0.0967, -0.1792,  0.5610, -0.0452,  0.3467,\n",
      "        -0.0785,  0.0654,  0.2764,  0.2742,  0.0887,  0.2971, -0.1720,  0.0746],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-2.5420e-01,  4.2373e-01,  2.8917e-02,  ...,  4.6754e-40,\n",
      "        -1.8262e-39,  3.0874e-09], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.1921e-07,\n",
      "         4.1723e-07, -5.3644e-07], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[ 5.4264e-04,  1.5545e-04,  2.8229e-04,  ...,  1.1981e-05,\n",
      "         -7.8082e-06, -9.2983e-06],\n",
      "        [-1.7410e-02,  2.0279e-02, -4.6959e-03,  ...,  3.3569e-04,\n",
      "          2.3937e-04,  9.3579e-06],\n",
      "        [-2.3132e-02,  1.9821e-02, -6.4774e-03,  ...,  8.0049e-05,\n",
      "         -7.3612e-05, -2.3127e-05],\n",
      "        ...,\n",
      "        [ 1.6510e-05,  1.8370e-04,  1.0347e-04,  ...,  1.7285e-06,\n",
      "          2.8014e-06, -1.1802e-05],\n",
      "        [ 2.5988e-05, -6.3837e-05,  9.1255e-05,  ...,  1.3053e-05,\n",
      "         -5.6028e-06, -2.2650e-06],\n",
      "        [-4.0388e-04,  4.8304e-04, -2.0981e-04,  ..., -8.4043e-06,\n",
      "         -6.9141e-06,  9.3579e-06]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([-4.0561e-04, -3.5575e-02, -3.6929e-02,  5.0802e-02,  2.9563e-03,\n",
      "         2.6775e-02,  4.0430e-04,  3.8284e-02, -1.6566e-03,  6.5269e-03,\n",
      "        -1.8905e-02, -1.4457e-03,  2.2137e-02, -2.5177e-04,  1.9929e-02,\n",
      "        -2.8627e-02, -4.8792e-04, -1.2385e-03,  1.6242e-04, -4.2111e-04,\n",
      "         4.6303e-03, -7.5375e-03, -9.9443e-03, -1.3569e-03, -6.4335e-03,\n",
      "         7.7355e-03, -8.6005e-03,  5.4426e-03,  1.1099e-02, -4.3393e-03,\n",
      "        -2.3985e-04, -5.6329e-03,  2.2626e-04, -2.0152e-04, -6.7961e-04,\n",
      "        -1.1200e-03,  2.2085e-03, -1.6172e-03,  1.1320e-03, -2.2286e-04,\n",
      "         4.5300e-06, -3.8379e-04,  8.3899e-04,  3.0088e-04, -2.0802e-04,\n",
      "         4.1294e-04, -1.1780e-03, -2.1338e-04, -2.7913e-04, -3.1185e-04,\n",
      "        -7.0602e-04,  1.0133e-06, -2.9349e-03, -2.7939e-03, -1.1629e-03,\n",
      "        -8.4233e-04, -7.3910e-06,  3.8695e-04, -1.8293e-04, -2.6792e-04,\n",
      "        -1.3097e-03,  8.0371e-04,  1.2153e-04,  9.4056e-05], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[ 1.2088e-04, -3.0563e-02, -5.0974e-04,  ..., -7.0393e-05,\n",
      "          1.8299e-05, -3.5858e-04],\n",
      "        [-1.7726e-04,  4.1313e-03,  8.1787e-03,  ...,  4.7684e-07,\n",
      "         -9.1195e-06, -4.4167e-05],\n",
      "        [-8.2850e-06,  1.8677e-02,  1.0857e-02,  ...,  1.6809e-05,\n",
      "          1.7047e-05,  9.7632e-05],\n",
      "        ...,\n",
      "        [-8.6010e-05, -2.6016e-02, -4.9103e-02,  ..., -3.5763e-07,\n",
      "          3.5763e-07,  2.8372e-05],\n",
      "        [-1.5914e-05, -3.3203e-02, -4.4952e-02,  ...,  1.5140e-05,\n",
      "         -5.8413e-06, -5.4717e-05],\n",
      "        [-1.4126e-05,  1.1871e-02,  3.4271e-02,  ..., -4.5538e-05,\n",
      "         -3.3379e-06,  1.5593e-04]], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([-0.0142,  0.0010,  0.0122, -0.0113, -0.0123, -0.0064,  0.0239,  0.0181,\n",
      "         0.0199, -0.0157, -0.0156,  0.0190, -0.0513, -0.0215, -0.0256,  0.0148],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([ 0.0019, -0.0012, -0.0011,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0')}}, 5500: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([-0.0254, -0.0006, -0.0002,  ..., -0.0039, -0.0107,  0.0005],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-0.1897, -0.2257,  0.0238,  ..., -0.1147,  0.0728,  0.0236],\n",
      "        [ 0.2739, -0.4865,  0.7336,  ..., -0.0833, -0.0660, -0.0102],\n",
      "        [ 0.5823,  0.2635, -0.2426,  ...,  0.0341,  0.0962, -0.0101],\n",
      "        ...,\n",
      "        [ 0.0815,  0.3641, -0.1718,  ..., -0.0413,  0.0163,  0.0574],\n",
      "        [ 0.0307,  0.1272, -0.1334,  ...,  0.0457, -0.0104, -0.0332],\n",
      "        [-0.1267,  0.0983, -0.1842,  ..., -0.0054, -0.0145,  0.1189]],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 0.3665,  0.0176,  0.3259, -0.0052,  0.4405,  0.1104,  0.3508,  0.1956,\n",
      "         0.2158,  0.7367, -0.0573,  0.3367,  0.1164,  0.2076,  0.0099,  0.0208,\n",
      "         0.0809,  0.1961,  0.0727,  0.1536,  0.1887,  0.2859,  0.0424,  0.2736,\n",
      "        -0.6807,  0.0322,  0.2281, -0.0304,  0.1717,  0.1551,  0.1763, -0.0314,\n",
      "         0.0794,  0.0759,  0.0830, -0.0571, -0.0438, -0.0237,  0.0497,  0.0333,\n",
      "        -0.0885,  0.1061,  0.0621, -0.0340,  0.0885,  0.0850, -0.0322, -0.0061,\n",
      "         0.1705, -0.1026, -0.0189, -0.0962, -0.0285,  0.0972, -0.0399, -0.0510,\n",
      "        -0.1325,  0.0089, -0.1341,  0.0884, -0.2148,  0.0677,  0.0762,  0.0971],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-1.3694e+00,  7.4137e-01,  1.1189e+00,  ..., -4.4733e-01,\n",
      "         -4.1212e-01, -1.2119e-01],\n",
      "        [ 1.4177e-01,  4.0145e-02,  7.6468e-05,  ...,  1.6988e-01,\n",
      "          8.1822e-02, -3.5573e-01],\n",
      "        [ 9.8345e-02, -3.4627e-01,  2.0737e-01,  ...,  1.3101e-01,\n",
      "          6.2737e-02, -2.0012e-01],\n",
      "        ...,\n",
      "        [ 4.2424e-01,  2.7773e-01,  5.9854e-02,  ...,  8.0437e-03,\n",
      "          8.4435e-02, -6.0108e-01],\n",
      "        [-3.9087e-01,  3.4131e-01, -5.1120e-02,  ...,  1.1077e-02,\n",
      "         -6.9513e-02,  9.1285e-02],\n",
      "        [ 3.8906e-01, -3.3478e-01, -2.5245e-01,  ..., -1.9699e-01,\n",
      "         -2.5228e-02, -2.9416e-01]], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([ 0.0282,  0.1607,  0.1271,  0.1160, -0.2096,  0.5951, -0.0636,  0.3300,\n",
      "        -0.0600,  0.0859,  0.2826,  0.2956,  0.1016,  0.3341, -0.1836,  0.0867],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-2.9191e-01,  3.8402e-01,  5.7108e-02,  ...,  1.7561e-39,\n",
      "         1.6140e-39, -1.3732e-20], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.7881e-07,\n",
      "        -0.0000e+00, -0.0000e+00], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[-5.3635e-03,  3.7460e-03, -2.4128e-03,  ...,  2.1338e-05,\n",
      "          8.7619e-06,  1.3411e-05],\n",
      "        [ 2.5406e-02, -1.1108e-02,  5.7983e-03,  ...,  1.2839e-04,\n",
      "         -1.4353e-04,  7.9870e-06],\n",
      "        [ 1.9577e-02, -7.5493e-03,  1.3992e-02,  ...,  1.5903e-04,\n",
      "          2.2280e-04, -1.6749e-05],\n",
      "        ...,\n",
      "        [-2.1970e-04, -1.9979e-04, -2.8872e-04,  ..., -3.5167e-06,\n",
      "         -2.0862e-06, -5.8413e-06],\n",
      "        [-2.0981e-04,  1.4782e-05, -3.4451e-04,  ..., -7.1526e-07,\n",
      "         -5.0068e-06,  3.9339e-06],\n",
      "        [ 2.3422e-03, -2.6283e-03,  6.5744e-05,  ..., -3.7313e-05,\n",
      "          5.4538e-05, -1.4544e-05]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([-1.1065e-02,  4.6494e-02,  7.5482e-02,  1.2139e-02,  4.5905e-02,\n",
      "        -6.3777e-02, -1.4192e-04,  1.1059e-01, -5.1838e-04, -1.8958e-02,\n",
      "        -2.2219e-02,  7.3733e-03,  1.6299e-02, -5.6392e-04,  1.0418e-02,\n",
      "        -6.7297e-03,  3.1362e-03, -4.4483e-04,  2.3419e-04,  1.2797e-04,\n",
      "         4.6968e-04, -2.1129e-02,  6.1000e-03,  8.1174e-03, -1.9357e-02,\n",
      "        -3.5799e-04,  4.3410e-03, -8.6927e-04,  1.0301e-02,  1.3467e-02,\n",
      "         8.0109e-05,  5.8783e-03,  7.4762e-04, -1.5676e-05,  2.4933e-04,\n",
      "        -1.5439e-03, -1.0811e-03, -5.4687e-04, -7.7361e-04, -9.2065e-04,\n",
      "         7.9930e-05,  1.1277e-04, -1.9560e-03,  3.2712e-03, -2.7335e-04,\n",
      "        -2.9987e-04,  1.0454e-03, -2.2136e-03,  4.6194e-05, -6.8861e-04,\n",
      "         1.5063e-03, -1.7881e-07, -1.5860e-03,  3.4649e-03,  1.5358e-03,\n",
      "         3.2824e-04,  1.8400e-04,  6.1113e-04, -1.2910e-03,  5.0664e-04,\n",
      "         1.2088e-03, -9.9492e-04, -1.2185e-03,  3.5604e-03], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[-4.3213e-05,  7.1106e-02,  7.6538e-02,  ...,  1.2052e-04,\n",
      "          6.7353e-05,  9.0885e-04],\n",
      "        [ 1.2207e-04,  3.9520e-02,  4.6875e-02,  ...,  1.3113e-06,\n",
      "          1.7643e-05,  1.8096e-04],\n",
      "        [-6.0463e-04, -2.5375e-02, -2.8015e-02,  ..., -2.2888e-05,\n",
      "          3.0875e-05, -3.4666e-04],\n",
      "        ...,\n",
      "        [-4.0102e-04, -1.3580e-02, -1.5884e-02,  ..., -4.0293e-05,\n",
      "         -1.7881e-07, -3.0255e-04],\n",
      "        [ 2.9206e-04,  1.8555e-02,  2.4185e-02,  ...,  5.5194e-05,\n",
      "          9.0063e-05,  1.2529e-04],\n",
      "        [-2.7084e-04, -1.3145e-02,  4.7112e-03,  ..., -5.5492e-05,\n",
      "          2.6345e-05, -3.5107e-05]], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([ 0.0437,  0.0243, -0.0188,  0.0105,  0.0249, -0.0105, -0.0148,  0.0093,\n",
      "         0.0090,  0.0084, -0.0330, -0.0398, -0.0631, -0.0126,  0.0141, -0.0022],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([-7.1859e-04,  4.7684e-05,  5.2643e-04,  ...,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0')}}, 6000: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([ 4.3490e-05,  3.8393e-06, -3.0081e-09,  ...,  1.5259e-02,\n",
      "         1.6995e-04, -3.9521e-03], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-2.6131e-01, -1.7274e-01,  4.0714e-02,  ..., -3.5129e-02,\n",
      "          6.1774e-02,  1.9088e-02],\n",
      "        [ 2.7778e-01, -4.9085e-01,  7.2806e-01,  ..., -4.1541e-02,\n",
      "          9.9793e-02,  2.9068e-02],\n",
      "        [ 5.6840e-01,  2.7347e-01, -2.3553e-01,  ...,  5.7059e-02,\n",
      "         -9.1794e-02,  8.9168e-02],\n",
      "        ...,\n",
      "        [ 8.4165e-02,  2.7955e-01, -1.7338e-01,  ..., -3.9204e-02,\n",
      "          3.6335e-02,  4.8453e-02],\n",
      "        [ 6.9898e-02,  9.9959e-02, -2.3079e-01,  ...,  2.7254e-02,\n",
      "         -6.9293e-04, -2.4173e-02],\n",
      "        [-1.6243e-01,  7.7309e-02, -1.5619e-01,  ..., -1.3912e-02,\n",
      "         -4.5033e-02,  1.0558e-01]], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 0.4740,  0.0307,  0.3280, -0.0046,  0.4436,  0.1293,  0.4016,  0.1982,\n",
      "         0.2429,  0.7589, -0.0648,  0.3527,  0.1478,  0.2142,  0.0147,  0.0353,\n",
      "         0.1034,  0.2062,  0.0758,  0.1595,  0.2043,  0.3032,  0.0587,  0.2818,\n",
      "        -0.6894,  0.0587,  0.2578, -0.0308,  0.1902,  0.1548,  0.1864, -0.0325,\n",
      "         0.0675,  0.0765,  0.0783, -0.0508, -0.0181, -0.0212,  0.0381,  0.0271,\n",
      "        -0.0874,  0.1037,  0.0286, -0.0417,  0.0901,  0.0806, -0.0333,  0.0113,\n",
      "         0.1383, -0.1011, -0.0149, -0.0953, -0.0363,  0.0877, -0.0395, -0.0449,\n",
      "        -0.1151,  0.0142, -0.1925,  0.0895, -0.2539,  0.0680,  0.0726,  0.0863],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-1.6733e+00,  7.5633e-01,  1.1381e+00,  ..., -4.7279e-01,\n",
      "         -4.0422e-01, -1.2347e-01],\n",
      "        [ 2.1288e-01,  4.6482e-02, -5.8037e-03,  ...,  8.3490e-02,\n",
      "          1.0995e-01, -3.2687e-01],\n",
      "        [ 9.0015e-02, -3.4541e-01,  2.0748e-01,  ...,  1.2040e-01,\n",
      "          9.4801e-02, -1.9922e-01],\n",
      "        ...,\n",
      "        [ 4.2328e-01,  2.9011e-01,  6.2608e-02,  ..., -3.9230e-02,\n",
      "         -3.2012e-04, -5.8148e-01],\n",
      "        [-3.8681e-01,  3.3897e-01, -5.7612e-02,  ..., -5.7484e-02,\n",
      "         -4.2754e-03,  1.9367e-01],\n",
      "        [ 4.2088e-01, -3.3407e-01, -2.5161e-01,  ..., -1.1233e-01,\n",
      "          7.3867e-02, -2.0164e-01]], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([ 0.0325,  0.1674,  0.1183,  0.1303, -0.2329,  0.6218, -0.0775,  0.3233,\n",
      "        -0.0464,  0.1022,  0.2738,  0.3084,  0.1080,  0.3544, -0.1867,  0.1059],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-3.0655e-01,  3.8738e-01,  9.2860e-02,  ...,  1.5826e-39,\n",
      "        -4.6540e-40, -3.2187e-06], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([0., 0., 0.,  ..., 0., -0., 0.], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[-6.2275e-04,  1.2369e-03, -1.9016e-03,  ...,  1.9073e-05,\n",
      "          3.1054e-05, -5.1141e-05],\n",
      "        [ 1.2268e-02, -1.7166e-02, -4.0054e-03,  ...,  6.5625e-05,\n",
      "          1.9217e-04,  1.4305e-05],\n",
      "        [-2.2144e-03, -1.0132e-02, -8.9340e-03,  ...,  1.3959e-04,\n",
      "          8.9169e-05, -1.2708e-04],\n",
      "        ...,\n",
      "        [ 2.7514e-04, -8.5235e-06, -1.4961e-04,  ..., -4.6492e-06,\n",
      "          7.2122e-06,  4.5300e-06],\n",
      "        [ 2.3031e-04,  9.6738e-05, -1.2863e-04,  ...,  7.1526e-07,\n",
      "          1.7881e-07, -4.1723e-06],\n",
      "        [-6.1655e-04,  1.3046e-03, -1.2469e-04,  ..., -1.7941e-05,\n",
      "          3.8326e-05,  9.4175e-06]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([-2.4906e-03,  2.9253e-02, -2.4137e-02,  3.8638e-02,  8.4054e-04,\n",
      "        -3.8227e-02, -3.0342e-03,  2.6587e-02, -2.2176e-03, -2.0449e-03,\n",
      "         3.6708e-03,  1.0150e-02, -8.1451e-03, -5.1463e-04, -1.5838e-02,\n",
      "         1.0555e-02, -2.2730e-03,  1.0427e-03, -3.8588e-04, -7.8869e-04,\n",
      "        -8.7281e-03, -1.4759e-03,  1.1029e-03,  7.4515e-03,  8.7404e-03,\n",
      "         1.6317e-03,  7.4477e-03, -9.1385e-03, -1.9103e-03, -2.1657e-03,\n",
      "        -3.3480e-04,  2.2651e-03,  2.5975e-03, -3.5954e-04,  1.4955e-04,\n",
      "         3.2043e-04, -4.0877e-04, -1.6034e-04, -5.4419e-05,  3.9756e-04,\n",
      "         2.6822e-06,  9.9719e-05, -2.5749e-05,  1.2792e-03,  2.2721e-04,\n",
      "        -8.6784e-04, -2.6625e-03, -1.1826e-03,  9.1791e-06,  2.9039e-04,\n",
      "        -4.5121e-05,  0.0000e+00,  1.2368e-04, -1.1281e-03, -4.4107e-05,\n",
      "         1.0669e-03, -9.9730e-04, -1.3959e-03,  2.4951e-04, -6.5386e-05,\n",
      "         2.8743e-03,  3.6824e-04,  4.4602e-04, -1.3803e-03], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[-1.2279e-05, -1.3947e-02, -2.0279e-02,  ..., -4.4286e-05,\n",
      "         -2.0921e-05,  4.6611e-05],\n",
      "        [-1.9979e-04, -9.6970e-03, -2.7023e-02,  ..., -1.6689e-05,\n",
      "          3.6359e-05, -2.6107e-05],\n",
      "        [-1.8084e-04, -1.3046e-02, -3.0594e-02,  ..., -1.6391e-05,\n",
      "         -2.9802e-05, -1.7977e-04],\n",
      "        ...,\n",
      "        [-2.8467e-04, -8.2703e-03, -2.4536e-02,  ..., -3.8385e-05,\n",
      "         -5.3167e-05,  8.0824e-05],\n",
      "        [-1.5914e-05, -5.7068e-03, -2.1469e-02,  ..., -2.0146e-05,\n",
      "          4.8339e-05,  6.7770e-05],\n",
      "        [-6.8903e-05,  2.0172e-02,  3.1494e-02,  ...,  1.6332e-05,\n",
      "         -1.8537e-05, -1.1861e-04]], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([-1.1233e-02, -8.7390e-03, -1.5150e-02, -3.2888e-02, -3.3356e-03,\n",
      "        -3.4152e-02,  1.2446e-02, -2.7739e-02, -1.2193e-02,  1.5198e-05,\n",
      "        -1.9288e-02, -6.4699e-03, -2.4327e-02, -1.0164e-02, -5.3383e-03,\n",
      "         1.3405e-02], device='cuda:0'), 'mlp_head.params': tensor([-1.0481e-03,  2.9802e-05, -3.4714e-04,  ...,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0')}}, 6500: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([-2.1683e-04, -1.5453e-04, -4.3164e-05,  ...,  2.9304e-03,\n",
      "        -1.7438e-03, -2.8115e-03], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-2.9293e-01, -1.6983e-01,  9.6485e-03,  ..., -1.4441e-01,\n",
      "          2.3751e-02,  4.8693e-02],\n",
      "        [ 2.6243e-01, -4.9385e-01,  7.3218e-01,  ...,  2.2475e-02,\n",
      "          4.4986e-02, -2.9118e-02],\n",
      "        [ 5.5358e-01,  2.7689e-01, -2.6999e-01,  ...,  6.9340e-02,\n",
      "          6.8247e-02,  7.7787e-02],\n",
      "        ...,\n",
      "        [ 5.1141e-04,  2.8534e-01, -1.5787e-01,  ..., -1.2051e-02,\n",
      "          1.7763e-02,  4.5754e-02],\n",
      "        [ 3.4229e-02,  3.7429e-02, -1.6351e-01,  ...,  4.9273e-03,\n",
      "          1.0823e-02, -8.4315e-03],\n",
      "        [-1.8188e-01,  6.9224e-02, -1.5152e-01,  ...,  3.1997e-02,\n",
      "          1.9500e-02,  6.9576e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 5.4257e-01,  4.3932e-02,  3.3262e-01, -1.2409e-02,  4.5746e-01,\n",
      "         1.3130e-01,  4.1295e-01,  1.9264e-01,  2.7598e-01,  7.5643e-01,\n",
      "        -8.1901e-02,  3.5966e-01,  1.7086e-01,  2.1812e-01,  1.6983e-02,\n",
      "         3.4459e-02,  1.0265e-01,  2.1867e-01,  7.9573e-02,  1.6605e-01,\n",
      "         2.2306e-01,  2.9424e-01,  6.9983e-02,  3.0105e-01, -7.0641e-01,\n",
      "         5.2949e-02,  2.7480e-01, -4.7249e-02,  2.1741e-01,  1.7653e-01,\n",
      "         1.9497e-01, -3.3127e-02,  5.6924e-02,  7.4946e-02,  8.3292e-02,\n",
      "        -5.4240e-02,  3.8797e-04, -4.2471e-02,  3.4879e-02, -6.8237e-04,\n",
      "        -8.5482e-02,  1.0335e-01,  3.4461e-02, -6.7656e-02,  8.5877e-02,\n",
      "         7.3145e-02, -3.7725e-02,  2.7383e-02,  1.3958e-01, -9.4557e-02,\n",
      "        -8.2188e-03, -9.4112e-02, -3.4869e-02,  8.3438e-02, -3.6939e-02,\n",
      "        -5.3754e-02, -1.2324e-01,  2.3298e-02, -2.1673e-01,  8.6818e-02,\n",
      "        -2.5073e-01,  6.2989e-02,  7.0913e-02,  8.8627e-02], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-1.8791,  0.7543,  1.1456,  ..., -0.4572, -0.4359, -0.1190],\n",
      "        [ 0.2631,  0.0477, -0.0163,  ..., -0.0159, -0.0633, -0.3622],\n",
      "        [ 0.0806, -0.3563,  0.1989,  ...,  0.0223,  0.0348, -0.2234],\n",
      "        ...,\n",
      "        [ 0.4349,  0.3041,  0.0607,  ..., -0.0371, -0.0076, -0.5952],\n",
      "        [-0.4741,  0.3477, -0.0515,  ..., -0.0418,  0.0070,  0.1393],\n",
      "        [ 0.4328, -0.3382, -0.2542,  ..., -0.2615,  0.0619, -0.0511]],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([ 0.0443,  0.1784,  0.1076,  0.1399, -0.2499,  0.6541, -0.0981,  0.3188,\n",
      "        -0.0444,  0.1101,  0.2696,  0.3299,  0.1167,  0.3858, -0.1847,  0.1188],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-3.2832e-01,  3.0428e-01,  1.5285e-01,  ..., -1.8097e-39,\n",
      "        -2.1300e-39,  2.1762e-17], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[ 2.2907e-03, -3.0479e-03,  1.4458e-03,  ..., -9.3579e-06,\n",
      "         -1.9670e-06, -1.3649e-05],\n",
      "        [ 1.6586e-02, -1.1230e-02,  8.5220e-03,  ...,  4.6611e-04,\n",
      "         -1.4305e-05, -1.3340e-04],\n",
      "        [-5.1346e-03,  1.6861e-02, -9.6130e-03,  ..., -7.6711e-05,\n",
      "         -4.6372e-05, -4.3631e-05],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([ 0.0010,  0.0854, -0.0136,  0.0064,  0.0328, -0.0200, -0.0053,  0.0196,\n",
      "         0.0035, -0.0043, -0.0055,  0.0122,  0.0142, -0.0002,  0.0004, -0.0131,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[ 2.6155e-04,  1.5717e-02,  7.3059e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-3.5048e-04,  5.0621e-03,  7.7972e-03,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-6.1333e-05, -1.5160e-02, -1.8112e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 2.9516e-04,  3.9703e-02,  5.1605e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2469e-04,  3.2410e-02,  4.7668e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 3.2830e-04,  4.0474e-03, -9.3002e-03,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([ 0.0281,  0.0038, -0.0115, -0.0458, -0.0214, -0.0120, -0.0202,  0.0140,\n",
      "        -0.0044, -0.0174, -0.0270, -0.0013, -0.0054,  0.0248,  0.0209, -0.0008],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([-0.0028, -0.0006, -0.0016,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0')}}, 7000: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([ 4.0309e-09,  1.8609e-09, -1.8394e-03,  ...,  6.9439e-03,\n",
      "        -6.1782e-02, -2.1087e-02], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-3.6165e-01, -1.7702e-01, -2.9105e-02,  ...,  2.0531e-02,\n",
      "          5.6355e-02, -2.2257e-02],\n",
      "        [ 2.7140e-01, -5.1970e-01,  7.3410e-01,  ..., -1.4447e-02,\n",
      "         -6.0294e-02, -1.2531e-01],\n",
      "        [ 5.3818e-01,  2.8482e-01, -2.6350e-01,  ..., -1.0299e-01,\n",
      "          1.3043e-02,  3.4146e-02],\n",
      "        ...,\n",
      "        [-1.3204e-02,  2.4809e-01, -1.6557e-01,  ...,  1.1244e-02,\n",
      "          1.2430e-02,  2.7122e-02],\n",
      "        [-2.2388e-02, -2.7980e-03, -1.8066e-01,  ..., -1.9203e-02,\n",
      "          3.8250e-04, -1.0539e-02],\n",
      "        [-2.4530e-01,  9.6561e-02, -2.4480e-01,  ...,  1.9791e-02,\n",
      "         -7.4496e-03,  4.3826e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 0.6378,  0.0529,  0.3498, -0.0135,  0.4654,  0.1479,  0.4770,  0.1811,\n",
      "         0.3177,  0.7586, -0.0926,  0.3409,  0.1936,  0.2091,  0.0294,  0.0087,\n",
      "         0.1034,  0.2356,  0.0810,  0.1692,  0.2532,  0.3017,  0.1026,  0.3070,\n",
      "        -0.7442,  0.0823,  0.3129, -0.0486,  0.2374,  0.1861,  0.1957, -0.0391,\n",
      "         0.0378,  0.0537,  0.0747, -0.0686,  0.0055, -0.0498,  0.0295, -0.0387,\n",
      "        -0.0826,  0.0946,  0.0191, -0.0656,  0.0865,  0.0656, -0.0372,  0.0417,\n",
      "         0.0882, -0.0971, -0.0087, -0.0926, -0.0346,  0.0861, -0.0414, -0.0475,\n",
      "        -0.1023,  0.0335, -0.2700,  0.0794, -0.2865,  0.0589,  0.0559,  0.0656],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-2.0777,  0.7469,  1.1319,  ..., -0.4167, -0.3896, -0.1903],\n",
      "        [ 0.2686,  0.0473, -0.0181,  ..., -0.0330, -0.0283, -0.3066],\n",
      "        [ 0.0605, -0.3524,  0.2039,  ...,  0.0033,  0.0595, -0.2151],\n",
      "        ...,\n",
      "        [ 0.4200,  0.3138,  0.0602,  ..., -0.0688,  0.2164, -0.5667],\n",
      "        [-0.4908,  0.3432, -0.0544,  ...,  0.0037,  0.0987,  0.3763],\n",
      "        [ 0.2887, -0.3389, -0.2461,  ..., -0.0973,  0.0488,  0.0077]],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([ 0.0666,  0.1808,  0.1103,  0.1636, -0.2779,  0.6801, -0.1086,  0.3083,\n",
      "        -0.0380,  0.1328,  0.2678,  0.3477,  0.1299,  0.4109, -0.2026,  0.1292],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-3.4615e-01,  2.2768e-01,  1.9608e-01,  ..., -1.0947e-39,\n",
      "         3.4776e-39,  2.4230e-09], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[-5.9080e-04, -1.4687e-03, -6.3848e-04,  ..., -4.4167e-05,\n",
      "         -4.9949e-05, -8.5413e-05],\n",
      "        [-5.2338e-03,  3.8376e-03, -5.2681e-03,  ..., -4.9710e-05,\n",
      "          2.4498e-05,  2.8133e-05],\n",
      "        [-9.7046e-03,  6.8893e-03, -1.3000e-02,  ...,  1.6236e-04,\n",
      "          9.3877e-05, -2.8014e-06],\n",
      "        ...,\n",
      "        [-1.0133e-05, -9.0241e-05, -4.8220e-05,  ..., -3.5763e-07,\n",
      "         -2.3246e-06, -9.7752e-06],\n",
      "        [ 1.8513e-04, -1.6201e-04, -6.1274e-05,  ..., -1.6093e-06,\n",
      "          1.6093e-06, -5.9605e-08],\n",
      "        [-5.2977e-04,  3.3236e-04, -3.0804e-04,  ..., -1.7881e-06,\n",
      "         -1.4603e-05,  5.9605e-08]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([-1.1532e-03, -2.2506e-02, -3.6930e-02,  6.0958e-02,  1.7704e-03,\n",
      "         3.8753e-02,  5.0533e-03, -1.3775e-01, -3.9061e-03, -4.9208e-03,\n",
      "         6.9695e-03, -6.0958e-03, -2.0422e-02,  2.1767e-03, -1.0900e-02,\n",
      "         1.2195e-02, -6.2166e-03, -1.5979e-03, -5.3710e-04, -1.8436e-04,\n",
      "         7.5696e-03, -8.7804e-03,  4.5181e-03, -1.3854e-02, -2.4319e-03,\n",
      "         7.3197e-03,  1.8808e-02,  3.1141e-03, -3.3879e-03, -2.4435e-03,\n",
      "         1.2279e-04, -1.5730e-04,  1.3524e-04,  5.4479e-05, -2.4694e-04,\n",
      "         6.3545e-04,  2.1180e-03,  2.0808e-04, -3.0935e-05, -5.1856e-06,\n",
      "         6.9320e-05, -2.8193e-04,  4.2748e-04, -1.2716e-03,  7.5698e-06,\n",
      "         5.7125e-04,  2.4800e-03,  3.0857e-03, -3.4869e-05,  2.7806e-04,\n",
      "        -1.9097e-04,  0.0000e+00, -4.1052e-03,  2.8324e-04, -1.0529e-03,\n",
      "        -1.4287e-03,  1.4289e-03, -1.5364e-03, -1.2853e-03,  2.2793e-04,\n",
      "         8.9175e-04, -8.7857e-04,  1.2171e-04, -1.9523e-03], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[ 8.2636e-04, -1.6418e-02, -5.6305e-03,  ...,  9.5904e-05,\n",
      "         -2.2590e-05, -1.2279e-04],\n",
      "        [-2.4891e-04, -6.8787e-02, -8.2153e-02,  ..., -1.9014e-05,\n",
      "         -1.4663e-05,  7.5161e-05],\n",
      "        [ 3.0971e-04,  1.4282e-02,  7.9956e-03,  ..., -1.3232e-05,\n",
      "         -6.0201e-06,  5.3823e-05],\n",
      "        ...,\n",
      "        [ 5.4932e-04,  2.7191e-02,  5.2414e-03,  ..., -4.7088e-06,\n",
      "         -9.2983e-06,  2.1768e-04],\n",
      "        [-2.4700e-04, -4.6387e-02, -4.0283e-02,  ..., -3.7432e-05,\n",
      "          5.4836e-06, -1.7643e-05],\n",
      "        [ 4.3201e-04,  1.1032e-02,  2.2446e-02,  ...,  1.0848e-05,\n",
      "         -6.9737e-06,  3.0935e-05]], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([-0.0008, -0.0471,  0.0072, -0.0205, -0.0369,  0.0060,  0.0291,  0.0048,\n",
      "        -0.0168,  0.0052,  0.0320,  0.0574,  0.0295,  0.0109, -0.0258,  0.0103],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([ 0.0013, -0.0015, -0.0006,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0')}}, 7500: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([ 2.0432e-21, -7.4128e-21,  2.0836e-07,  ...,  2.1760e-02,\n",
      "         8.7236e-03, -1.7386e-02], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-0.4029, -0.1858, -0.0739,  ..., -0.0061, -0.0676, -0.0061],\n",
      "        [ 0.2603, -0.5284,  0.7358,  ..., -0.0708,  0.0824, -0.0333],\n",
      "        [ 0.5160,  0.2778, -0.2736,  ..., -0.0513, -0.0500,  0.0443],\n",
      "        ...,\n",
      "        [-0.0271,  0.1716, -0.1859,  ...,  0.0042,  0.0024,  0.0121],\n",
      "        [-0.0248,  0.1025, -0.1196,  ..., -0.0057,  0.0072, -0.0071],\n",
      "        [-0.2436,  0.1392, -0.1939,  ..., -0.0253,  0.0662,  0.0345]],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 0.6696,  0.0677,  0.3586, -0.0185,  0.4711,  0.1541,  0.4571,  0.1742,\n",
      "         0.3362,  0.7387, -0.1030,  0.3663,  0.2091,  0.1921,  0.0397,  0.0188,\n",
      "         0.1181,  0.2305,  0.0815,  0.1721,  0.2714,  0.2996,  0.1157,  0.3164,\n",
      "        -0.7323,  0.0793,  0.3425, -0.0523,  0.2239,  0.1953,  0.2023, -0.0247,\n",
      "         0.0205,  0.0572,  0.0786, -0.0750,  0.0332, -0.0644,  0.0225, -0.0352,\n",
      "        -0.0808,  0.0899, -0.0231, -0.0771,  0.0849,  0.0541, -0.0245,  0.0446,\n",
      "         0.0729, -0.1232,  0.0088, -0.0907, -0.0358,  0.1098, -0.0411, -0.0429,\n",
      "        -0.1201,  0.0605, -0.3176,  0.0752, -0.3389,  0.0489,  0.0619,  0.0660],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-2.2530e+00,  7.6212e-01,  1.1432e+00,  ..., -3.5758e-01,\n",
      "         -4.0403e-01, -2.1495e-01],\n",
      "        [ 3.3237e-01,  4.7309e-02, -2.4869e-02,  ..., -2.9944e-02,\n",
      "          1.2665e-03, -2.2063e-01],\n",
      "        [-1.7317e-02, -3.5549e-01,  2.0600e-01,  ..., -1.2372e-02,\n",
      "          8.8905e-03, -2.2602e-01],\n",
      "        ...,\n",
      "        [ 4.6523e-01,  3.2544e-01,  5.7000e-02,  ..., -4.4350e-02,\n",
      "          7.9024e-02, -4.8562e-01],\n",
      "        [-4.5738e-01,  3.4484e-01, -5.4612e-02,  ..., -1.4685e-02,\n",
      "          2.3130e-02,  3.5362e-01],\n",
      "        [ 3.7869e-01, -3.4355e-01, -2.4756e-01,  ..., -8.6393e-02,\n",
      "          2.9815e-02, -5.4809e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([ 0.0841,  0.1858,  0.1055,  0.1793, -0.2812,  0.7027, -0.1203,  0.3005,\n",
      "        -0.0357,  0.1428,  0.2747,  0.3611,  0.1453,  0.4376, -0.2006,  0.1404],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-3.5085e-01,  2.5356e-01,  2.5272e-01,  ..., -1.4410e-39,\n",
      "         1.7707e-39,  1.6743e-04], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -5.9605e-08,\n",
      "        -5.9605e-08, -1.1921e-07], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[-6.6681e-03,  7.9346e-03, -5.4245e-03,  ...,  1.8716e-05,\n",
      "          5.0843e-05,  5.0604e-05],\n",
      "        [ 4.9316e-02, -3.4882e-02,  2.2415e-02,  ..., -1.5593e-04,\n",
      "          1.6868e-05, -6.7353e-05],\n",
      "        [-1.0597e-02, -1.3170e-03,  6.0234e-03,  ...,  1.9598e-04,\n",
      "          1.2153e-04,  1.7560e-04],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([-0.0189,  0.1173,  0.0209,  0.1028,  0.0094, -0.0159,  0.0037,  0.2023,\n",
      "        -0.0048, -0.0127, -0.0325,  0.0295, -0.0096, -0.0060,  0.0402,  0.0197,\n",
      "         0.0038, -0.0016, -0.0014, -0.0012, -0.0040, -0.0106, -0.0069,  0.0227,\n",
      "        -0.0170,  0.0021,  0.0109, -0.0164,  0.0123,  0.0043, -0.0014,  0.0043,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[ 0.0006,  0.0568,  0.0724,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0003, -0.0106,  0.0002,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0009, -0.0938, -0.1052,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.0009, -0.0542, -0.0390,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0007,  0.0372,  0.0514,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0009, -0.0471, -0.0319,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([ 0.0437, -0.0093, -0.0672, -0.0229, -0.0026, -0.0621, -0.0252,  0.0330,\n",
      "        -0.0044, -0.0336, -0.0589, -0.0389, -0.0893, -0.0357,  0.0282, -0.0291],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([-0.0007, -0.0004,  0.0002,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0')}}, 8000: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([-3.4948e-32, -2.4338e-32, -4.3733e-18,  ..., -8.2872e-02,\n",
      "        -1.6004e-03,  2.4793e-03], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-0.4032, -0.1673, -0.0850,  ...,  0.0214,  0.0022, -0.0423],\n",
      "        [ 0.2648, -0.5324,  0.7465,  ...,  0.1390,  0.0167, -0.0292],\n",
      "        [ 0.5047,  0.2945, -0.2747,  ..., -0.0276,  0.1202, -0.0227],\n",
      "        ...,\n",
      "        [-0.0642,  0.1660, -0.1372,  ...,  0.0081, -0.0013,  0.0035],\n",
      "        [-0.0292,  0.0315, -0.0737,  ..., -0.0019,  0.0051, -0.0014],\n",
      "        [-0.1934,  0.0965, -0.2418,  ...,  0.0685, -0.0040,  0.0560]],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 7.2316e-01,  7.0103e-02,  3.5065e-01, -2.5614e-02,  4.6282e-01,\n",
      "         1.6332e-01,  4.8388e-01,  1.6749e-01,  3.6917e-01,  7.0453e-01,\n",
      "        -1.1499e-01,  3.4636e-01,  2.2216e-01,  1.5011e-01,  3.2398e-02,\n",
      "         4.6076e-03,  1.2800e-01,  2.3421e-01,  8.0722e-02,  1.7517e-01,\n",
      "         2.9669e-01,  2.7831e-01,  1.2692e-01,  3.1123e-01, -7.3538e-01,\n",
      "         1.0833e-01,  3.5564e-01, -6.2304e-02,  2.2429e-01,  2.0739e-01,\n",
      "         2.0483e-01, -4.2416e-02,  3.8128e-04,  4.1478e-02,  6.0759e-02,\n",
      "        -7.7848e-02,  4.3041e-02, -7.5724e-02,  8.3113e-03, -6.0724e-02,\n",
      "        -7.6673e-02,  7.3902e-02, -4.9535e-02, -9.2029e-02,  7.4964e-02,\n",
      "         4.6539e-02, -1.1376e-02,  4.8129e-02,  3.5938e-02, -1.3026e-01,\n",
      "         2.3665e-02, -8.8382e-02, -3.4189e-02,  1.4888e-01, -5.6770e-02,\n",
      "        -3.9156e-02, -1.1433e-01,  7.3164e-02, -3.4806e-01,  6.3072e-02,\n",
      "        -3.5723e-01,  4.1279e-02,  6.1825e-02,  3.9695e-02], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-2.3822e+00,  7.6385e-01,  1.1451e+00,  ..., -2.8120e-01,\n",
      "         -4.3552e-01, -2.2381e-01],\n",
      "        [ 4.2455e-01,  5.5741e-02, -2.7045e-02,  ...,  8.3833e-03,\n",
      "          8.0361e-04, -2.8249e-01],\n",
      "        [-7.9556e-02, -3.5621e-01,  2.0647e-01,  ...,  5.9514e-03,\n",
      "          9.4965e-03, -2.5362e-01],\n",
      "        ...,\n",
      "        [ 5.3474e-01,  3.2645e-01,  5.2011e-02,  ..., -2.0659e-02,\n",
      "          2.4537e-02, -5.2983e-01],\n",
      "        [-4.7736e-01,  3.4401e-01, -5.9937e-02,  ..., -3.1723e-02,\n",
      "         -3.6103e-02,  2.2145e-01],\n",
      "        [ 3.3740e-01, -3.5162e-01, -2.5921e-01,  ..., -3.9175e-02,\n",
      "          4.0806e-03, -1.2398e-03]], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([ 0.0925,  0.1974,  0.1053,  0.1846, -0.3022,  0.7260, -0.1288,  0.2764,\n",
      "        -0.0281,  0.1474,  0.2782,  0.3817,  0.1519,  0.4603, -0.2148,  0.1515],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-3.6434e-01,  2.9171e-01,  2.2002e-01,  ..., -3.8618e-39,\n",
      "        -1.1924e-39, -3.0698e-13], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 1.7881e-07,\n",
      "        1.1921e-07], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[ 7.5989e-03, -3.8815e-03,  2.8000e-03,  ..., -3.1590e-06,\n",
      "          2.1398e-05, -3.1412e-05],\n",
      "        [ 3.1982e-02, -2.8915e-02, -1.8587e-03,  ...,  3.5286e-05,\n",
      "         -2.6727e-04, -1.1206e-05],\n",
      "        [-1.4526e-02,  2.0401e-02, -8.7814e-03,  ...,  3.3236e-04,\n",
      "         -1.1790e-04,  3.4428e-04],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([ 0.0087,  0.0395, -0.0235,  0.1084, -0.0533,  0.0560,  0.0001,  0.0829,\n",
      "        -0.0009, -0.0016, -0.0059,  0.0044, -0.0222,  0.0028,  0.0095,  0.0152,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[-0.0017,  0.0038,  0.0035,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0006, -0.0357, -0.0320,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0007, -0.0629, -0.0637,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.0005, -0.0649, -0.0646,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0003, -0.0394, -0.0331,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0004, -0.0570, -0.0702,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([-0.0108, -0.0229, -0.0463, -0.0285, -0.0089, -0.0593,  0.0007, -0.0102,\n",
      "        -0.0025, -0.0255, -0.0044,  0.0139, -0.0768, -0.0447, -0.0197, -0.0458],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([0.0030, 0.0005, 0.0016,  ..., 0.0000, 0.0000, 0.0000], device='cuda:0')}}, 8500: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([ 2.6063e-40, -7.4121e-40,  1.7574e-05,  ...,  1.3320e-02,\n",
      "        -1.9694e-02,  2.7887e-02], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-0.4087, -0.1291, -0.1322,  ..., -0.1518, -0.0671, -0.0390],\n",
      "        [ 0.2688, -0.5463,  0.7369,  ...,  0.0301, -0.1199, -0.0364],\n",
      "        [ 0.4911,  0.2990, -0.2639,  ...,  0.0641, -0.0491, -0.0331],\n",
      "        ...,\n",
      "        [-0.0451,  0.0941, -0.1111,  ...,  0.0021, -0.0016, -0.0025],\n",
      "        [-0.1262,  0.0423, -0.1193,  ..., -0.0147,  0.0088,  0.0054],\n",
      "        [-0.2158,  0.0791, -0.2861,  ...,  0.0310,  0.0208,  0.0377]],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 0.7721,  0.0755,  0.3549, -0.0266,  0.4735,  0.1744,  0.5151,  0.1598,\n",
      "         0.4227,  0.7278, -0.1043,  0.3567,  0.2489,  0.1101,  0.0604, -0.0034,\n",
      "         0.1391,  0.2414,  0.0778,  0.1674,  0.3122,  0.2759,  0.1536,  0.3187,\n",
      "        -0.7642,  0.1196,  0.3903, -0.0700,  0.2258,  0.2084,  0.2113, -0.0434,\n",
      "        -0.0318,  0.0257,  0.0608, -0.0584,  0.0250, -0.0934,  0.0073, -0.0553,\n",
      "        -0.0747,  0.0715, -0.0480, -0.0876,  0.0749,  0.0321, -0.0136,  0.0514,\n",
      "         0.0185, -0.1638,  0.0330, -0.0854, -0.0331,  0.0981, -0.0605, -0.0351,\n",
      "        -0.0960,  0.0848, -0.3563,  0.0620, -0.4142,  0.0369,  0.0556,  0.0138],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-2.5099e+00,  7.5752e-01,  1.1347e+00,  ..., -2.1402e-01,\n",
      "         -4.0297e-01, -2.0845e-01],\n",
      "        [ 3.9218e-01,  4.5421e-02, -3.3966e-02,  ..., -1.0264e-02,\n",
      "          1.1700e-03, -2.9175e-01],\n",
      "        [-1.0345e-01, -3.4898e-01,  2.0661e-01,  ..., -8.7013e-03,\n",
      "          2.3811e-03, -2.4084e-01],\n",
      "        ...,\n",
      "        [ 5.6990e-01,  3.3583e-01,  4.8197e-02,  ..., -1.1311e-02,\n",
      "          2.0902e-02, -5.2697e-01],\n",
      "        [-5.8266e-01,  3.4257e-01, -6.0095e-02,  ..., -1.4412e-02,\n",
      "         -5.4895e-03,  2.8255e-01],\n",
      "        [ 2.8345e-01, -3.5306e-01, -2.5299e-01,  ..., -4.5372e-03,\n",
      "         -5.8505e-03,  1.0397e-01]], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([ 0.1163,  0.1975,  0.1086,  0.2011, -0.3218,  0.7496, -0.1397,  0.2839,\n",
      "        -0.0440,  0.1590,  0.2784,  0.4008,  0.1676,  0.4864, -0.2208,  0.1717],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-3.5748e-01,  3.4449e-01,  2.0348e-01,  ..., -2.3502e-39,\n",
      "         2.9018e-39,  2.7987e-13], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -5.9605e-08,\n",
      "        -0.0000e+00, -5.9605e-08], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[-1.8501e-03,  4.5776e-03, -1.6260e-04,  ..., -1.1075e-04,\n",
      "         -1.1802e-05,  2.3723e-05],\n",
      "        [ 4.7302e-02, -3.0380e-02, -9.5062e-03,  ...,  1.2529e-04,\n",
      "          1.4234e-04,  4.6432e-05],\n",
      "        [ 6.2065e-03, -8.8043e-03,  1.5144e-02,  ...,  1.5235e-04,\n",
      "         -5.5492e-05,  3.1471e-05],\n",
      "        ...,\n",
      "        [ 1.2517e-06, -3.3379e-06, -5.3644e-07,  ..., -1.1921e-07,\n",
      "          4.1723e-07, -3.5763e-07],\n",
      "        [-1.1444e-05,  1.6272e-05, -2.6584e-05,  ..., -1.0133e-06,\n",
      "         -8.9407e-07,  1.7881e-07],\n",
      "        [ 8.8811e-06,  3.0327e-04,  6.7711e-04,  ..., -9.5367e-07,\n",
      "          6.6757e-06,  4.6492e-06]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([-3.0614e-03,  6.5947e-02,  5.6087e-02,  5.9635e-02, -1.3465e-02,\n",
      "        -3.0894e-02,  2.0325e-03,  2.0337e-01, -9.1946e-04, -1.3259e-03,\n",
      "        -6.8580e-03,  2.7490e-02, -7.3375e-03, -4.8498e-03,  1.5646e-02,\n",
      "         1.7618e-02, -1.6940e-03, -9.5838e-04,  1.0014e-04, -6.1440e-04,\n",
      "        -7.4439e-03, -1.6282e-02, -3.3159e-03,  2.7175e-02, -2.3353e-02,\n",
      "         6.5088e-04, -7.8989e-03, -9.7334e-03,  3.4434e-03, -5.7870e-03,\n",
      "         3.9514e-03,  5.4018e-03,  3.6746e-03,  3.6442e-04, -4.1467e-04,\n",
      "         5.6940e-04,  2.1006e-03, -3.5578e-04,  6.3181e-06, -3.8087e-04,\n",
      "        -1.0437e-04,  6.0320e-05, -1.8457e-03,  1.6570e-05,  9.1165e-04,\n",
      "        -2.4039e-04, -2.2505e-03, -8.5548e-03,  1.4901e-06,  2.2566e-04,\n",
      "        -3.2376e-03,  0.0000e+00, -2.3757e-03, -4.3127e-03, -1.5144e-03,\n",
      "        -3.9852e-04, -3.0059e-03,  1.0867e-03,  8.2195e-04,  5.3942e-05,\n",
      "        -1.0274e-03,  1.6332e-05, -4.7803e-05,  9.5630e-04], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[-6.9237e-04,  8.0948e-03,  3.8239e-02,  ..., -7.7486e-07,\n",
      "         -1.0729e-06,  2.8110e-04],\n",
      "        [-1.0008e-04,  1.5900e-02,  1.8265e-02,  ..., -5.3644e-07,\n",
      "         -2.6226e-06, -6.1393e-06],\n",
      "        [-8.6737e-04, -4.4312e-02, -5.0293e-02,  ..., -4.7684e-07,\n",
      "         -1.1921e-07,  4.7088e-06],\n",
      "        ...,\n",
      "        [-1.2827e-03, -4.6722e-02, -3.7048e-02,  ..., -5.9605e-07,\n",
      "         -1.1921e-06, -7.1168e-05],\n",
      "        [ 2.7895e-04,  2.1637e-02,  4.3182e-02,  ..., -3.5763e-07,\n",
      "          1.0133e-06, -1.8382e-04],\n",
      "        [-9.2411e-04, -2.3270e-02, -2.6550e-02,  ..., -5.9605e-08,\n",
      "         -2.8014e-06, -6.9678e-05]], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([ 0.0175,  0.0100, -0.0356,  0.0076,  0.0108, -0.0672, -0.0333, -0.0053,\n",
      "        -0.0042, -0.0030, -0.0447, -0.0385, -0.1170, -0.0342,  0.0224, -0.0223],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([0.0010, 0.0009, 0.0011,  ..., 0.0000, 0.0000, 0.0000], device='cuda:0')}}, 9000: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([ 7.2629e-40, -5.8656e-41, -3.5111e-17,  ...,  1.6807e-02,\n",
      "        -1.7320e-02, -4.3803e-04], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-4.7333e-01, -1.2673e-01, -1.8619e-01,  ...,  3.5054e-02,\n",
      "          1.4799e-01, -6.0439e-02],\n",
      "        [ 2.6850e-01, -5.4817e-01,  7.3976e-01,  ..., -5.5811e-02,\n",
      "          1.3548e-02,  1.1836e-01],\n",
      "        [ 4.7955e-01,  2.9321e-01, -2.5444e-01,  ...,  2.8643e-03,\n",
      "         -7.2315e-04, -2.7903e-02],\n",
      "        ...,\n",
      "        [-1.5378e-01,  1.4450e-01, -5.9088e-02,  ...,  5.9879e-04,\n",
      "         -8.1653e-03,  5.3052e-03],\n",
      "        [-1.0704e-01,  3.9827e-02, -9.7069e-02,  ..., -2.8761e-02,\n",
      "         -2.2983e-02,  1.1654e-02],\n",
      "        [-2.6463e-01, -7.8309e-03, -2.2050e-01,  ..., -1.2170e-01,\n",
      "         -5.3735e-02, -7.3720e-03]], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 0.8006,  0.0865,  0.3615, -0.0291,  0.4760,  0.1835,  0.5091,  0.1490,\n",
      "         0.4713,  0.7087, -0.0988,  0.3606,  0.2702,  0.0741,  0.0510, -0.0064,\n",
      "         0.1611,  0.2348,  0.0768,  0.1646,  0.3350,  0.2843,  0.1496,  0.3500,\n",
      "        -0.7691,  0.1402,  0.4065, -0.0515,  0.2107,  0.2095,  0.2020, -0.0166,\n",
      "        -0.0654,  0.0163,  0.0417, -0.0805, -0.0129, -0.0885,  0.0064, -0.0587,\n",
      "        -0.1194,  0.0574, -0.0930, -0.0948,  0.0476,  0.0160, -0.0114,  0.0443,\n",
      "         0.0081, -0.1841,  0.0253, -0.0818, -0.0426,  0.0606, -0.0442, -0.0361,\n",
      "        -0.1439,  0.1267, -0.3887,  0.0551, -0.4134,  0.0242,  0.0444,  0.0015],\n",
      "       device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-2.5669e+00,  7.6313e-01,  1.1341e+00,  ..., -8.7783e-02,\n",
      "         -3.5065e-01, -2.9262e-01],\n",
      "        [ 4.1941e-01,  4.6016e-02, -3.8083e-02,  ...,  1.1967e-01,\n",
      "          1.2273e-02, -2.8740e-01],\n",
      "        [-2.2932e-01, -3.5554e-01,  2.0721e-01,  ...,  6.0226e-03,\n",
      "          1.7873e-03, -2.0330e-01],\n",
      "        ...,\n",
      "        [ 5.6897e-01,  3.4220e-01,  4.4951e-02,  ...,  1.5577e-01,\n",
      "          5.4170e-02, -3.7063e-01],\n",
      "        [-5.1731e-01,  3.4038e-01, -6.0655e-02,  ...,  2.5072e-02,\n",
      "          2.3415e-02,  3.3430e-01],\n",
      "        [ 3.1529e-01, -3.5915e-01, -2.5109e-01,  ...,  2.1132e-03,\n",
      "         -1.2813e-02,  1.1100e-01]], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([ 0.1461,  0.2027,  0.1030,  0.2201, -0.3433,  0.7773, -0.1551,  0.2803,\n",
      "        -0.0344,  0.1707,  0.2754,  0.4202,  0.1790,  0.5110, -0.2367,  0.1915],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-3.7364e-01,  2.7021e-01,  2.2939e-01,  ...,  1.0293e-38,\n",
      "        -1.3073e-27, -9.6147e-12], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., -0.0000e+00, 5.9605e-08,\n",
      "        -0.0000e+00], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[-4.8294e-03,  6.9141e-05,  1.6375e-03,  ...,  7.6354e-05,\n",
      "         -1.1921e-05,  5.3644e-06],\n",
      "        [-2.9648e-02,  1.9440e-02, -3.2745e-02,  ..., -5.7042e-05,\n",
      "          1.0318e-04, -2.2292e-05],\n",
      "        [-8.2779e-03,  1.9302e-02, -3.0838e-02,  ...,  9.5129e-05,\n",
      "         -8.1003e-05,  3.9577e-05],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([ 2.3350e-03, -1.1929e-01, -9.2274e-02, -1.3390e-01, -3.1676e-02,\n",
      "         4.6514e-02, -3.0812e-03, -1.4563e-01,  3.4225e-04,  1.6842e-02,\n",
      "         2.7863e-02, -1.1538e-02, -9.9313e-04,  1.2540e-02, -4.4089e-02,\n",
      "         1.9426e-03, -1.3712e-02, -7.0733e-04, -1.2295e-03, -3.2467e-04,\n",
      "        -7.2467e-03,  2.0325e-02, -7.1147e-03, -2.2492e-02,  3.8118e-02,\n",
      "        -9.6979e-03, -5.6015e-03,  7.6280e-03, -1.5991e-02, -1.2616e-02,\n",
      "        -1.0473e-04, -4.8741e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[ 0.0004, -0.1074, -0.1360,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0002,  0.0142,  0.0181,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0004,  0.1059,  0.1326,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0004,  0.0103,  0.0072,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0004, -0.0118, -0.0062,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0007,  0.0448,  0.0315,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([-0.0793,  0.0093,  0.0702, -0.0194,  0.0203,  0.0584,  0.0203, -0.0221,\n",
      "        -0.0033,  0.0182,  0.0514,  0.0245,  0.0903,  0.0097, -0.0073,  0.0299],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([ 0.0020, -0.0003,  0.0015,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0')}}, 9500: {'params': OrderedDict([('aabb', tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')), ('direction_encoding.params', tensor([], device='cuda:0')), ('mlp_base.encoding.params', tensor([ 3.8531e-40,  6.1780e-40,  1.3689e-28,  ...,  7.7783e-03,\n",
      "        -5.3331e-04,  7.1601e-03], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.weight', tensor([[-4.8137e-01, -1.2107e-01, -1.6080e-01,  ..., -6.6737e-02,\n",
      "         -3.2735e-02,  5.8764e-02],\n",
      "        [ 2.6872e-01, -5.6152e-01,  7.3446e-01,  ...,  9.2467e-02,\n",
      "          1.8794e-02,  8.7550e-02],\n",
      "        [ 4.6426e-01,  3.0540e-01, -2.6090e-01,  ..., -6.5558e-02,\n",
      "          3.0734e-02,  4.3906e-02],\n",
      "        ...,\n",
      "        [-1.0537e-01,  6.2463e-02, -5.0384e-02,  ...,  2.2118e-03,\n",
      "         -1.5297e-04,  3.0389e-04],\n",
      "        [-8.9246e-02,  7.3220e-02, -8.1259e-02,  ...,  1.5900e-03,\n",
      "         -5.9011e-03, -3.0787e-03],\n",
      "        [-2.7673e-01, -4.3483e-02, -2.3909e-01,  ..., -7.2836e-02,\n",
      "          5.8778e-02,  2.6005e-02]], device='cuda:0')), ('mlp_base.elastic_mlp.hidden_layers.0.bias', tensor([ 8.4532e-01,  8.9545e-02,  3.5542e-01, -3.4024e-02,  4.7099e-01,\n",
      "         1.8843e-01,  5.0983e-01,  1.4724e-01,  4.7804e-01,  6.8200e-01,\n",
      "        -1.1586e-01,  3.7980e-01,  2.7765e-01,  4.8990e-02,  6.4320e-02,\n",
      "        -1.7123e-02,  1.8329e-01,  2.2021e-01,  8.2243e-02,  1.4231e-01,\n",
      "         3.5840e-01,  2.7245e-01,  1.3928e-01,  3.4218e-01, -7.6247e-01,\n",
      "         1.2203e-01,  4.1229e-01, -4.8873e-02,  2.1883e-01,  2.0481e-01,\n",
      "         1.8196e-01, -1.9907e-02, -8.2478e-02,  1.1352e-02,  3.1225e-02,\n",
      "        -8.0481e-02, -1.7982e-02, -1.0719e-01, -5.9827e-03, -6.2903e-02,\n",
      "        -1.1567e-01,  4.3672e-02, -9.9684e-02, -1.0332e-01,  5.0385e-02,\n",
      "         9.8643e-04,  1.2205e-02,  4.4898e-02,  4.7313e-04, -1.9288e-01,\n",
      "         2.9651e-02, -7.7367e-02, -4.6487e-02,  1.1826e-01, -2.8418e-02,\n",
      "        -3.1893e-02, -1.3528e-01,  1.6840e-01, -3.8414e-01,  3.7974e-02,\n",
      "        -4.3799e-01,  1.9755e-02,  3.3932e-02, -5.6055e-02], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.weight', tensor([[-2.6723e+00,  7.6854e-01,  1.1416e+00,  ..., -5.4562e-02,\n",
      "         -2.9246e-01, -3.4089e-01],\n",
      "        [ 4.5057e-01,  4.6285e-02, -3.7447e-02,  ..., -6.4190e-03,\n",
      "          2.8122e-04, -1.8957e-01],\n",
      "        [-2.4371e-01, -3.5967e-01,  2.1123e-01,  ..., -3.0002e-02,\n",
      "          1.6725e-03, -2.1458e-01],\n",
      "        ...,\n",
      "        [ 6.4071e-01,  3.4890e-01,  4.0615e-02,  ..., -4.0127e-03,\n",
      "          1.6455e-02, -3.3497e-01],\n",
      "        [-6.0715e-01,  3.3956e-01, -6.0116e-02,  ..., -6.0188e-02,\n",
      "          1.1427e-02,  2.0202e-01],\n",
      "        [ 2.8381e-01, -3.5834e-01, -2.4457e-01,  ..., -4.2807e-02,\n",
      "         -4.8931e-03,  2.2478e-01]], device='cuda:0')), ('mlp_base.elastic_mlp.output_layer.bias', tensor([ 0.1637,  0.2040,  0.1033,  0.2233, -0.3550,  0.7930, -0.1633,  0.2818,\n",
      "        -0.0386,  0.1725,  0.2712,  0.4253,  0.1902,  0.5324, -0.2433,  0.2055],\n",
      "       device='cuda:0')), ('mlp_head.params', tensor([-3.6751e-01,  3.3878e-01,  2.0513e-01,  ..., -3.9433e-39,\n",
      "         2.2698e-12, -1.7021e-10], device='cuda:0'))]), 'gradients': {'direction_encoding.params': tensor([], device='cuda:0'), 'mlp_base.encoding.params': tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -3.5763e-07,\n",
      "        -0.0000e+00,  0.0000e+00], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.weight': tensor([[-3.8910e-03, -1.5144e-03, -1.4420e-03,  ...,  3.4273e-05,\n",
      "         -2.4736e-05,  7.1287e-05],\n",
      "        [-1.1612e-02,  1.1299e-02, -1.5587e-02,  ..., -1.0908e-05,\n",
      "          1.1027e-05, -2.3961e-04],\n",
      "        [-1.6006e-02,  2.3514e-02, -1.7090e-02,  ..., -1.4114e-04,\n",
      "          2.4557e-05, -3.7766e-04],\n",
      "        ...,\n",
      "        [-5.9605e-08,  0.0000e+00,  5.9605e-08,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 2.8014e-06,  3.2783e-06, -1.0550e-05,  ...,  1.1325e-06,\n",
      "          0.0000e+00,  2.9802e-07],\n",
      "        [ 5.0259e-04, -1.0862e-03,  3.3665e-04,  ..., -1.2040e-05,\n",
      "          3.8743e-06,  1.7583e-05]], device='cuda:0'), 'mlp_base.elastic_mlp.hidden_layers.0.bias': tensor([-2.8669e-03, -4.3234e-02, -8.8003e-02, -2.6220e-02,  9.9552e-04,\n",
      "         4.9715e-02, -7.6991e-03, -5.9542e-02, -2.2352e-03,  6.9106e-04,\n",
      "        -9.0817e-03, -7.8976e-04,  1.5169e-02,  2.3761e-03, -1.9762e-02,\n",
      "         6.4170e-03, -3.9783e-03, -1.9503e-04, -1.3425e-03,  1.8120e-05,\n",
      "         1.6199e-03,  4.3111e-03, -3.0554e-03, -8.0252e-03,  1.4286e-02,\n",
      "         4.4746e-03, -4.2874e-04,  3.4591e-03, -1.9580e-03,  1.3024e-04,\n",
      "        -2.5033e-03, -6.5708e-03,  9.4992e-04,  1.2934e-05, -1.2976e-04,\n",
      "         7.6169e-04, -2.5602e-03, -5.9605e-08,  5.9605e-08,  3.6359e-05,\n",
      "         0.0000e+00, -5.3644e-06, -7.3075e-05, -2.4903e-03,  2.5910e-04,\n",
      "         2.4879e-04,  1.0721e-03,  3.4511e-03, -1.1921e-07, -2.3878e-04,\n",
      "         1.6264e-03,  0.0000e+00, -4.6068e-04, -1.4518e-03, -1.6833e-03,\n",
      "        -6.5202e-04, -1.4949e-04, -1.3611e-03,  6.6853e-04, -1.9073e-06,\n",
      "        -1.8938e-03, -2.9802e-07,  4.9770e-05,  1.2846e-03], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.weight': tensor([[ 8.5783e-04, -3.5736e-02, -4.7394e-02,  ...,  0.0000e+00,\n",
      "          4.0531e-06, -3.9530e-04],\n",
      "        [ 1.1480e-04, -1.2808e-03,  1.3779e-02,  ...,  0.0000e+00,\n",
      "         -1.1921e-07, -1.8334e-04],\n",
      "        [ 3.3319e-05,  1.1101e-02,  1.3283e-02,  ...,  0.0000e+00,\n",
      "         -3.5763e-07, -1.1474e-04],\n",
      "        ...,\n",
      "        [ 2.8896e-04,  1.3969e-02,  1.5173e-03,  ...,  0.0000e+00,\n",
      "          1.3113e-06, -1.1170e-04],\n",
      "        [ 5.9426e-05, -1.7349e-02, -2.4689e-02,  ...,  0.0000e+00,\n",
      "         -8.3447e-07, -2.5368e-04],\n",
      "        [ 4.8661e-04,  3.3295e-02,  3.8055e-02,  ...,  0.0000e+00,\n",
      "          4.8280e-06, -5.3883e-05]], device='cuda:0'), 'mlp_base.elastic_mlp.output_layer.bias': tensor([-0.0312,  0.0038,  0.0083, -0.0296,  0.0068,  0.0387,  0.0132,  0.0057,\n",
      "        -0.0004, -0.0319,  0.0257,  0.0135,  0.0249,  0.0059, -0.0116,  0.0243],\n",
      "       device='cuda:0'), 'mlp_head.params': tensor([-9.7871e-05,  1.7703e-04,  5.9509e-04,  ...,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0')}}}})\n"
     ]
    }
   ],
   "source": [
    "ordered_steps = sorted(list(run_weights_grads[\"radiance_field\"].keys()))\n",
    "radiance_fields = run_weights_grads[\"radiance_field\"]\n",
    "print(run_weights_grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scene': 'ficus',\n",
       " 'device': 'cuda:0',\n",
       " '_target': '__main__.NGPOccTrainer',\n",
       " 'dataset': {'name': 'blender',\n",
       "  'scene': 'ficus',\n",
       "  'data_root': '/home/user/shared/nerfstudio/data/blender',\n",
       "  'far_plane': 10000000000.0,\n",
       "  'grid_nlvl': 1,\n",
       "  'alpha_thre': 0,\n",
       "  'cone_angle': 0,\n",
       "  'near_plane': 0,\n",
       "  'aabb_coeffs': [-1.5, -1.5, -1.5, 1.5, 1.5, 1.5],\n",
       "  'train_split': 'train',\n",
       "  'optimizer_lr': 0.01,\n",
       "  'weight_decay': 1e-05,\n",
       "  'optimizer_eps': 1e-15,\n",
       "  'subject_loader': 'elastic_nerf.nerfacc.datasets.nerf_synthetic.SubjectLoader',\n",
       "  'grid_resolution': 128,\n",
       "  'init_batch_size': 1024,\n",
       "  'scheduler_gamma': 0.33,\n",
       "  'test_chunk_size': 8192,\n",
       "  'render_step_size': 0.005,\n",
       "  'test_dataset_kwargs': {},\n",
       "  'train_dataset_kwargs': {},\n",
       "  'scheduler_total_iters': 100,\n",
       "  'scheduler_start_factor': 0.01,\n",
       "  'target_sample_batch_size': 262144,\n",
       "  'num_dynamic_batch_warmup_steps': 20},\n",
       " 'log_dir': '/home/user/shared/nerfstudio/wandb_cache',\n",
       " 'exp_name': '2024-02-15-17-12-28',\n",
       " 'max_steps': 20000,\n",
       " 'hidden_dim': 64,\n",
       " 'model_path': None,\n",
       " 'host_machine': 'citrus',\n",
       " 'project_name': 'elastic-nerf',\n",
       " 'num_log_steps': 500,\n",
       " 'radiance_field': {'base': {'_target': 'elastic_nerf.nerfacc.radiance_fields.mlp.ElasticMLP',\n",
       "   'bias_init': 'torch.nn.init.zeros_',\n",
       "   'hidden_init': 'torch.nn.init.xavier_uniform_',\n",
       "   'output_init': 'torch.nn.init.xavier_uniform_',\n",
       "   'bias_enabled': True,\n",
       "   'hidden_activation': 'ReLU()',\n",
       "   'output_activation': None},\n",
       "  '_target': 'elastic_nerf.nerfacc.radiance_fields.ngp.NGPRadianceField',\n",
       "  'use_elastic': True},\n",
       " 'num-train-widths': 4,\n",
       " 'num_train_widths': 4,\n",
       " 'sampling-strategy': 'exp-reverse',\n",
       " 'sampling_strategy': 'exp-reverse',\n",
       " 'num_eval_all_steps': 5000,\n",
       " 'eval_elastic_widths': [64, 32, 16, 8],\n",
       " 'num-widths-to-sample': 1,\n",
       " 'num_checkpoint_steps': 10000,\n",
       " 'num_widths_to_sample': 1,\n",
       " 'radiance-field.use-elastic': True}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del '_target' in run.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_l1_norm(tensor):\n",
    "    return tensor.abs().sum()\n",
    "\n",
    "\n",
    "def compute_l2_norm(tensor):\n",
    "    return torch.sqrt((tensor**2).sum())\n",
    "\n",
    "\n",
    "def compute_frobenius_norm(tensor):\n",
    "    return torch.norm(tensor, \"fro\")\n",
    "\n",
    "\n",
    "def compute_spectral_norm(tensor):\n",
    "    # For tensors that are not 2D, we need to reshape them appropriately.\n",
    "    # The common approach is to view them as a matrix where one dimension is the 'feature' dimension\n",
    "    # and the other aggregates all other dimensions.\n",
    "    if tensor.dim() != 2:\n",
    "        # Assume the first dimension is the 'feature' dimension and flatten the rest.\n",
    "        tensor = tensor.view(tensor.size(0), -1)\n",
    "\n",
    "    # Compute the spectral norm (largest singular value)\n",
    "    u, s, v = torch.svd(tensor, compute_uv=False)\n",
    "    return s.max().item()\n",
    "\n",
    "\n",
    "def visualize_norms(norms_dict, title=\"Norms Visualization\"):\n",
    "    labels, values = zip(*norms_dict.items())\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(labels, values, color=\"skyblue\")\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.ylabel(\"Norm Value\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp_base.elastic_mlp.hidden_layers.0.weight torch.Size([64, 32])\n",
      "mlp_base.elastic_mlp.hidden_layers.0.bias torch.Size([64])\n",
      "mlp_base.elastic_mlp.output_layer.weight torch.Size([16, 64])\n",
      "mlp_base.elastic_mlp.output_layer.bias torch.Size([16])\n",
      "mlp_base.elastic_mlp.hidden_layers.0.weight torch.Size([64, 32])\n",
      "mlp_base.elastic_mlp.hidden_layers.0.bias torch.Size([64])\n",
      "mlp_base.elastic_mlp.output_layer.weight torch.Size([16, 64])\n",
      "mlp_base.elastic_mlp.output_layer.bias torch.Size([16])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filter 'mlp_base' parameters and gradients\n",
    "mlp_base_params = {\n",
    "    name: tensor\n",
    "    for name, tensor in params_dict[\"params\"].items()\n",
    "    if name.startswith(\"mlp_base.elastic_mlp\")\n",
    "}\n",
    "mlp_base_grads = {\n",
    "    name: tensor\n",
    "    for name, tensor in params_dict[\"gradients\"].items()\n",
    "    if name.startswith(\"mlp_base.elastic_mlp\")\n",
    "}\n",
    "\n",
    "# Initialize dictionaries to store norms\n",
    "weights_norms = {}\n",
    "grads_norms = {}\n",
    "\n",
    "# Compute norms for 'mlp_base' weights\n",
    "for name, tensor in mlp_base_params.items():\n",
    "    print(name, tensor.shape)\n",
    "    # weights_norms[f'{name} L1'] = compute_l1_norm(tensor).item()\n",
    "    weights_norms[f\"{name} L2\"] = compute_l2_norm(tensor).item()\n",
    "    weights_norms[f\"{name} Fro\"] = compute_frobenius_norm(tensor).item()\n",
    "    weights_norms[f\"{name} Spec\"] = compute_spectral_norm(tensor)\n",
    "\n",
    "# Compute norms for 'mlp_base' gradients\n",
    "for name, tensor in mlp_base_grads.items():\n",
    "    print(name, tensor.shape)\n",
    "    # grads_norms[f'{name} L1'] = compute_l1_norm(tensor).item()\n",
    "    grads_norms[f\"{name} L2\"] = compute_l2_norm(tensor).item()\n",
    "    grads_norms[f\"{name} Fro\"] = compute_frobenius_norm(tensor).item()\n",
    "    grads_norms[f\"{name} Spec\"] = compute_spectral_norm(tensor)\n",
    "\n",
    "# Visualize norms for 'mlp_base' weights and gradients\n",
    "visualize_norms(weights_norms, \"MLP Base Weights Norms Visualization\")\n",
    "visualize_norms(grads_norms, \"MLP Base Gradients Norms Visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('aabb',\n",
       "              tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')),\n",
       "             ('direction_encoding.params', tensor([], device='cuda:0')),\n",
       "             ('mlp_base.encoding.params',\n",
       "              tensor([-0.0524,  0.0649, -0.0417,  ..., -0.0345,  0.0275,  0.0005],\n",
       "                     device='cuda:0')),\n",
       "             ('mlp_base.elastic_mlp.hidden_layers.0.weight',\n",
       "              tensor([[-0.2936,  0.3607, -0.1735,  ..., -0.4993,  0.4694,  0.2571],\n",
       "                      [ 0.6481, -0.3079,  0.5560,  ..., -0.2090,  0.3847,  0.3557],\n",
       "                      [ 0.4086, -0.5158,  0.4631,  ..., -0.1006,  0.0544,  0.0539],\n",
       "                      ...,\n",
       "                      [ 0.1088,  0.2196, -0.0533,  ..., -0.2910,  0.2519,  0.1855],\n",
       "                      [ 0.0242,  0.2957,  0.1008,  ...,  0.1412, -0.1653, -0.0571],\n",
       "                      [ 0.1781, -0.0493,  0.1350,  ...,  0.0667, -0.0790,  0.2647]],\n",
       "                     device='cuda:0')),\n",
       "             ('mlp_base.elastic_mlp.hidden_layers.0.bias',\n",
       "              tensor([ 0.0990,  0.1136,  0.1232,  0.0969,  0.2931,  0.1104,  0.2307, -0.0039,\n",
       "                       0.0635,  0.1884, -0.0845,  0.2397, -0.1002,  0.0913, -0.1282, -0.0826,\n",
       "                      -0.0266,  0.0671,  0.0419,  0.0584, -0.0568,  0.0851, -0.0475,  0.0531,\n",
       "                       0.0784, -0.0821, -0.0999,  0.0465, -0.0907,  0.0562,  0.0883, -0.0975,\n",
       "                       0.0612,  0.0434,  0.0426, -0.0730, -0.0385, -0.0260,  0.0346,  0.0341,\n",
       "                      -0.0652,  0.0558,  0.0432,  0.0434,  0.0417,  0.0478, -0.0736, -0.0370,\n",
       "                       0.0290, -0.0299, -0.0481, -0.0394, -0.0461, -0.0259, -0.0647, -0.0768,\n",
       "                       0.0026, -0.0481,  0.0373,  0.0539, -0.0224,  0.0377,  0.0412,  0.0497],\n",
       "                     device='cuda:0')),\n",
       "             ('mlp_base.elastic_mlp.output_layer.weight',\n",
       "              tensor([[-0.6854,  0.7001,  0.7986,  ..., -0.3042, -0.3333, -0.2259],\n",
       "                      [-0.1724,  0.0273,  0.3445,  ...,  0.1888,  0.0432, -0.3549],\n",
       "                      [ 0.2881, -0.2947,  0.0932,  ...,  0.0925,  0.1915,  0.1235],\n",
       "                      ...,\n",
       "                      [ 0.0597,  0.1201,  0.1987,  ..., -0.0970,  0.1165, -0.2964],\n",
       "                      [ 0.1497,  0.1628,  0.1386,  ...,  0.1309,  0.1970,  0.0332],\n",
       "                      [-0.1386, -0.1357, -0.1284,  ...,  0.0970,  0.2269, -0.0031]],\n",
       "                     device='cuda:0')),\n",
       "             ('mlp_base.elastic_mlp.output_layer.bias',\n",
       "              tensor([ 0.0091, -0.0141,  0.0857,  0.0267,  0.0071, -0.0590,  0.0679, -0.0783,\n",
       "                      -0.0364, -0.0330, -0.0387,  0.1181, -0.0168,  0.0098, -0.0181,  0.0171],\n",
       "                     device='cuda:0')),\n",
       "             ('mlp_head.params',\n",
       "              tensor([-2.4881e-01, -2.0479e-01, -1.0365e-01,  ...,  3.1787e-12,\n",
       "                       1.3063e-12,  2.5802e-13], device='cuda:0'))])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_dict[\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
