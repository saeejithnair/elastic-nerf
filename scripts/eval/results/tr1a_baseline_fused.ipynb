{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elastic_nerf.utils import wandb_utils as wu\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "sweep_mappings = {\n",
    "    \"2uxektzo\": \"ngp_occ-mipnerf360-baseline\",\n",
    "    # \"kebumdc0\": \"ngp_occ-mipnerf360-baseline\",\n",
    "    \"xxjsfkbw\": \"ngp_prop-mipnerf360-baseline\",\n",
    "    # \"8w0wks0x\": \"ngp_prop-mipnerf360-baseline\",\n",
    "    # \"qfkjdvv2\": \"ngp_occ-mipnerf360-sampling_single\",\n",
    "    # \"hy03dx0e\": \"ngp_occ-mipnerf360-sampling\",\n",
    "    # \"wsxh6gjo\": \"ngp_prop-mipnerf360-sampling\",\n",
    "    # \"8ishbvau\": \"ngp_prop-mipnerf360-sampling_single\",\n",
    "    # \"b674pjcs\": \"ngp_occ-mipnerf360-baseline_head_depth1\",\n",
    "    # \"58hgroe5\": \"ngp_prop-mipnerf360-baseline_head_depth1\",\n",
    "    # \"c6g1mc5g\": \"ngp_occ-mipnerf360-baseline-mup\",\n",
    "    # \"ccrwhsr5\": \"ngp_prop-mipnerf360-baseline-mup\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TR1a_Baseline_Fused\n",
    "This experiment benchmarks the baseline for the Nerfacc NGP Occ and Nerfacc Prop models on all scenes from the Mip-NeRF 360 dataset. Similar to Matformer, we sample exponentially spaced widths of $d={64, 32, 16, 8}$ (with $d=64$ being the baseline full-width) and evaluate the performance of both the Nerfacc-Occ and Nerfacc-Prop models after naively shrinking every linear layer to these widths. The goal here is to understand how much of a performance drop there is when you train with a much smaller model. Note that models at all widths are trained using the same hyperparameters (batch size, learning rate, etc) as the baseline full-width implementation. While this is not going to result in optimally tuned small width models, keep in mind that our overarching goal is to be able to train models of multiple widths optimally and simultaneously, but before that, we need to establish baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m(gonas) [WARNING] Using cached results for sweep 2uxektzo\u001b[0m\n",
      "\u001b[93m(gonas) [WARNING] Using cached results for sweep xxjsfkbw\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to results_tr1a_baseline_fused.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2206211/685674255.py:46: DtypeWarning: Columns (117,141,205,207,215,219,220) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(fp)\n"
     ]
    }
   ],
   "source": [
    "tables = [\"EvalResultsSummarytable\"]\n",
    "sweeps = sweep_mappings.keys()\n",
    "results_cache_dir = Path(\"/home/user/shared/results/elastic-nerf\")\n",
    "sweep_results = {}\n",
    "\n",
    "for sweep in sweeps:\n",
    "    sweep_results[sweep] = wu.fetch_sweep_results(\n",
    "        sweep=sweep,\n",
    "        refresh_cache=False,\n",
    "        download_history=True,\n",
    "        tables=tables,\n",
    "        results_cache_dir=results_cache_dir,\n",
    "    )\n",
    "all_history = []\n",
    "# Create a dataframe with all the results\n",
    "for sweep_name in sweep_results:\n",
    "    for run in sweep_results[sweep_name]:\n",
    "        # Flatten the config\n",
    "        flat_config = wu.flatten_dict(run.config, sep=\".\")\n",
    "        # Concatenate the config with each row of the history results\n",
    "        # Note that history results are already a dataframe\n",
    "        history = run.history\n",
    "        history[\"sweep_id\"] = sweep_name\n",
    "        history[\"run_id\"] = run.run_id\n",
    "        history[\"model_type\"] = (\n",
    "            \"ngp_prop\" if \"prop\" in sweep_mappings[sweep_name] else \"ngp_occ\"\n",
    "        )\n",
    "        history[\"sweep_name\"] = sweep_mappings[sweep_name]\n",
    "        for key in flat_config:\n",
    "            try:\n",
    "                history[key] = str(flat_config[key])\n",
    "            except:\n",
    "                print(f\"Failed to add {key} to history with value {flat_config[key]}\")\n",
    "                raise\n",
    "        all_history.append(history)\n",
    "\n",
    "# %%\n",
    "# Concatenate all the history results into a single dataframe\n",
    "final_df = pd.concat(all_history, ignore_index=True)\n",
    "\n",
    "\n",
    "# %%\n",
    "fp = f\"results_tr1a_baseline_fused.csv\"\n",
    "final_df.to_csv(fp, index=False)\n",
    "print(f\"Saved results to {fp}\")\n",
    "df = pd.read_csv(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "Looking at the following Table, we can see that in general, across scenes and models, the smaller width architectures perform more poorly than larger width architectures. On average, decreasing the size of the Nerfacc Prop model to width of 8 seems to have a larger reduction in average PSNR compared to the Nerfacc Occ model, potentially due to the presence of the 2 proposal networks (which are also being shrunk). On the other hand, the Nerfacc Occ model uses the NGP hash grid estimator (which we do not reduce in size), potentially resulting in it being more robust against downstream width reductions. One exception to the overall trend is results on the Stump scene for the Nerfacc Occ model where the width 16 model does a lot more poorly than the Width 8 model. This will require additional scrutiny in a future experiment.\n",
    "\n",
    "But overall though, it seems that even after shrinking all the layers to width 8, the performance drop on all scenes is less than 9\\% compared to their respective baselines. Given that's not terrible, how much smaller are we making these networks anyway? For that, let's take a look at the parameter counts of both the Nerfacc Occ and Nerfacc Prop models for each stage and compare the architectural complexity at full width vs reduced widths.\n",
    "\n",
    "## Issues\n",
    "After running the experiment, I realized that I had created non-elastic (aka fused NGP) versions of all the models. At the time, I thought this would be appropriate because I was trying to benchmark the baseline. However, due to the way tiny-cuda-nn implements padding, this meant that the small width layers (for models with more than 2 hidden layers) would get padded to the nearest block size, and these would actually be trainable parameters. I think this is only really relevant for the width 8 models, but this could explain why the width 16 for stump does worse than the width 8 (not necessarily because the width 8 is bigger, but now we have more confounding variabels). I will be re-running this baseline benchmarking again, but this time using my native PyTorch implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_28844\">\n",
       "  <caption>PSNR values after 20k steps of training for NGP Occ model at different widths across scenes from the MipNeRF-360 dataset.  Values in brackets are the percentage difference compared to the baseline PSNR for each model at full-size (width 64).</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_28844_level0_col0\" class=\"col_heading level0 col0\" >Scene</th>\n",
       "      <th id=\"T_28844_level0_col1\" class=\"col_heading level0 col1\" >Width 64</th>\n",
       "      <th id=\"T_28844_level0_col2\" class=\"col_heading level0 col2\" >Width 32</th>\n",
       "      <th id=\"T_28844_level0_col3\" class=\"col_heading level0 col3\" >Width 16</th>\n",
       "      <th id=\"T_28844_level0_col4\" class=\"col_heading level0 col4\" >Width 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_28844_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_28844_row0_col0\" class=\"data row0 col0\" >Bicycle</td>\n",
       "      <td id=\"T_28844_row0_col1\" class=\"data row0 col1\" >22.37</td>\n",
       "      <td id=\"T_28844_row0_col2\" class=\"data row0 col2\" >22.12 (-1.13%)</td>\n",
       "      <td id=\"T_28844_row0_col3\" class=\"data row0 col3\" >22.01 (-1.61%)</td>\n",
       "      <td id=\"T_28844_row0_col4\" class=\"data row0 col4\" >21.74 (-2.86%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28844_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_28844_row1_col0\" class=\"data row1 col0\" >Bonsai</td>\n",
       "      <td id=\"T_28844_row1_col1\" class=\"data row1 col1\" >29.35</td>\n",
       "      <td id=\"T_28844_row1_col2\" class=\"data row1 col2\" >29.12 (-0.80%)</td>\n",
       "      <td id=\"T_28844_row1_col3\" class=\"data row1 col3\" >28.38 (-3.31%)</td>\n",
       "      <td id=\"T_28844_row1_col4\" class=\"data row1 col4\" >27.76 (-5.41%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28844_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_28844_row2_col0\" class=\"data row2 col0\" >Counter</td>\n",
       "      <td id=\"T_28844_row2_col1\" class=\"data row2 col1\" >26.56</td>\n",
       "      <td id=\"T_28844_row2_col2\" class=\"data row2 col2\" >26.31 (-0.94%)</td>\n",
       "      <td id=\"T_28844_row2_col3\" class=\"data row2 col3\" >25.89 (-2.53%)</td>\n",
       "      <td id=\"T_28844_row2_col4\" class=\"data row2 col4\" >25.33 (-4.63%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28844_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_28844_row3_col0\" class=\"data row3 col0\" >Garden</td>\n",
       "      <td id=\"T_28844_row3_col1\" class=\"data row3 col1\" >24.36</td>\n",
       "      <td id=\"T_28844_row3_col2\" class=\"data row3 col2\" >24.28 (-0.34%)</td>\n",
       "      <td id=\"T_28844_row3_col3\" class=\"data row3 col3\" >24.04 (-1.30%)</td>\n",
       "      <td id=\"T_28844_row3_col4\" class=\"data row3 col4\" >23.65 (-2.92%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28844_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_28844_row4_col0\" class=\"data row4 col0\" >Kitchen</td>\n",
       "      <td id=\"T_28844_row4_col1\" class=\"data row4 col1\" >27.95</td>\n",
       "      <td id=\"T_28844_row4_col2\" class=\"data row4 col2\" >27.26 (-2.49%)</td>\n",
       "      <td id=\"T_28844_row4_col3\" class=\"data row4 col3\" >26.64 (-4.71%)</td>\n",
       "      <td id=\"T_28844_row4_col4\" class=\"data row4 col4\" >25.88 (-7.43%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28844_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_28844_row5_col0\" class=\"data row5 col0\" >Room</td>\n",
       "      <td id=\"T_28844_row5_col1\" class=\"data row5 col1\" >30.13</td>\n",
       "      <td id=\"T_28844_row5_col2\" class=\"data row5 col2\" >29.87 (-0.86%)</td>\n",
       "      <td id=\"T_28844_row5_col3\" class=\"data row5 col3\" >29.80 (-1.10%)</td>\n",
       "      <td id=\"T_28844_row5_col4\" class=\"data row5 col4\" >29.42 (-2.35%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28844_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_28844_row6_col0\" class=\"data row6 col0\" >Stump</td>\n",
       "      <td id=\"T_28844_row6_col1\" class=\"data row6 col1\" >23.10</td>\n",
       "      <td id=\"T_28844_row6_col2\" class=\"data row6 col2\" >22.69 (-1.75%)</td>\n",
       "      <td id=\"T_28844_row6_col3\" class=\"data row6 col3\" >21.53 (-6.79%)</td>\n",
       "      <td id=\"T_28844_row6_col4\" class=\"data row6 col4\" >22.62 (-2.05%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff681751b40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_b0049\">\n",
       "  <caption>PSNR values after 20k steps of training for NGP Prop model at different widths across scenes from the MipNeRF-360 dataset.  Values in brackets are the percentage difference compared to the baseline PSNR for each model at full-size (width 64).</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b0049_level0_col0\" class=\"col_heading level0 col0\" >Scene</th>\n",
       "      <th id=\"T_b0049_level0_col1\" class=\"col_heading level0 col1\" >Width 64</th>\n",
       "      <th id=\"T_b0049_level0_col2\" class=\"col_heading level0 col2\" >Width 32</th>\n",
       "      <th id=\"T_b0049_level0_col3\" class=\"col_heading level0 col3\" >Width 16</th>\n",
       "      <th id=\"T_b0049_level0_col4\" class=\"col_heading level0 col4\" >Width 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b0049_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b0049_row0_col0\" class=\"data row0 col0\" >Bicycle</td>\n",
       "      <td id=\"T_b0049_row0_col1\" class=\"data row0 col1\" >23.04</td>\n",
       "      <td id=\"T_b0049_row0_col2\" class=\"data row0 col2\" >22.95 (-0.38%)</td>\n",
       "      <td id=\"T_b0049_row0_col3\" class=\"data row0 col3\" >22.68 (-1.55%)</td>\n",
       "      <td id=\"T_b0049_row0_col4\" class=\"data row0 col4\" >22.33 (-3.07%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b0049_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b0049_row1_col0\" class=\"data row1 col0\" >Bonsai</td>\n",
       "      <td id=\"T_b0049_row1_col1\" class=\"data row1 col1\" >29.87</td>\n",
       "      <td id=\"T_b0049_row1_col2\" class=\"data row1 col2\" >29.36 (-1.70%)</td>\n",
       "      <td id=\"T_b0049_row1_col3\" class=\"data row1 col3\" >28.76 (-3.72%)</td>\n",
       "      <td id=\"T_b0049_row1_col4\" class=\"data row1 col4\" >28.11 (-5.90%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b0049_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b0049_row2_col0\" class=\"data row2 col0\" >Counter</td>\n",
       "      <td id=\"T_b0049_row2_col1\" class=\"data row2 col1\" >26.42</td>\n",
       "      <td id=\"T_b0049_row2_col2\" class=\"data row2 col2\" >25.93 (-1.87%)</td>\n",
       "      <td id=\"T_b0049_row2_col3\" class=\"data row2 col3\" >25.58 (-3.19%)</td>\n",
       "      <td id=\"T_b0049_row2_col4\" class=\"data row2 col4\" >24.29 (-8.07%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b0049_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b0049_row3_col0\" class=\"data row3 col0\" >Garden</td>\n",
       "      <td id=\"T_b0049_row3_col1\" class=\"data row3 col1\" >25.11</td>\n",
       "      <td id=\"T_b0049_row3_col2\" class=\"data row3 col2\" >24.91 (-0.77%)</td>\n",
       "      <td id=\"T_b0049_row3_col3\" class=\"data row3 col3\" >24.70 (-1.62%)</td>\n",
       "      <td id=\"T_b0049_row3_col4\" class=\"data row3 col4\" >24.47 (-2.56%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b0049_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_b0049_row4_col0\" class=\"data row4 col0\" >Kitchen</td>\n",
       "      <td id=\"T_b0049_row4_col1\" class=\"data row4 col1\" >30.01</td>\n",
       "      <td id=\"T_b0049_row4_col2\" class=\"data row4 col2\" >29.50 (-1.70%)</td>\n",
       "      <td id=\"T_b0049_row4_col3\" class=\"data row4 col3\" >28.74 (-4.23%)</td>\n",
       "      <td id=\"T_b0049_row4_col4\" class=\"data row4 col4\" >27.47 (-8.45%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b0049_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_b0049_row5_col0\" class=\"data row5 col0\" >Room</td>\n",
       "      <td id=\"T_b0049_row5_col1\" class=\"data row5 col1\" >30.53</td>\n",
       "      <td id=\"T_b0049_row5_col2\" class=\"data row5 col2\" >30.34 (-0.62%)</td>\n",
       "      <td id=\"T_b0049_row5_col3\" class=\"data row5 col3\" >30.06 (-1.54%)</td>\n",
       "      <td id=\"T_b0049_row5_col4\" class=\"data row5 col4\" >29.83 (-2.27%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b0049_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_b0049_row6_col0\" class=\"data row6 col0\" >Stump</td>\n",
       "      <td id=\"T_b0049_row6_col1\" class=\"data row6 col1\" >24.94</td>\n",
       "      <td id=\"T_b0049_row6_col2\" class=\"data row6 col2\" >24.77 (-0.68%)</td>\n",
       "      <td id=\"T_b0049_row6_col3\" class=\"data row6 col3\" >24.64 (-1.19%)</td>\n",
       "      <td id=\"T_b0049_row6_col4\" class=\"data row6 col4\" >24.20 (-2.96%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff6815efa30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_scenes = len(df[\"scene\"].unique())\n",
    "table_cols = [\"Scene\", \"Width 64\", \"Width 32\", \"Width 16\", \"Width 8\"]\n",
    "for i, (model_type, model_group) in enumerate(df.groupby(by=\"model_type\")):\n",
    "    table_data = []\n",
    "    model_group = model_group.query(\"_step == 20000\")\n",
    "    model_name_split = [m.capitalize() for m in model_type.split(\"_\")]\n",
    "    model_name_split[0] = model_name_split[0].upper()\n",
    "    model_type_name = \" \".join(model_name_split)\n",
    "    for j, (scene, scene_group) in enumerate(model_group.groupby(by=\"scene\")):\n",
    "        base_psnr = scene_group.query(\"_step == 20000 and hidden_dim == 64\")[\n",
    "            \"Eval Results Summary/psnr_avg/elastic_64\"\n",
    "        ].iloc[0]\n",
    "        table_row = {\"Scene\": scene.capitalize()}\n",
    "        for dim, dim_group in scene_group.groupby(by=\"hidden_dim\"):\n",
    "            psnr_col = f\"Eval Results Summary/psnr_avg/elastic_{dim}\"\n",
    "            psnr_avg = dim_group[psnr_col].iloc[0]\n",
    "            pc_diff = 100 * (psnr_avg - base_psnr) / base_psnr\n",
    "            if dim == 64:\n",
    "                table_row.update({f\"Width {dim}\": f\"{psnr_avg:.2f}\"})\n",
    "            else:\n",
    "                table_row.update({f\"Width {dim}\": f\"{psnr_avg:.2f} ({pc_diff:.2f}%)\"})\n",
    "        table_data.append(table_row)\n",
    "\n",
    "    table_data = pd.DataFrame(table_data, columns=table_cols)\n",
    "    caption = (\n",
    "        f\"PSNR values after 20k steps of training for {model_type_name} model at different widths across scenes from the MipNeRF-360 dataset.\"\n",
    "        f\"  Values in brackets are the percentage difference compared to the baseline PSNR for each model at full-size (width 64).\"\n",
    "    )\n",
    "    table_data = table_data.style.set_caption(caption)\n",
    "    display(table_data)\n",
    "    # print(\n",
    "    #     table_data.to_latex(\n",
    "    #         index=False,\n",
    "    #         caption=f\"Baseline performance (PSNR) after 20k steps of training for {model_type_name} model at different widths across scenes from the MipNeRF-360 dataset\",\n",
    "    #         label=f\"tab:baseline_{model_type_name.replace(' ', '_')}\",\n",
    "    #         position=\"h\",\n",
    "    #         column_format=\"lcccccc\",\n",
    "    #         escape=True,\n",
    "    #         bold_rows=True,\n",
    "    #     )\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
